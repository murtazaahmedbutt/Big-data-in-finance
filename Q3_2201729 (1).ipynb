{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r3txZHDfwh04",
    "outputId": "af82dc44-0103-43fb-b4e2-63f7705d26fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.22.4)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.3.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.22.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (61.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (21.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.54.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.2)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: ml-dtypes>=0.0.3 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.7.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\murtaza\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.12.0->tensorflow) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "!pip install tensorflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import tensorflow as tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "i4nYqFnIwoji",
    "outputId": "b0b473a5-99c8-4cdc-ce43-9799d20e8bb3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales/Revenues</th>\n",
       "      <th>Gross Margin</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>EBITDA Margin</th>\n",
       "      <th>Net Income Before Extras</th>\n",
       "      <th>Total Debt</th>\n",
       "      <th>Net Debt</th>\n",
       "      <th>LT Debt</th>\n",
       "      <th>ST Debt</th>\n",
       "      <th>Cash</th>\n",
       "      <th>...</th>\n",
       "      <th>Interest Coverage</th>\n",
       "      <th>Total Liquidity</th>\n",
       "      <th>Current Liquidity</th>\n",
       "      <th>Current Liabilities</th>\n",
       "      <th>EPS Before Extras</th>\n",
       "      <th>PE</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>InvGrd</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.018885</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136748</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>0.100409</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.005496</td>\n",
       "      <td>0.030763</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>0.146849</td>\n",
       "      <td>-0.029710</td>\n",
       "      <td>-0.019296</td>\n",
       "      <td>-0.042648</td>\n",
       "      <td>0.049875</td>\n",
       "      <td>-0.133716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>0.392143</td>\n",
       "      <td>-0.184887</td>\n",
       "      <td>0.062781</td>\n",
       "      <td>0.148305</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.102521</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007045</td>\n",
       "      <td>0.023159</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.096440</td>\n",
       "      <td>0.108590</td>\n",
       "      <td>0.039410</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.009059</td>\n",
       "      <td>0.250371</td>\n",
       "      <td>0.101315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205290</td>\n",
       "      <td>0.483257</td>\n",
       "      <td>-0.017877</td>\n",
       "      <td>0.121357</td>\n",
       "      <td>0.110656</td>\n",
       "      <td>-0.045142</td>\n",
       "      <td>0.105711</td>\n",
       "      <td>0.103378</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.009396</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.146137</td>\n",
       "      <td>0.030071</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>-0.016964</td>\n",
       "      <td>0.356994</td>\n",
       "      <td>-0.052606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232991</td>\n",
       "      <td>0.996955</td>\n",
       "      <td>-0.122017</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>0.151639</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>0.162421</td>\n",
       "      <td>0.132295</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009009</td>\n",
       "      <td>0.027714</td>\n",
       "      <td>0.088716</td>\n",
       "      <td>0.098611</td>\n",
       "      <td>0.123500</td>\n",
       "      <td>0.024224</td>\n",
       "      <td>0.034445</td>\n",
       "      <td>-0.034132</td>\n",
       "      <td>0.461894</td>\n",
       "      <td>-0.090869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.172906</td>\n",
       "      <td>1.711426</td>\n",
       "      <td>-0.161561</td>\n",
       "      <td>0.084319</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.156427</td>\n",
       "      <td>0.225144</td>\n",
       "      <td>1</td>\n",
       "      <td>A1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales/Revenues  Gross Margin    EBITDA  EBITDA Margin  \\\n",
       "0       -0.005496      0.030763  0.018885       0.024515   \n",
       "1       -0.005496      0.030763  0.088716       0.094733   \n",
       "2       -0.007045      0.023159  0.088716       0.096440   \n",
       "3       -0.009396      0.028400  0.088716       0.099046   \n",
       "4       -0.009009      0.027714  0.088716       0.098611   \n",
       "\n",
       "   Net Income Before Extras  Total Debt  Net Debt   LT Debt   ST Debt  \\\n",
       "0                  0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "1                  0.146849   -0.029710 -0.019296 -0.042648  0.049875   \n",
       "2                  0.108590    0.039410  0.034268  0.009059  0.250371   \n",
       "3                  0.146137    0.030071  0.036938 -0.016964  0.356994   \n",
       "4                  0.123500    0.024224  0.034445 -0.034132  0.461894   \n",
       "\n",
       "       Cash  ...  Interest Coverage  Total Liquidity  Current Liquidity  \\\n",
       "0 -0.133716  ...           0.136748         0.392143          -0.184887   \n",
       "1 -0.133716  ...           0.214657         0.392143          -0.184887   \n",
       "2  0.101315  ...           0.205290         0.483257          -0.017877   \n",
       "3 -0.052606  ...           0.232991         0.996955          -0.122017   \n",
       "4 -0.090869  ...           0.172906         1.711426          -0.161561   \n",
       "\n",
       "   Current Liabilities  EPS Before Extras        PE       ROA       ROE  \\\n",
       "0             0.062781           0.148305  0.100409  0.163266  0.102521   \n",
       "1             0.062781           0.148305 -0.089598  0.163266  0.102521   \n",
       "2             0.121357           0.110656 -0.045142  0.105711  0.103378   \n",
       "3             0.079051           0.151639 -0.008231  0.162421  0.132295   \n",
       "4             0.084319           0.130435  0.015528  0.156427  0.225144   \n",
       "\n",
       "   InvGrd  Rating  \n",
       "0       1      A1  \n",
       "1       1      A1  \n",
       "2       1      A1  \n",
       "3       1      A1  \n",
       "4       1      A1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('MLF_GP1_CreditScore.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "K9OtuHSrxJxB"
   },
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "df['InvGrd'] = label_encoder.fit_transform(df['InvGrd'])\n",
    "df['Rating'] = label_encoder.fit_transform(df['Rating'])\n",
    "\n",
    "# Standardise numerical variables\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df.iloc[:, :-2])\n",
    "y_rating = df['Rating']\n",
    "y_grade = df['InvGrd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spliting Data in ratio 80:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nqTJkRHUxOKX"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_rating, y_test_rating, y_train_grade, y_test_grade = train_test_split(X, y_rating, y_grade, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features in X_train and their target variables in y_train_grade are used in the code to build a ridge regression model with L1 smoothing to predict investment grade. The smoothing strength is controlled by the Alpha parameter set to 0.5. Stronger regularization is associated with higher alpha values, while weaker regularization is associated with lower alpha values. The goal is to determine the alpha value that balances the bias-variance tradeoff and produces the best results on the test set. Make predictions after model training on a test set, then evaluate model performance using various metrics, including accuracy scores, confusion matrices, and classification rates. The accuracy score indicates the probability of correct guesses, while the confusion matrix indicates the number of correct positive predictions, correct negative predictions, false positive predictions, and false negative predictions. For each class, the classification report includes additional data including accuracy, recall, and F1 score. To predict investment quality, the code implements a ridge regression model with L1 smoothing. The parameters are chosen so as to reach a compromise between the complexity of the model and the performance of the test set. \n",
    "After implementing the model, we get the Accuracy Score (L1): 0.7705882352941177\n",
    "\n",
    "- Reference https://www.geeksforgeeks.org/implementation-of-ridge-regression-from-scratch-using-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ITwRIN4exVXw",
    "outputId": "8a4df88f-e812-4597-c59a-9dda6fba355a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (L1): 0.7705882352941177\n",
      "Confusion Matrix (L1):\n",
      "[[  1  74]\n",
      " [  4 261]]\n",
      "Classification Report (L1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.01      0.03        75\n",
      "           1       0.78      0.98      0.87       265\n",
      "\n",
      "    accuracy                           0.77       340\n",
      "   macro avg       0.49      0.50      0.45       340\n",
      "weighted avg       0.65      0.77      0.68       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reg_l1 = Ridge(alpha=0.5)\n",
    "reg_l1.fit(X_train, y_train_grade)\n",
    "\n",
    "y_pred_l1 = reg_l1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score (L1):\", accuracy_score(y_test_grade, np.round(y_pred_l1)))\n",
    "print(\"Confusion Matrix (L1):\")\n",
    "print(confusion_matrix(y_test_grade, np.round(y_pred_l1)))\n",
    "print(\"Classification Report (L1):\")\n",
    "print(classification_report(y_test_grade, np.round(y_pred_l1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression using Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code uses the features in X_train and the corresponding target variables in y_train_grade to construct an L2 smooth Lasso regression model to predict the investment grade. The smoothing strength is controlled by the Alpha parameter set to 0.5. Stronger regularization is associated with higher alpha values, while weaker regularization is associated with lower alpha values. The goal is to determine the alpha value that balances the bias-variance tradeoff and performs best on the test set. After the model is trained, predictions are made on the test set, and then model performance is evaluated using various metrics, including accuracy score, confusion matrix, and classification rate. The accuracy value gives the number of times the model was correct, while the confusion matrix gives the number of accurate and inaccurate predictions made by the model. For each class, the classification report includes additional data such as precision, recall, and F1 score. . To predict investment grade, the code implements a lasso regression model with L2 smoothing. Parameters are chosen to find the trade-off between model complexity and test set performance. It should be noted that L2 regularization is not commonly used with lasso patterns, in which case it is likely only used for the intercept term.\n",
    "After implementing the model, we get the Accuracy Score (L2): 0.7794117647058824\n",
    "\n",
    "- Reference https://www.geeksforgeeks.org/implementation-of-lasso-regression-from-scratch-using-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXMb4-68xb2c",
    "outputId": "e4eb37bc-3a66-4d98-87a3-0d5c7794f2c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (L2): 0.7794117647058824\n",
      "Confusion Matrix (L2):\n",
      "[[  0  75]\n",
      " [  0 265]]\n",
      "Classification Report (L2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        75\n",
      "           1       0.78      1.00      0.88       265\n",
      "\n",
      "    accuracy                           0.78       340\n",
      "   macro avg       0.39      0.50      0.44       340\n",
      "weighted avg       0.61      0.78      0.68       340\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Murtaza\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Murtaza\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Murtaza\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "reg_l2 = Lasso(alpha=0.5)\n",
    "reg_l2.fit(X_train, y_train_grade)\n",
    "\n",
    "y_pred_l2 = reg_l2.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score (L2):\", accuracy_score(y_test_grade, np.round(y_pred_l2)))\n",
    "print(\"Confusion Matrix (L2):\")\n",
    "print(confusion_matrix(y_test_grade, np.round(y_pred_l2)))\n",
    "print(\"Classification Report (L2):\")\n",
    "print(classification_report(y_test_grade, np.round(y_pred_l2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code uses the characteristics in X_train and the associated target variables in y_train_grade to build a logistic regression model with L1 smoothing to predict investment grade. The model applies L1 regularization because the penalty parameter is set to \"l1\". The solver option is set to saga, which enables L1 regularization and is suitable for processing large amounts of data. To ensure that the search results can be replicated, the random_state option is set to 0. After training the model, predictions are made on the test set, and then the model's performance on the test set is evaluated using various metrics. including accuracy ratings, confusion matrices, and classification. reports. The accuracy value gives the number of times the model was correct, while the confusion matrix gives the number of accurate and inaccurate predictions made by the model. For each class, the classification report includes additional data such as including accuracy, recall, and F1 score. The parameters are chosen according to their applicability to the given situation, and the code as a whole implements a logistic regression model with L1 regularization to predict investment scores. The choice of the solver and random_state parameters ensures efficient and reproducible results, while the use of L1 regularization helps minimize the amount of features used in the model and improve its interpretability.\n",
    "After implementing the model, we get the Accuracy Score (Logistic L1): 0.7676470588235295\n",
    "\n",
    "- Reference https://stackoverflow.com/questions/41639557/how-to-perform-logistic-lasso-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBJ-9cwwxfgr",
    "outputId": "bf2559b2-74e8-4387-84bd-51facbc7bb8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Logistic L1): 0.7676470588235295\n",
      "Confusion Matrix (Logistic L1):\n",
      "[[  1  74]\n",
      " [  5 260]]\n",
      "Classification Report (Logistic L1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.01      0.02        75\n",
      "           1       0.78      0.98      0.87       265\n",
      "\n",
      "    accuracy                           0.77       340\n",
      "   macro avg       0.47      0.50      0.45       340\n",
      "weighted avg       0.64      0.77      0.68       340\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Murtaza\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "log_reg_l1 = LogisticRegression(penalty='l1', solver='saga', random_state=0)\n",
    "log_reg_l1.fit(X_train, y_train_grade)\n",
    "\n",
    "y_pred_log_l1 = log_reg_l1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score (Logistic L1):\", accuracy_score(y_test_grade, y_pred_log_l1))\n",
    "print(\"Confusion Matrix (Logistic L1):\")\n",
    "print(confusion_matrix(y_test_grade, y_pred_log_l1))\n",
    "print(\"Classification Report (Logistic L1):\")\n",
    "print(classification_report(y_test_grade, y_pred_log_l1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression using Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code uses the features in X_train and the associated target variable in y_train_grade to build a logistic regression model with L2 smoothing to predict investment grade. The model uses L2 regularization because the penalty parameter is set to \"l2\". The solver option is set to liblinear, a solver that supports L2 regularization for small to medium datasets. The reciprocal parameter C of the smoothing power is fixed at 0.1. Lower values of C produce more regularization. After training the model, generate predictions on the test set, then evaluate model performance using various metrics, including accuracy scores, confusion matrices, and classification rates. The confusion matrix presents the count of correct positive predictions, correct negative predictions, incorrect positive predictions, and incorrect negative predictions, while the accuracy score displays the proportion of correct predictions as a percentage. For each class, the classification report includes additional data such as precision, recall, and F1 score. Parameters are chosen based on their applicability to the specified business, and the code as a whole implements a logistic regression model with L2 regularization to predict investment quality. While the choice of solver and C parameters provides effective and efficient regularization, the use of L2 regularization helps prevent overfitting and improves the generalizability of the model.\n",
    "The accuracy score is the proportion of correct predictions, while the confusion matrix shows the number of true positives, true negatives, false positives, and false negatives.\n",
    "After implementing the model, we get the Accuracy Score (Logistic L1): 0.7676470588235295\n",
    "\n",
    "- Reference https://machinelearningmastery.com/ridge-regression-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EKwrBQChxkNR",
    "outputId": "cbeb6267-3439-4736-b2bc-228898e65f72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score (Logistic L1): 0.7676470588235295\n",
      "Confusion Matrix (Logistic L1):\n",
      "[[  1  74]\n",
      " [  5 260]]\n",
      "Classification Report (Logistic L1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.01      0.02        75\n",
      "           1       0.78      0.98      0.87       265\n",
      "\n",
      "    accuracy                           0.77       340\n",
      "   macro avg       0.47      0.50      0.45       340\n",
      "weighted avg       0.64      0.77      0.68       340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(penalty='l2', solver='liblinear', C=0.1)\n",
    "\n",
    "logreg.fit(X_train, y_train_grade)\n",
    "\n",
    "y_pred_log_l2 = logreg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy Score (Logistic L1):\", accuracy_score(y_test_grade, y_pred_log_l2))\n",
    "print(\"Confusion Matrix (Logistic L1):\")\n",
    "print(confusion_matrix(y_test_grade, y_pred_log_l2))\n",
    "print(\"Classification Report (Logistic L1):\")\n",
    "print(classification_report(y_test_grade, y_pred_log_l2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code uses the Keras package to create a neural network model for credit rating classification. Three dense layers compose the model architecture, the input layer has 64 nodes with \"relu\" activation, the second layer has 32 nodes with \"relu\" and the output layer has 16 nodes with \"softmax\" activation. To avoid overfitting, a suppression layer is also placed after the input layer and the second masked layer. The \"adam\" optimizer and the \"sparse_categorical_crossentropy\" loss function are used to build the model. A loss function is used to determine the difference between predicted and actual values, which is minimized by the optimizer during training. To monitor model performance during training, the Metrics option is set to Accuracy. The model is then trained using the training data for 1000 epochs and a batch size of 32. Validation data is also provided to monitor the performance of the model during training on data it has never seen before. After the model is trained, its accuracy is measured using the test set. Then use the prediction function to predict the credit value of the test set. The predicted probabilities are converted to their respective credit ratings using a label encoder. In summary, the code uses the Keras library to build a neural network model to rank credit scores, choosing parameters based on how well they solve the problem at hand. Choose model architectures, optimizers, loss functions, and metrics to improve model performance on credit classification problems.\n",
    "After implementing the model, we get the Accuracy for credit rating classification: 41.18%.\n",
    "\n",
    "- Reference https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 849
    },
    "id": "V-XN81L_xndm",
    "outputId": "ba9433b5-0c37-4ccb-bbca-6d6c98c4e30a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "43/43 [==============================] - 1s 6ms/step - loss: 2.7677 - accuracy: 0.1118 - val_loss: 2.6272 - val_accuracy: 0.1382\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.6336 - accuracy: 0.1463 - val_loss: 2.5353 - val_accuracy: 0.2000\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.5440 - accuracy: 0.1809 - val_loss: 2.4760 - val_accuracy: 0.2000\n",
      "Epoch 4/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.4605 - accuracy: 0.1956 - val_loss: 2.4219 - val_accuracy: 0.2029\n",
      "Epoch 5/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.4269 - accuracy: 0.1941 - val_loss: 2.3827 - val_accuracy: 0.2206\n",
      "Epoch 6/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.4002 - accuracy: 0.2125 - val_loss: 2.3547 - val_accuracy: 0.2294\n",
      "Epoch 7/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.3524 - accuracy: 0.2228 - val_loss: 2.3361 - val_accuracy: 0.2294\n",
      "Epoch 8/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.3395 - accuracy: 0.2132 - val_loss: 2.3158 - val_accuracy: 0.2441\n",
      "Epoch 9/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.3077 - accuracy: 0.2184 - val_loss: 2.3042 - val_accuracy: 0.2176\n",
      "Epoch 10/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2995 - accuracy: 0.2199 - val_loss: 2.2886 - val_accuracy: 0.2294\n",
      "Epoch 11/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2650 - accuracy: 0.2375 - val_loss: 2.2853 - val_accuracy: 0.2294\n",
      "Epoch 12/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2531 - accuracy: 0.2331 - val_loss: 2.2761 - val_accuracy: 0.2206\n",
      "Epoch 13/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.2549 - accuracy: 0.2456 - val_loss: 2.2669 - val_accuracy: 0.2294\n",
      "Epoch 14/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.2295 - accuracy: 0.2375 - val_loss: 2.2558 - val_accuracy: 0.2147\n",
      "Epoch 15/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2144 - accuracy: 0.2426 - val_loss: 2.2447 - val_accuracy: 0.2294\n",
      "Epoch 16/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2101 - accuracy: 0.2456 - val_loss: 2.2354 - val_accuracy: 0.2265\n",
      "Epoch 17/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.2057 - accuracy: 0.2404 - val_loss: 2.2314 - val_accuracy: 0.2412\n",
      "Epoch 18/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.1901 - accuracy: 0.2529 - val_loss: 2.2278 - val_accuracy: 0.2441\n",
      "Epoch 19/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1796 - accuracy: 0.2669 - val_loss: 2.2165 - val_accuracy: 0.2500\n",
      "Epoch 20/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1673 - accuracy: 0.2544 - val_loss: 2.2128 - val_accuracy: 0.2529\n",
      "Epoch 21/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1498 - accuracy: 0.2618 - val_loss: 2.2039 - val_accuracy: 0.2500\n",
      "Epoch 22/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1560 - accuracy: 0.2603 - val_loss: 2.2015 - val_accuracy: 0.2471\n",
      "Epoch 23/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1572 - accuracy: 0.2588 - val_loss: 2.1953 - val_accuracy: 0.2706\n",
      "Epoch 24/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1456 - accuracy: 0.2647 - val_loss: 2.1892 - val_accuracy: 0.2559\n",
      "Epoch 25/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1476 - accuracy: 0.2684 - val_loss: 2.1876 - val_accuracy: 0.2529\n",
      "Epoch 26/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.1251 - accuracy: 0.2610 - val_loss: 2.1845 - val_accuracy: 0.2588\n",
      "Epoch 27/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1263 - accuracy: 0.2772 - val_loss: 2.1787 - val_accuracy: 0.2529\n",
      "Epoch 28/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0957 - accuracy: 0.2801 - val_loss: 2.1717 - val_accuracy: 0.2706\n",
      "Epoch 29/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1103 - accuracy: 0.2860 - val_loss: 2.1662 - val_accuracy: 0.2706\n",
      "Epoch 30/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0786 - accuracy: 0.2831 - val_loss: 2.1625 - val_accuracy: 0.2559\n",
      "Epoch 31/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.1053 - accuracy: 0.2838 - val_loss: 2.1566 - val_accuracy: 0.2735\n",
      "Epoch 32/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.0797 - accuracy: 0.2809 - val_loss: 2.1549 - val_accuracy: 0.2647\n",
      "Epoch 33/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0944 - accuracy: 0.2691 - val_loss: 2.1493 - val_accuracy: 0.2676\n",
      "Epoch 34/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0660 - accuracy: 0.2882 - val_loss: 2.1475 - val_accuracy: 0.2735\n",
      "Epoch 35/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0592 - accuracy: 0.2956 - val_loss: 2.1487 - val_accuracy: 0.2706\n",
      "Epoch 36/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0543 - accuracy: 0.2926 - val_loss: 2.1521 - val_accuracy: 0.2706\n",
      "Epoch 37/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0608 - accuracy: 0.3088 - val_loss: 2.1502 - val_accuracy: 0.2618\n",
      "Epoch 38/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0557 - accuracy: 0.2868 - val_loss: 2.1443 - val_accuracy: 0.2647\n",
      "Epoch 39/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0663 - accuracy: 0.2897 - val_loss: 2.1331 - val_accuracy: 0.2706\n",
      "Epoch 40/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0640 - accuracy: 0.2919 - val_loss: 2.1213 - val_accuracy: 0.2706\n",
      "Epoch 41/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0437 - accuracy: 0.3000 - val_loss: 2.1232 - val_accuracy: 0.2735\n",
      "Epoch 42/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0174 - accuracy: 0.3184 - val_loss: 2.1275 - val_accuracy: 0.2706\n",
      "Epoch 43/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0241 - accuracy: 0.2993 - val_loss: 2.1177 - val_accuracy: 0.2647\n",
      "Epoch 44/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0252 - accuracy: 0.3037 - val_loss: 2.1189 - val_accuracy: 0.2853\n",
      "Epoch 45/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0275 - accuracy: 0.3051 - val_loss: 2.1173 - val_accuracy: 0.2824\n",
      "Epoch 46/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0263 - accuracy: 0.3066 - val_loss: 2.1167 - val_accuracy: 0.2765\n",
      "Epoch 47/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0322 - accuracy: 0.3066 - val_loss: 2.1147 - val_accuracy: 0.2676\n",
      "Epoch 48/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0202 - accuracy: 0.3007 - val_loss: 2.1129 - val_accuracy: 0.2676\n",
      "Epoch 49/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.0041 - accuracy: 0.3110 - val_loss: 2.1044 - val_accuracy: 0.2735\n",
      "Epoch 50/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 2.0146 - accuracy: 0.2926 - val_loss: 2.1046 - val_accuracy: 0.2765\n",
      "Epoch 51/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.0022 - accuracy: 0.3022 - val_loss: 2.0988 - val_accuracy: 0.2676\n",
      "Epoch 52/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 2.0192 - accuracy: 0.3015 - val_loss: 2.0947 - val_accuracy: 0.2882\n",
      "Epoch 53/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.9843 - accuracy: 0.3110 - val_loss: 2.0938 - val_accuracy: 0.2824\n",
      "Epoch 54/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9736 - accuracy: 0.3199 - val_loss: 2.0913 - val_accuracy: 0.2912\n",
      "Epoch 55/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9646 - accuracy: 0.3221 - val_loss: 2.0856 - val_accuracy: 0.2971\n",
      "Epoch 56/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9798 - accuracy: 0.3184 - val_loss: 2.0797 - val_accuracy: 0.2941\n",
      "Epoch 57/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9690 - accuracy: 0.3257 - val_loss: 2.0789 - val_accuracy: 0.3059\n",
      "Epoch 58/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9675 - accuracy: 0.3088 - val_loss: 2.0799 - val_accuracy: 0.3000\n",
      "Epoch 59/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9517 - accuracy: 0.3199 - val_loss: 2.0694 - val_accuracy: 0.3059\n",
      "Epoch 60/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9702 - accuracy: 0.3081 - val_loss: 2.0756 - val_accuracy: 0.3059\n",
      "Epoch 61/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9546 - accuracy: 0.3132 - val_loss: 2.0820 - val_accuracy: 0.2941\n",
      "Epoch 62/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9707 - accuracy: 0.3235 - val_loss: 2.0760 - val_accuracy: 0.2971\n",
      "Epoch 63/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9495 - accuracy: 0.3228 - val_loss: 2.0802 - val_accuracy: 0.3147\n",
      "Epoch 64/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9451 - accuracy: 0.3309 - val_loss: 2.0702 - val_accuracy: 0.2853\n",
      "Epoch 65/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9387 - accuracy: 0.3301 - val_loss: 2.0713 - val_accuracy: 0.2912\n",
      "Epoch 66/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9101 - accuracy: 0.3346 - val_loss: 2.0787 - val_accuracy: 0.3088\n",
      "Epoch 67/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9413 - accuracy: 0.3404 - val_loss: 2.0752 - val_accuracy: 0.2941\n",
      "Epoch 68/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9527 - accuracy: 0.3176 - val_loss: 2.0701 - val_accuracy: 0.2971\n",
      "Epoch 69/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9347 - accuracy: 0.3169 - val_loss: 2.0622 - val_accuracy: 0.2912\n",
      "Epoch 70/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9115 - accuracy: 0.3353 - val_loss: 2.0561 - val_accuracy: 0.3029\n",
      "Epoch 71/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9484 - accuracy: 0.3199 - val_loss: 2.0544 - val_accuracy: 0.3176\n",
      "Epoch 72/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9211 - accuracy: 0.3441 - val_loss: 2.0516 - val_accuracy: 0.3059\n",
      "Epoch 73/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9045 - accuracy: 0.3390 - val_loss: 2.0468 - val_accuracy: 0.3147\n",
      "Epoch 74/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8999 - accuracy: 0.3529 - val_loss: 2.0457 - val_accuracy: 0.3118\n",
      "Epoch 75/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9007 - accuracy: 0.3434 - val_loss: 2.0496 - val_accuracy: 0.3147\n",
      "Epoch 76/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9090 - accuracy: 0.3221 - val_loss: 2.0519 - val_accuracy: 0.3176\n",
      "Epoch 77/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9055 - accuracy: 0.3397 - val_loss: 2.0456 - val_accuracy: 0.3235\n",
      "Epoch 78/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8820 - accuracy: 0.3529 - val_loss: 2.0400 - val_accuracy: 0.3176\n",
      "Epoch 79/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8927 - accuracy: 0.3463 - val_loss: 2.0345 - val_accuracy: 0.3147\n",
      "Epoch 80/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9107 - accuracy: 0.3360 - val_loss: 2.0404 - val_accuracy: 0.3206\n",
      "Epoch 81/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8690 - accuracy: 0.3353 - val_loss: 2.0358 - val_accuracy: 0.3382\n",
      "Epoch 82/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.9141 - accuracy: 0.3507 - val_loss: 2.0240 - val_accuracy: 0.3118\n",
      "Epoch 83/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8988 - accuracy: 0.3353 - val_loss: 2.0336 - val_accuracy: 0.3118\n",
      "Epoch 84/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8884 - accuracy: 0.3419 - val_loss: 2.0330 - val_accuracy: 0.3088\n",
      "Epoch 85/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8931 - accuracy: 0.3426 - val_loss: 2.0306 - val_accuracy: 0.3118\n",
      "Epoch 86/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8690 - accuracy: 0.3478 - val_loss: 2.0310 - val_accuracy: 0.3176\n",
      "Epoch 87/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8822 - accuracy: 0.3419 - val_loss: 2.0272 - val_accuracy: 0.2971\n",
      "Epoch 88/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8705 - accuracy: 0.3390 - val_loss: 2.0311 - val_accuracy: 0.3265\n",
      "Epoch 89/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8625 - accuracy: 0.3463 - val_loss: 2.0326 - val_accuracy: 0.3176\n",
      "Epoch 90/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8281 - accuracy: 0.3728 - val_loss: 2.0356 - val_accuracy: 0.2971\n",
      "Epoch 91/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8506 - accuracy: 0.3610 - val_loss: 2.0337 - val_accuracy: 0.3206\n",
      "Epoch 92/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8533 - accuracy: 0.3544 - val_loss: 2.0411 - val_accuracy: 0.3059\n",
      "Epoch 93/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8436 - accuracy: 0.3632 - val_loss: 2.0410 - val_accuracy: 0.3147\n",
      "Epoch 94/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8434 - accuracy: 0.3426 - val_loss: 2.0369 - val_accuracy: 0.3029\n",
      "Epoch 95/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8492 - accuracy: 0.3574 - val_loss: 2.0291 - val_accuracy: 0.3235\n",
      "Epoch 96/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8336 - accuracy: 0.3706 - val_loss: 2.0215 - val_accuracy: 0.3176\n",
      "Epoch 97/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8526 - accuracy: 0.3596 - val_loss: 2.0272 - val_accuracy: 0.3206\n",
      "Epoch 98/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.8530 - accuracy: 0.3632 - val_loss: 2.0155 - val_accuracy: 0.3206\n",
      "Epoch 99/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8287 - accuracy: 0.3559 - val_loss: 2.0138 - val_accuracy: 0.3206\n",
      "Epoch 100/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8414 - accuracy: 0.3721 - val_loss: 2.0118 - val_accuracy: 0.3265\n",
      "Epoch 101/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8240 - accuracy: 0.3743 - val_loss: 2.0221 - val_accuracy: 0.3235\n",
      "Epoch 102/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8214 - accuracy: 0.3610 - val_loss: 2.0255 - val_accuracy: 0.3147\n",
      "Epoch 103/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8274 - accuracy: 0.3625 - val_loss: 2.0186 - val_accuracy: 0.3176\n",
      "Epoch 104/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8225 - accuracy: 0.3713 - val_loss: 2.0160 - val_accuracy: 0.3029\n",
      "Epoch 105/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8231 - accuracy: 0.3500 - val_loss: 2.0122 - val_accuracy: 0.3206\n",
      "Epoch 106/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8116 - accuracy: 0.3699 - val_loss: 2.0147 - val_accuracy: 0.3206\n",
      "Epoch 107/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8045 - accuracy: 0.3728 - val_loss: 2.0128 - val_accuracy: 0.3235\n",
      "Epoch 108/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8332 - accuracy: 0.3529 - val_loss: 2.0144 - val_accuracy: 0.3265\n",
      "Epoch 109/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8183 - accuracy: 0.3662 - val_loss: 2.0105 - val_accuracy: 0.3029\n",
      "Epoch 110/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7959 - accuracy: 0.3757 - val_loss: 2.0072 - val_accuracy: 0.3176\n",
      "Epoch 111/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8251 - accuracy: 0.3728 - val_loss: 2.0000 - val_accuracy: 0.3206\n",
      "Epoch 112/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7890 - accuracy: 0.3978 - val_loss: 2.0044 - val_accuracy: 0.3353\n",
      "Epoch 113/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7811 - accuracy: 0.3559 - val_loss: 2.0124 - val_accuracy: 0.3265\n",
      "Epoch 114/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8014 - accuracy: 0.3794 - val_loss: 2.0047 - val_accuracy: 0.2971\n",
      "Epoch 115/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8041 - accuracy: 0.3684 - val_loss: 2.0050 - val_accuracy: 0.3265\n",
      "Epoch 116/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7808 - accuracy: 0.3824 - val_loss: 2.0114 - val_accuracy: 0.3206\n",
      "Epoch 117/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.8058 - accuracy: 0.3838 - val_loss: 1.9949 - val_accuracy: 0.3294\n",
      "Epoch 118/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7956 - accuracy: 0.3684 - val_loss: 1.9971 - val_accuracy: 0.3294\n",
      "Epoch 119/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7800 - accuracy: 0.3934 - val_loss: 2.0097 - val_accuracy: 0.3471\n",
      "Epoch 120/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7873 - accuracy: 0.3787 - val_loss: 1.9988 - val_accuracy: 0.3382\n",
      "Epoch 121/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7975 - accuracy: 0.3566 - val_loss: 2.0110 - val_accuracy: 0.3353\n",
      "Epoch 122/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7914 - accuracy: 0.3662 - val_loss: 1.9893 - val_accuracy: 0.3324\n",
      "Epoch 123/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7904 - accuracy: 0.3772 - val_loss: 1.9965 - val_accuracy: 0.3353\n",
      "Epoch 124/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7930 - accuracy: 0.3787 - val_loss: 1.9905 - val_accuracy: 0.3500\n",
      "Epoch 125/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7974 - accuracy: 0.3757 - val_loss: 1.9915 - val_accuracy: 0.3500\n",
      "Epoch 126/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7766 - accuracy: 0.3699 - val_loss: 1.9997 - val_accuracy: 0.3294\n",
      "Epoch 127/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7767 - accuracy: 0.3691 - val_loss: 1.9859 - val_accuracy: 0.3382\n",
      "Epoch 128/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7792 - accuracy: 0.3875 - val_loss: 1.9846 - val_accuracy: 0.3500\n",
      "Epoch 129/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7512 - accuracy: 0.3978 - val_loss: 1.9943 - val_accuracy: 0.3265\n",
      "Epoch 130/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7705 - accuracy: 0.3926 - val_loss: 1.9883 - val_accuracy: 0.3324\n",
      "Epoch 131/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7818 - accuracy: 0.3640 - val_loss: 1.9861 - val_accuracy: 0.3206\n",
      "Epoch 132/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7425 - accuracy: 0.3846 - val_loss: 1.9923 - val_accuracy: 0.3294\n",
      "Epoch 133/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7578 - accuracy: 0.3699 - val_loss: 1.9894 - val_accuracy: 0.3324\n",
      "Epoch 134/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7413 - accuracy: 0.4007 - val_loss: 1.9809 - val_accuracy: 0.3441\n",
      "Epoch 135/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7683 - accuracy: 0.3985 - val_loss: 1.9811 - val_accuracy: 0.3412\n",
      "Epoch 136/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7523 - accuracy: 0.3853 - val_loss: 1.9717 - val_accuracy: 0.3618\n",
      "Epoch 137/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7480 - accuracy: 0.3801 - val_loss: 1.9773 - val_accuracy: 0.3647\n",
      "Epoch 138/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7703 - accuracy: 0.3750 - val_loss: 1.9720 - val_accuracy: 0.3529\n",
      "Epoch 139/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7437 - accuracy: 0.3875 - val_loss: 1.9698 - val_accuracy: 0.3500\n",
      "Epoch 140/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7168 - accuracy: 0.3926 - val_loss: 1.9736 - val_accuracy: 0.3382\n",
      "Epoch 141/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7282 - accuracy: 0.4059 - val_loss: 1.9698 - val_accuracy: 0.3500\n",
      "Epoch 142/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7481 - accuracy: 0.3868 - val_loss: 1.9801 - val_accuracy: 0.3412\n",
      "Epoch 143/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7534 - accuracy: 0.3904 - val_loss: 1.9733 - val_accuracy: 0.3324\n",
      "Epoch 144/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7187 - accuracy: 0.3985 - val_loss: 1.9656 - val_accuracy: 0.3529\n",
      "Epoch 145/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7560 - accuracy: 0.3824 - val_loss: 1.9701 - val_accuracy: 0.3618\n",
      "Epoch 146/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7508 - accuracy: 0.3860 - val_loss: 1.9541 - val_accuracy: 0.3353\n",
      "Epoch 147/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7149 - accuracy: 0.4044 - val_loss: 1.9550 - val_accuracy: 0.3382\n",
      "Epoch 148/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7152 - accuracy: 0.3926 - val_loss: 1.9514 - val_accuracy: 0.3441\n",
      "Epoch 149/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7269 - accuracy: 0.3904 - val_loss: 1.9584 - val_accuracy: 0.3559\n",
      "Epoch 150/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7163 - accuracy: 0.4022 - val_loss: 1.9607 - val_accuracy: 0.3559\n",
      "Epoch 151/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7195 - accuracy: 0.4037 - val_loss: 1.9686 - val_accuracy: 0.3559\n",
      "Epoch 152/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7565 - accuracy: 0.3816 - val_loss: 1.9689 - val_accuracy: 0.3441\n",
      "Epoch 153/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7367 - accuracy: 0.3860 - val_loss: 1.9658 - val_accuracy: 0.3529\n",
      "Epoch 154/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7030 - accuracy: 0.3963 - val_loss: 1.9687 - val_accuracy: 0.3441\n",
      "Epoch 155/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7026 - accuracy: 0.4191 - val_loss: 1.9684 - val_accuracy: 0.3382\n",
      "Epoch 156/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7152 - accuracy: 0.4059 - val_loss: 1.9670 - val_accuracy: 0.3441\n",
      "Epoch 157/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7400 - accuracy: 0.3993 - val_loss: 1.9740 - val_accuracy: 0.3324\n",
      "Epoch 158/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7125 - accuracy: 0.4015 - val_loss: 1.9708 - val_accuracy: 0.3441\n",
      "Epoch 159/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7110 - accuracy: 0.4206 - val_loss: 1.9604 - val_accuracy: 0.3441\n",
      "Epoch 160/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7164 - accuracy: 0.4154 - val_loss: 1.9661 - val_accuracy: 0.3382\n",
      "Epoch 161/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7097 - accuracy: 0.4118 - val_loss: 1.9614 - val_accuracy: 0.3618\n",
      "Epoch 162/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7187 - accuracy: 0.3750 - val_loss: 1.9648 - val_accuracy: 0.3618\n",
      "Epoch 163/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7197 - accuracy: 0.3956 - val_loss: 1.9591 - val_accuracy: 0.3529\n",
      "Epoch 164/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6987 - accuracy: 0.4257 - val_loss: 1.9652 - val_accuracy: 0.3529\n",
      "Epoch 165/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6989 - accuracy: 0.3904 - val_loss: 1.9659 - val_accuracy: 0.3353\n",
      "Epoch 166/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7121 - accuracy: 0.4088 - val_loss: 1.9670 - val_accuracy: 0.3441\n",
      "Epoch 167/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6686 - accuracy: 0.4184 - val_loss: 1.9692 - val_accuracy: 0.3529\n",
      "Epoch 168/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6889 - accuracy: 0.3934 - val_loss: 1.9701 - val_accuracy: 0.3500\n",
      "Epoch 169/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6957 - accuracy: 0.4022 - val_loss: 1.9646 - val_accuracy: 0.3559\n",
      "Epoch 170/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6628 - accuracy: 0.4265 - val_loss: 1.9644 - val_accuracy: 0.3588\n",
      "Epoch 171/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7113 - accuracy: 0.3978 - val_loss: 1.9700 - val_accuracy: 0.3471\n",
      "Epoch 172/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6942 - accuracy: 0.4110 - val_loss: 1.9659 - val_accuracy: 0.3412\n",
      "Epoch 173/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6887 - accuracy: 0.4015 - val_loss: 1.9619 - val_accuracy: 0.3412\n",
      "Epoch 174/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6882 - accuracy: 0.4103 - val_loss: 1.9751 - val_accuracy: 0.3412\n",
      "Epoch 175/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6771 - accuracy: 0.4184 - val_loss: 1.9704 - val_accuracy: 0.3441\n",
      "Epoch 176/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6379 - accuracy: 0.4221 - val_loss: 1.9709 - val_accuracy: 0.3471\n",
      "Epoch 177/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7529 - accuracy: 0.3934 - val_loss: 1.9764 - val_accuracy: 0.3500\n",
      "Epoch 178/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6645 - accuracy: 0.4125 - val_loss: 1.9647 - val_accuracy: 0.3647\n",
      "Epoch 179/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6872 - accuracy: 0.4140 - val_loss: 1.9534 - val_accuracy: 0.3588\n",
      "Epoch 180/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6737 - accuracy: 0.4169 - val_loss: 1.9571 - val_accuracy: 0.3559\n",
      "Epoch 181/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6734 - accuracy: 0.4118 - val_loss: 1.9656 - val_accuracy: 0.3441\n",
      "Epoch 182/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.7005 - accuracy: 0.4081 - val_loss: 1.9537 - val_accuracy: 0.3588\n",
      "Epoch 183/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6574 - accuracy: 0.4250 - val_loss: 1.9576 - val_accuracy: 0.3588\n",
      "Epoch 184/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6837 - accuracy: 0.4125 - val_loss: 1.9674 - val_accuracy: 0.3529\n",
      "Epoch 185/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6307 - accuracy: 0.4338 - val_loss: 1.9579 - val_accuracy: 0.3529\n",
      "Epoch 186/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6500 - accuracy: 0.4228 - val_loss: 1.9518 - val_accuracy: 0.3588\n",
      "Epoch 187/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6213 - accuracy: 0.4309 - val_loss: 1.9572 - val_accuracy: 0.3412\n",
      "Epoch 188/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6413 - accuracy: 0.4309 - val_loss: 1.9686 - val_accuracy: 0.3500\n",
      "Epoch 189/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6692 - accuracy: 0.4235 - val_loss: 1.9669 - val_accuracy: 0.3529\n",
      "Epoch 190/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6709 - accuracy: 0.4074 - val_loss: 1.9446 - val_accuracy: 0.3706\n",
      "Epoch 191/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6477 - accuracy: 0.4169 - val_loss: 1.9625 - val_accuracy: 0.3559\n",
      "Epoch 192/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6586 - accuracy: 0.4434 - val_loss: 1.9555 - val_accuracy: 0.3559\n",
      "Epoch 193/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6633 - accuracy: 0.4213 - val_loss: 1.9406 - val_accuracy: 0.3647\n",
      "Epoch 194/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6868 - accuracy: 0.4250 - val_loss: 1.9396 - val_accuracy: 0.3647\n",
      "Epoch 195/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6494 - accuracy: 0.4184 - val_loss: 1.9465 - val_accuracy: 0.3706\n",
      "Epoch 196/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6660 - accuracy: 0.4088 - val_loss: 1.9351 - val_accuracy: 0.3529\n",
      "Epoch 197/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6328 - accuracy: 0.4316 - val_loss: 1.9444 - val_accuracy: 0.3529\n",
      "Epoch 198/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6613 - accuracy: 0.3971 - val_loss: 1.9414 - val_accuracy: 0.3588\n",
      "Epoch 199/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6621 - accuracy: 0.4096 - val_loss: 1.9311 - val_accuracy: 0.3676\n",
      "Epoch 200/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6765 - accuracy: 0.4154 - val_loss: 1.9407 - val_accuracy: 0.3559\n",
      "Epoch 201/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6504 - accuracy: 0.4301 - val_loss: 1.9348 - val_accuracy: 0.3618\n",
      "Epoch 202/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6700 - accuracy: 0.4140 - val_loss: 1.9452 - val_accuracy: 0.3588\n",
      "Epoch 203/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6227 - accuracy: 0.4331 - val_loss: 1.9543 - val_accuracy: 0.3471\n",
      "Epoch 204/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6473 - accuracy: 0.4213 - val_loss: 1.9635 - val_accuracy: 0.3500\n",
      "Epoch 205/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6196 - accuracy: 0.4316 - val_loss: 1.9620 - val_accuracy: 0.3529\n",
      "Epoch 206/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6694 - accuracy: 0.4081 - val_loss: 1.9621 - val_accuracy: 0.3676\n",
      "Epoch 207/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6381 - accuracy: 0.4169 - val_loss: 1.9585 - val_accuracy: 0.3500\n",
      "Epoch 208/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6348 - accuracy: 0.4221 - val_loss: 1.9595 - val_accuracy: 0.3676\n",
      "Epoch 209/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6577 - accuracy: 0.4147 - val_loss: 1.9439 - val_accuracy: 0.3588\n",
      "Epoch 210/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6351 - accuracy: 0.4368 - val_loss: 1.9426 - val_accuracy: 0.3706\n",
      "Epoch 211/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6121 - accuracy: 0.4360 - val_loss: 1.9591 - val_accuracy: 0.3647\n",
      "Epoch 212/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6522 - accuracy: 0.4397 - val_loss: 1.9610 - val_accuracy: 0.3647\n",
      "Epoch 213/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6322 - accuracy: 0.4213 - val_loss: 1.9548 - val_accuracy: 0.3618\n",
      "Epoch 214/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6641 - accuracy: 0.4199 - val_loss: 1.9652 - val_accuracy: 0.3647\n",
      "Epoch 215/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6247 - accuracy: 0.4316 - val_loss: 1.9531 - val_accuracy: 0.3559\n",
      "Epoch 216/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6053 - accuracy: 0.4368 - val_loss: 1.9577 - val_accuracy: 0.3676\n",
      "Epoch 217/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6200 - accuracy: 0.4301 - val_loss: 1.9570 - val_accuracy: 0.3588\n",
      "Epoch 218/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6397 - accuracy: 0.4272 - val_loss: 1.9586 - val_accuracy: 0.3618\n",
      "Epoch 219/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6289 - accuracy: 0.4279 - val_loss: 1.9631 - val_accuracy: 0.3647\n",
      "Epoch 220/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6174 - accuracy: 0.4309 - val_loss: 1.9678 - val_accuracy: 0.3529\n",
      "Epoch 221/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6340 - accuracy: 0.4191 - val_loss: 1.9596 - val_accuracy: 0.3588\n",
      "Epoch 222/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6468 - accuracy: 0.4301 - val_loss: 1.9526 - val_accuracy: 0.3588\n",
      "Epoch 223/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6024 - accuracy: 0.4375 - val_loss: 1.9599 - val_accuracy: 0.3676\n",
      "Epoch 224/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5924 - accuracy: 0.4404 - val_loss: 1.9540 - val_accuracy: 0.3765\n",
      "Epoch 225/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6303 - accuracy: 0.4346 - val_loss: 1.9651 - val_accuracy: 0.3500\n",
      "Epoch 226/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6262 - accuracy: 0.4375 - val_loss: 1.9583 - val_accuracy: 0.3559\n",
      "Epoch 227/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6179 - accuracy: 0.4397 - val_loss: 1.9525 - val_accuracy: 0.3676\n",
      "Epoch 228/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6345 - accuracy: 0.4088 - val_loss: 1.9510 - val_accuracy: 0.3529\n",
      "Epoch 229/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6078 - accuracy: 0.4412 - val_loss: 1.9431 - val_accuracy: 0.3471\n",
      "Epoch 230/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5800 - accuracy: 0.4404 - val_loss: 1.9504 - val_accuracy: 0.3647\n",
      "Epoch 231/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6034 - accuracy: 0.4375 - val_loss: 1.9461 - val_accuracy: 0.3647\n",
      "Epoch 232/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5980 - accuracy: 0.4375 - val_loss: 1.9400 - val_accuracy: 0.3706\n",
      "Epoch 233/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5862 - accuracy: 0.4441 - val_loss: 1.9420 - val_accuracy: 0.3647\n",
      "Epoch 234/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5994 - accuracy: 0.4360 - val_loss: 1.9409 - val_accuracy: 0.3794\n",
      "Epoch 235/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6077 - accuracy: 0.4456 - val_loss: 1.9419 - val_accuracy: 0.3735\n",
      "Epoch 236/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5919 - accuracy: 0.4360 - val_loss: 1.9416 - val_accuracy: 0.3765\n",
      "Epoch 237/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5824 - accuracy: 0.4434 - val_loss: 1.9360 - val_accuracy: 0.3588\n",
      "Epoch 238/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6235 - accuracy: 0.4309 - val_loss: 1.9508 - val_accuracy: 0.3676\n",
      "Epoch 239/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6047 - accuracy: 0.4257 - val_loss: 1.9572 - val_accuracy: 0.3765\n",
      "Epoch 240/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5903 - accuracy: 0.4419 - val_loss: 1.9623 - val_accuracy: 0.3765\n",
      "Epoch 241/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5772 - accuracy: 0.4382 - val_loss: 1.9566 - val_accuracy: 0.3647\n",
      "Epoch 242/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6267 - accuracy: 0.4213 - val_loss: 1.9504 - val_accuracy: 0.3794\n",
      "Epoch 243/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6145 - accuracy: 0.4360 - val_loss: 1.9414 - val_accuracy: 0.3588\n",
      "Epoch 244/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5892 - accuracy: 0.4537 - val_loss: 1.9396 - val_accuracy: 0.3676\n",
      "Epoch 245/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5813 - accuracy: 0.4426 - val_loss: 1.9390 - val_accuracy: 0.3676\n",
      "Epoch 246/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6026 - accuracy: 0.4382 - val_loss: 1.9431 - val_accuracy: 0.3765\n",
      "Epoch 247/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5843 - accuracy: 0.4493 - val_loss: 1.9463 - val_accuracy: 0.3676\n",
      "Epoch 248/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6324 - accuracy: 0.4316 - val_loss: 1.9489 - val_accuracy: 0.3824\n",
      "Epoch 249/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6050 - accuracy: 0.4346 - val_loss: 1.9417 - val_accuracy: 0.3794\n",
      "Epoch 250/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6190 - accuracy: 0.4456 - val_loss: 1.9443 - val_accuracy: 0.3824\n",
      "Epoch 251/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6006 - accuracy: 0.4397 - val_loss: 1.9452 - val_accuracy: 0.3765\n",
      "Epoch 252/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5802 - accuracy: 0.4544 - val_loss: 1.9375 - val_accuracy: 0.3853\n",
      "Epoch 253/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5871 - accuracy: 0.4647 - val_loss: 1.9435 - val_accuracy: 0.3853\n",
      "Epoch 254/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5773 - accuracy: 0.4581 - val_loss: 1.9356 - val_accuracy: 0.3765\n",
      "Epoch 255/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5832 - accuracy: 0.4419 - val_loss: 1.9300 - val_accuracy: 0.3853\n",
      "Epoch 256/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5629 - accuracy: 0.4360 - val_loss: 1.9413 - val_accuracy: 0.3824\n",
      "Epoch 257/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5854 - accuracy: 0.4397 - val_loss: 1.9350 - val_accuracy: 0.3971\n",
      "Epoch 258/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.6034 - accuracy: 0.4449 - val_loss: 1.9532 - val_accuracy: 0.3853\n",
      "Epoch 259/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5858 - accuracy: 0.4434 - val_loss: 1.9401 - val_accuracy: 0.3765\n",
      "Epoch 260/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5863 - accuracy: 0.4500 - val_loss: 1.9393 - val_accuracy: 0.3765\n",
      "Epoch 261/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5530 - accuracy: 0.4515 - val_loss: 1.9412 - val_accuracy: 0.3912\n",
      "Epoch 262/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5795 - accuracy: 0.4412 - val_loss: 1.9343 - val_accuracy: 0.3971\n",
      "Epoch 263/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5648 - accuracy: 0.4618 - val_loss: 1.9323 - val_accuracy: 0.3912\n",
      "Epoch 264/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5875 - accuracy: 0.4412 - val_loss: 1.9245 - val_accuracy: 0.3765\n",
      "Epoch 265/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5785 - accuracy: 0.4441 - val_loss: 1.9249 - val_accuracy: 0.3706\n",
      "Epoch 266/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5593 - accuracy: 0.4574 - val_loss: 1.9286 - val_accuracy: 0.3794\n",
      "Epoch 267/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5579 - accuracy: 0.4478 - val_loss: 1.9234 - val_accuracy: 0.3912\n",
      "Epoch 268/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5602 - accuracy: 0.4559 - val_loss: 1.9155 - val_accuracy: 0.3971\n",
      "Epoch 269/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5771 - accuracy: 0.4279 - val_loss: 1.9152 - val_accuracy: 0.3853\n",
      "Epoch 270/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5673 - accuracy: 0.4471 - val_loss: 1.9250 - val_accuracy: 0.3794\n",
      "Epoch 271/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5658 - accuracy: 0.4544 - val_loss: 1.9350 - val_accuracy: 0.3794\n",
      "Epoch 272/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5457 - accuracy: 0.4610 - val_loss: 1.9206 - val_accuracy: 0.3882\n",
      "Epoch 273/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5598 - accuracy: 0.4441 - val_loss: 1.9196 - val_accuracy: 0.3765\n",
      "Epoch 274/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5792 - accuracy: 0.4603 - val_loss: 1.9226 - val_accuracy: 0.3912\n",
      "Epoch 275/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5761 - accuracy: 0.4515 - val_loss: 1.9163 - val_accuracy: 0.4000\n",
      "Epoch 276/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5531 - accuracy: 0.4588 - val_loss: 1.9200 - val_accuracy: 0.3941\n",
      "Epoch 277/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5698 - accuracy: 0.4529 - val_loss: 1.9345 - val_accuracy: 0.3971\n",
      "Epoch 278/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5438 - accuracy: 0.4618 - val_loss: 1.9364 - val_accuracy: 0.3882\n",
      "Epoch 279/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5200 - accuracy: 0.4566 - val_loss: 1.9389 - val_accuracy: 0.4000\n",
      "Epoch 280/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5307 - accuracy: 0.4618 - val_loss: 1.9500 - val_accuracy: 0.3971\n",
      "Epoch 281/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5691 - accuracy: 0.4449 - val_loss: 1.9355 - val_accuracy: 0.3941\n",
      "Epoch 282/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5346 - accuracy: 0.4669 - val_loss: 1.9306 - val_accuracy: 0.4059\n",
      "Epoch 283/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5406 - accuracy: 0.4441 - val_loss: 1.9287 - val_accuracy: 0.4029\n",
      "Epoch 284/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5600 - accuracy: 0.4596 - val_loss: 1.9332 - val_accuracy: 0.4147\n",
      "Epoch 285/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5438 - accuracy: 0.4551 - val_loss: 1.9238 - val_accuracy: 0.3824\n",
      "Epoch 286/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5290 - accuracy: 0.4699 - val_loss: 1.9390 - val_accuracy: 0.3676\n",
      "Epoch 287/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5580 - accuracy: 0.4522 - val_loss: 1.9327 - val_accuracy: 0.3912\n",
      "Epoch 288/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5146 - accuracy: 0.4779 - val_loss: 1.9339 - val_accuracy: 0.4029\n",
      "Epoch 289/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5331 - accuracy: 0.4676 - val_loss: 1.9403 - val_accuracy: 0.3794\n",
      "Epoch 290/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5530 - accuracy: 0.4544 - val_loss: 1.9297 - val_accuracy: 0.3882\n",
      "Epoch 291/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5441 - accuracy: 0.4507 - val_loss: 1.9239 - val_accuracy: 0.3794\n",
      "Epoch 292/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5385 - accuracy: 0.4588 - val_loss: 1.9271 - val_accuracy: 0.3765\n",
      "Epoch 293/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5342 - accuracy: 0.4816 - val_loss: 1.9180 - val_accuracy: 0.3941\n",
      "Epoch 294/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5307 - accuracy: 0.4721 - val_loss: 1.9136 - val_accuracy: 0.3941\n",
      "Epoch 295/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5589 - accuracy: 0.4721 - val_loss: 1.9155 - val_accuracy: 0.3941\n",
      "Epoch 296/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5292 - accuracy: 0.4500 - val_loss: 1.9095 - val_accuracy: 0.3882\n",
      "Epoch 297/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5064 - accuracy: 0.4544 - val_loss: 1.9134 - val_accuracy: 0.4000\n",
      "Epoch 298/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5626 - accuracy: 0.4331 - val_loss: 1.9195 - val_accuracy: 0.3912\n",
      "Epoch 299/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5558 - accuracy: 0.4441 - val_loss: 1.9161 - val_accuracy: 0.3971\n",
      "Epoch 300/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5097 - accuracy: 0.4713 - val_loss: 1.9130 - val_accuracy: 0.4000\n",
      "Epoch 301/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4952 - accuracy: 0.4721 - val_loss: 1.9212 - val_accuracy: 0.4088\n",
      "Epoch 302/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4968 - accuracy: 0.4831 - val_loss: 1.9161 - val_accuracy: 0.4029\n",
      "Epoch 303/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4993 - accuracy: 0.4956 - val_loss: 1.9058 - val_accuracy: 0.4000\n",
      "Epoch 304/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5477 - accuracy: 0.4721 - val_loss: 1.9376 - val_accuracy: 0.3912\n",
      "Epoch 305/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5304 - accuracy: 0.4699 - val_loss: 1.9355 - val_accuracy: 0.4059\n",
      "Epoch 306/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5384 - accuracy: 0.4537 - val_loss: 1.9288 - val_accuracy: 0.4029\n",
      "Epoch 307/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5486 - accuracy: 0.4537 - val_loss: 1.9297 - val_accuracy: 0.4000\n",
      "Epoch 308/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5341 - accuracy: 0.4610 - val_loss: 1.9219 - val_accuracy: 0.3971\n",
      "Epoch 309/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5033 - accuracy: 0.4750 - val_loss: 1.9266 - val_accuracy: 0.4088\n",
      "Epoch 310/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5187 - accuracy: 0.4706 - val_loss: 1.9100 - val_accuracy: 0.4118\n",
      "Epoch 311/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5424 - accuracy: 0.4676 - val_loss: 1.9325 - val_accuracy: 0.4000\n",
      "Epoch 312/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5570 - accuracy: 0.4603 - val_loss: 1.9165 - val_accuracy: 0.4118\n",
      "Epoch 313/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5169 - accuracy: 0.4559 - val_loss: 1.9234 - val_accuracy: 0.3971\n",
      "Epoch 314/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5630 - accuracy: 0.4596 - val_loss: 1.9188 - val_accuracy: 0.4088\n",
      "Epoch 315/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5413 - accuracy: 0.4640 - val_loss: 1.9159 - val_accuracy: 0.4059\n",
      "Epoch 316/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4898 - accuracy: 0.4831 - val_loss: 1.9163 - val_accuracy: 0.3971\n",
      "Epoch 317/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5380 - accuracy: 0.4603 - val_loss: 1.9259 - val_accuracy: 0.4029\n",
      "Epoch 318/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5153 - accuracy: 0.4728 - val_loss: 1.9082 - val_accuracy: 0.4088\n",
      "Epoch 319/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5122 - accuracy: 0.4926 - val_loss: 1.9137 - val_accuracy: 0.4000\n",
      "Epoch 320/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5135 - accuracy: 0.4684 - val_loss: 1.9273 - val_accuracy: 0.4176\n",
      "Epoch 321/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4937 - accuracy: 0.4846 - val_loss: 1.9338 - val_accuracy: 0.4059\n",
      "Epoch 322/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5126 - accuracy: 0.4765 - val_loss: 1.9245 - val_accuracy: 0.4118\n",
      "Epoch 323/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5391 - accuracy: 0.4640 - val_loss: 1.9043 - val_accuracy: 0.4147\n",
      "Epoch 324/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4974 - accuracy: 0.4809 - val_loss: 1.9256 - val_accuracy: 0.4147\n",
      "Epoch 325/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5110 - accuracy: 0.4669 - val_loss: 1.9212 - val_accuracy: 0.4000\n",
      "Epoch 326/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5127 - accuracy: 0.4632 - val_loss: 1.9155 - val_accuracy: 0.4088\n",
      "Epoch 327/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5261 - accuracy: 0.4699 - val_loss: 1.9217 - val_accuracy: 0.4176\n",
      "Epoch 328/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5430 - accuracy: 0.4721 - val_loss: 1.9172 - val_accuracy: 0.4118\n",
      "Epoch 329/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4845 - accuracy: 0.4956 - val_loss: 1.9096 - val_accuracy: 0.4176\n",
      "Epoch 330/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5134 - accuracy: 0.4765 - val_loss: 1.9104 - val_accuracy: 0.4088\n",
      "Epoch 331/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5343 - accuracy: 0.4654 - val_loss: 1.9094 - val_accuracy: 0.4118\n",
      "Epoch 332/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5092 - accuracy: 0.4743 - val_loss: 1.9115 - val_accuracy: 0.4118\n",
      "Epoch 333/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5337 - accuracy: 0.4735 - val_loss: 1.9058 - val_accuracy: 0.4088\n",
      "Epoch 334/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4919 - accuracy: 0.4691 - val_loss: 1.9009 - val_accuracy: 0.4147\n",
      "Epoch 335/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4993 - accuracy: 0.4706 - val_loss: 1.9096 - val_accuracy: 0.4059\n",
      "Epoch 336/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5185 - accuracy: 0.4750 - val_loss: 1.9042 - val_accuracy: 0.4235\n",
      "Epoch 337/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4872 - accuracy: 0.4772 - val_loss: 1.9033 - val_accuracy: 0.4324\n",
      "Epoch 338/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5016 - accuracy: 0.4941 - val_loss: 1.9149 - val_accuracy: 0.4118\n",
      "Epoch 339/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5247 - accuracy: 0.4706 - val_loss: 1.9113 - val_accuracy: 0.4176\n",
      "Epoch 340/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5022 - accuracy: 0.4684 - val_loss: 1.9073 - val_accuracy: 0.4265\n",
      "Epoch 341/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5142 - accuracy: 0.4816 - val_loss: 1.9144 - val_accuracy: 0.4176\n",
      "Epoch 342/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5186 - accuracy: 0.4868 - val_loss: 1.9020 - val_accuracy: 0.4206\n",
      "Epoch 343/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5206 - accuracy: 0.4787 - val_loss: 1.9115 - val_accuracy: 0.4147\n",
      "Epoch 344/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5243 - accuracy: 0.4868 - val_loss: 1.9112 - val_accuracy: 0.4147\n",
      "Epoch 345/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5243 - accuracy: 0.4816 - val_loss: 1.8952 - val_accuracy: 0.4235\n",
      "Epoch 346/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5236 - accuracy: 0.4750 - val_loss: 1.9128 - val_accuracy: 0.4118\n",
      "Epoch 347/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4784 - accuracy: 0.4882 - val_loss: 1.8964 - val_accuracy: 0.4206\n",
      "Epoch 348/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4939 - accuracy: 0.4868 - val_loss: 1.9028 - val_accuracy: 0.4235\n",
      "Epoch 349/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5272 - accuracy: 0.4676 - val_loss: 1.9122 - val_accuracy: 0.4294\n",
      "Epoch 350/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5009 - accuracy: 0.4963 - val_loss: 1.9009 - val_accuracy: 0.4235\n",
      "Epoch 351/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4937 - accuracy: 0.4794 - val_loss: 1.8964 - val_accuracy: 0.4206\n",
      "Epoch 352/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5002 - accuracy: 0.4949 - val_loss: 1.9031 - val_accuracy: 0.4147\n",
      "Epoch 353/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5272 - accuracy: 0.4706 - val_loss: 1.9151 - val_accuracy: 0.4147\n",
      "Epoch 354/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5084 - accuracy: 0.4691 - val_loss: 1.9044 - val_accuracy: 0.4206\n",
      "Epoch 355/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4945 - accuracy: 0.4816 - val_loss: 1.9014 - val_accuracy: 0.4147\n",
      "Epoch 356/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4934 - accuracy: 0.4787 - val_loss: 1.9031 - val_accuracy: 0.4118\n",
      "Epoch 357/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4856 - accuracy: 0.4890 - val_loss: 1.9004 - val_accuracy: 0.4206\n",
      "Epoch 358/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4667 - accuracy: 0.5088 - val_loss: 1.8960 - val_accuracy: 0.4059\n",
      "Epoch 359/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4753 - accuracy: 0.4735 - val_loss: 1.9018 - val_accuracy: 0.4118\n",
      "Epoch 360/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4948 - accuracy: 0.4926 - val_loss: 1.9103 - val_accuracy: 0.4000\n",
      "Epoch 361/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5065 - accuracy: 0.4912 - val_loss: 1.9032 - val_accuracy: 0.4029\n",
      "Epoch 362/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4845 - accuracy: 0.4779 - val_loss: 1.9169 - val_accuracy: 0.4118\n",
      "Epoch 363/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4977 - accuracy: 0.4787 - val_loss: 1.9137 - val_accuracy: 0.4059\n",
      "Epoch 364/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4808 - accuracy: 0.4853 - val_loss: 1.9174 - val_accuracy: 0.4147\n",
      "Epoch 365/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4954 - accuracy: 0.4824 - val_loss: 1.9123 - val_accuracy: 0.4088\n",
      "Epoch 366/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4679 - accuracy: 0.4743 - val_loss: 1.9082 - val_accuracy: 0.4147\n",
      "Epoch 367/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4913 - accuracy: 0.4890 - val_loss: 1.8955 - val_accuracy: 0.4147\n",
      "Epoch 368/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4902 - accuracy: 0.4934 - val_loss: 1.8839 - val_accuracy: 0.4147\n",
      "Epoch 369/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4891 - accuracy: 0.4978 - val_loss: 1.8817 - val_accuracy: 0.4088\n",
      "Epoch 370/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5136 - accuracy: 0.4640 - val_loss: 1.9046 - val_accuracy: 0.4088\n",
      "Epoch 371/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5152 - accuracy: 0.4765 - val_loss: 1.9091 - val_accuracy: 0.4176\n",
      "Epoch 372/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4619 - accuracy: 0.4963 - val_loss: 1.9071 - val_accuracy: 0.4176\n",
      "Epoch 373/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4781 - accuracy: 0.4868 - val_loss: 1.9017 - val_accuracy: 0.4176\n",
      "Epoch 374/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4660 - accuracy: 0.4904 - val_loss: 1.9070 - val_accuracy: 0.4059\n",
      "Epoch 375/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4890 - accuracy: 0.4838 - val_loss: 1.9058 - val_accuracy: 0.4147\n",
      "Epoch 376/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4854 - accuracy: 0.4853 - val_loss: 1.9057 - val_accuracy: 0.4029\n",
      "Epoch 377/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4788 - accuracy: 0.4846 - val_loss: 1.9110 - val_accuracy: 0.4088\n",
      "Epoch 378/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4582 - accuracy: 0.4919 - val_loss: 1.9035 - val_accuracy: 0.4088\n",
      "Epoch 379/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4749 - accuracy: 0.4934 - val_loss: 1.8991 - val_accuracy: 0.4118\n",
      "Epoch 380/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4770 - accuracy: 0.4816 - val_loss: 1.8983 - val_accuracy: 0.4088\n",
      "Epoch 381/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5092 - accuracy: 0.4728 - val_loss: 1.9118 - val_accuracy: 0.4059\n",
      "Epoch 382/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4726 - accuracy: 0.4779 - val_loss: 1.9143 - val_accuracy: 0.4059\n",
      "Epoch 383/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4980 - accuracy: 0.4890 - val_loss: 1.8993 - val_accuracy: 0.4147\n",
      "Epoch 384/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4952 - accuracy: 0.4904 - val_loss: 1.8943 - val_accuracy: 0.4059\n",
      "Epoch 385/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4653 - accuracy: 0.4949 - val_loss: 1.9046 - val_accuracy: 0.4118\n",
      "Epoch 386/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4701 - accuracy: 0.4838 - val_loss: 1.8984 - val_accuracy: 0.4147\n",
      "Epoch 387/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4510 - accuracy: 0.5044 - val_loss: 1.8957 - val_accuracy: 0.4059\n",
      "Epoch 388/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4446 - accuracy: 0.4904 - val_loss: 1.8890 - val_accuracy: 0.3971\n",
      "Epoch 389/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4725 - accuracy: 0.4963 - val_loss: 1.8961 - val_accuracy: 0.4059\n",
      "Epoch 390/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4448 - accuracy: 0.4949 - val_loss: 1.8885 - val_accuracy: 0.3971\n",
      "Epoch 391/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4278 - accuracy: 0.5051 - val_loss: 1.9067 - val_accuracy: 0.4118\n",
      "Epoch 392/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4668 - accuracy: 0.5118 - val_loss: 1.9065 - val_accuracy: 0.4176\n",
      "Epoch 393/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4409 - accuracy: 0.4934 - val_loss: 1.9124 - val_accuracy: 0.4118\n",
      "Epoch 394/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4273 - accuracy: 0.4779 - val_loss: 1.9031 - val_accuracy: 0.4206\n",
      "Epoch 395/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4472 - accuracy: 0.4919 - val_loss: 1.9120 - val_accuracy: 0.4088\n",
      "Epoch 396/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4506 - accuracy: 0.4853 - val_loss: 1.8989 - val_accuracy: 0.4324\n",
      "Epoch 397/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4441 - accuracy: 0.4926 - val_loss: 1.8834 - val_accuracy: 0.4176\n",
      "Epoch 398/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4250 - accuracy: 0.4978 - val_loss: 1.8906 - val_accuracy: 0.4000\n",
      "Epoch 399/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5024 - accuracy: 0.4713 - val_loss: 1.8878 - val_accuracy: 0.4147\n",
      "Epoch 400/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4448 - accuracy: 0.4801 - val_loss: 1.8860 - val_accuracy: 0.4118\n",
      "Epoch 401/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4821 - accuracy: 0.4816 - val_loss: 1.8906 - val_accuracy: 0.4088\n",
      "Epoch 402/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4666 - accuracy: 0.5037 - val_loss: 1.8934 - val_accuracy: 0.4235\n",
      "Epoch 403/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4580 - accuracy: 0.4853 - val_loss: 1.8887 - val_accuracy: 0.4147\n",
      "Epoch 404/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4831 - accuracy: 0.4890 - val_loss: 1.8783 - val_accuracy: 0.4265\n",
      "Epoch 405/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4613 - accuracy: 0.5022 - val_loss: 1.8979 - val_accuracy: 0.4176\n",
      "Epoch 406/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4527 - accuracy: 0.4949 - val_loss: 1.8947 - val_accuracy: 0.4147\n",
      "Epoch 407/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4428 - accuracy: 0.5022 - val_loss: 1.8944 - val_accuracy: 0.4147\n",
      "Epoch 408/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4423 - accuracy: 0.4978 - val_loss: 1.8803 - val_accuracy: 0.4147\n",
      "Epoch 409/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4537 - accuracy: 0.4971 - val_loss: 1.8796 - val_accuracy: 0.4088\n",
      "Epoch 410/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4157 - accuracy: 0.4971 - val_loss: 1.8713 - val_accuracy: 0.4118\n",
      "Epoch 411/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4227 - accuracy: 0.5110 - val_loss: 1.8712 - val_accuracy: 0.4235\n",
      "Epoch 412/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4384 - accuracy: 0.5007 - val_loss: 1.8654 - val_accuracy: 0.4206\n",
      "Epoch 413/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4619 - accuracy: 0.4897 - val_loss: 1.8864 - val_accuracy: 0.4235\n",
      "Epoch 414/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4670 - accuracy: 0.4993 - val_loss: 1.8878 - val_accuracy: 0.4176\n",
      "Epoch 415/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4181 - accuracy: 0.5051 - val_loss: 1.8847 - val_accuracy: 0.4059\n",
      "Epoch 416/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4841 - accuracy: 0.4713 - val_loss: 1.9032 - val_accuracy: 0.4147\n",
      "Epoch 417/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4707 - accuracy: 0.4941 - val_loss: 1.8982 - val_accuracy: 0.4147\n",
      "Epoch 418/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4830 - accuracy: 0.4971 - val_loss: 1.8880 - val_accuracy: 0.4029\n",
      "Epoch 419/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4516 - accuracy: 0.5096 - val_loss: 1.8968 - val_accuracy: 0.4206\n",
      "Epoch 420/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4497 - accuracy: 0.4956 - val_loss: 1.8922 - val_accuracy: 0.4294\n",
      "Epoch 421/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4527 - accuracy: 0.4904 - val_loss: 1.8837 - val_accuracy: 0.4324\n",
      "Epoch 422/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4011 - accuracy: 0.5118 - val_loss: 1.8898 - val_accuracy: 0.4176\n",
      "Epoch 423/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4717 - accuracy: 0.4860 - val_loss: 1.8989 - val_accuracy: 0.4235\n",
      "Epoch 424/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4520 - accuracy: 0.4993 - val_loss: 1.8863 - val_accuracy: 0.4412\n",
      "Epoch 425/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4462 - accuracy: 0.5066 - val_loss: 1.8733 - val_accuracy: 0.4382\n",
      "Epoch 426/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4211 - accuracy: 0.5235 - val_loss: 1.8773 - val_accuracy: 0.4265\n",
      "Epoch 427/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4801 - accuracy: 0.4691 - val_loss: 1.8803 - val_accuracy: 0.4206\n",
      "Epoch 428/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4079 - accuracy: 0.5103 - val_loss: 1.8947 - val_accuracy: 0.4294\n",
      "Epoch 429/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4833 - accuracy: 0.4846 - val_loss: 1.8988 - val_accuracy: 0.4235\n",
      "Epoch 430/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4164 - accuracy: 0.5125 - val_loss: 1.9029 - val_accuracy: 0.4235\n",
      "Epoch 431/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4499 - accuracy: 0.5103 - val_loss: 1.8959 - val_accuracy: 0.4294\n",
      "Epoch 432/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4271 - accuracy: 0.4926 - val_loss: 1.8821 - val_accuracy: 0.4294\n",
      "Epoch 433/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4070 - accuracy: 0.5044 - val_loss: 1.8787 - val_accuracy: 0.4176\n",
      "Epoch 434/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4113 - accuracy: 0.5066 - val_loss: 1.8859 - val_accuracy: 0.4029\n",
      "Epoch 435/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4252 - accuracy: 0.4853 - val_loss: 1.8780 - val_accuracy: 0.4176\n",
      "Epoch 436/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4326 - accuracy: 0.4963 - val_loss: 1.8812 - val_accuracy: 0.4324\n",
      "Epoch 437/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4413 - accuracy: 0.5081 - val_loss: 1.8790 - val_accuracy: 0.4235\n",
      "Epoch 438/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4414 - accuracy: 0.5213 - val_loss: 1.8722 - val_accuracy: 0.4265\n",
      "Epoch 439/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4436 - accuracy: 0.4971 - val_loss: 1.8746 - val_accuracy: 0.4235\n",
      "Epoch 440/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4438 - accuracy: 0.5074 - val_loss: 1.8691 - val_accuracy: 0.4235\n",
      "Epoch 441/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4541 - accuracy: 0.4882 - val_loss: 1.8907 - val_accuracy: 0.4265\n",
      "Epoch 442/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4247 - accuracy: 0.5066 - val_loss: 1.8653 - val_accuracy: 0.4412\n",
      "Epoch 443/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4064 - accuracy: 0.5279 - val_loss: 1.8798 - val_accuracy: 0.4353\n",
      "Epoch 444/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4405 - accuracy: 0.4824 - val_loss: 1.8806 - val_accuracy: 0.4353\n",
      "Epoch 445/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4339 - accuracy: 0.4978 - val_loss: 1.8965 - val_accuracy: 0.4235\n",
      "Epoch 446/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4383 - accuracy: 0.5022 - val_loss: 1.8885 - val_accuracy: 0.4353\n",
      "Epoch 447/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4242 - accuracy: 0.5162 - val_loss: 1.8830 - val_accuracy: 0.4382\n",
      "Epoch 448/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4612 - accuracy: 0.4875 - val_loss: 1.8894 - val_accuracy: 0.4294\n",
      "Epoch 449/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4157 - accuracy: 0.4993 - val_loss: 1.8981 - val_accuracy: 0.4441\n",
      "Epoch 450/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4277 - accuracy: 0.5037 - val_loss: 1.8890 - val_accuracy: 0.4353\n",
      "Epoch 451/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4125 - accuracy: 0.5007 - val_loss: 1.8727 - val_accuracy: 0.4294\n",
      "Epoch 452/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.5004 - accuracy: 0.4978 - val_loss: 1.8769 - val_accuracy: 0.4324\n",
      "Epoch 453/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4700 - accuracy: 0.4978 - val_loss: 1.8833 - val_accuracy: 0.4235\n",
      "Epoch 454/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4206 - accuracy: 0.5007 - val_loss: 1.8723 - val_accuracy: 0.4176\n",
      "Epoch 455/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4219 - accuracy: 0.5235 - val_loss: 1.8754 - val_accuracy: 0.4324\n",
      "Epoch 456/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4162 - accuracy: 0.5037 - val_loss: 1.8767 - val_accuracy: 0.4353\n",
      "Epoch 457/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4451 - accuracy: 0.5059 - val_loss: 1.8841 - val_accuracy: 0.4353\n",
      "Epoch 458/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4448 - accuracy: 0.5169 - val_loss: 1.8820 - val_accuracy: 0.4265\n",
      "Epoch 459/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4460 - accuracy: 0.4956 - val_loss: 1.8761 - val_accuracy: 0.4382\n",
      "Epoch 460/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3991 - accuracy: 0.5029 - val_loss: 1.8916 - val_accuracy: 0.4382\n",
      "Epoch 461/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4455 - accuracy: 0.4934 - val_loss: 1.8783 - val_accuracy: 0.4353\n",
      "Epoch 462/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4431 - accuracy: 0.5125 - val_loss: 1.8900 - val_accuracy: 0.4353\n",
      "Epoch 463/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4358 - accuracy: 0.4904 - val_loss: 1.8934 - val_accuracy: 0.4265\n",
      "Epoch 464/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4567 - accuracy: 0.4853 - val_loss: 1.9085 - val_accuracy: 0.4471\n",
      "Epoch 465/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4105 - accuracy: 0.5250 - val_loss: 1.9173 - val_accuracy: 0.4353\n",
      "Epoch 466/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4042 - accuracy: 0.5029 - val_loss: 1.9119 - val_accuracy: 0.4353\n",
      "Epoch 467/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4323 - accuracy: 0.5294 - val_loss: 1.9101 - val_accuracy: 0.4294\n",
      "Epoch 468/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4201 - accuracy: 0.5176 - val_loss: 1.9005 - val_accuracy: 0.4235\n",
      "Epoch 469/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4020 - accuracy: 0.4985 - val_loss: 1.9051 - val_accuracy: 0.4294\n",
      "Epoch 470/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4162 - accuracy: 0.5331 - val_loss: 1.9162 - val_accuracy: 0.4206\n",
      "Epoch 471/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4851 - accuracy: 0.4853 - val_loss: 1.9067 - val_accuracy: 0.4147\n",
      "Epoch 472/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3836 - accuracy: 0.5301 - val_loss: 1.9162 - val_accuracy: 0.4147\n",
      "Epoch 473/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4051 - accuracy: 0.5140 - val_loss: 1.9057 - val_accuracy: 0.4294\n",
      "Epoch 474/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4420 - accuracy: 0.4985 - val_loss: 1.9024 - val_accuracy: 0.4353\n",
      "Epoch 475/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4305 - accuracy: 0.5199 - val_loss: 1.8865 - val_accuracy: 0.4294\n",
      "Epoch 476/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4071 - accuracy: 0.5074 - val_loss: 1.8861 - val_accuracy: 0.4324\n",
      "Epoch 477/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4151 - accuracy: 0.5081 - val_loss: 1.8993 - val_accuracy: 0.4324\n",
      "Epoch 478/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4014 - accuracy: 0.5250 - val_loss: 1.8967 - val_accuracy: 0.4353\n",
      "Epoch 479/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4438 - accuracy: 0.5118 - val_loss: 1.9039 - val_accuracy: 0.4294\n",
      "Epoch 480/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4278 - accuracy: 0.4993 - val_loss: 1.8926 - val_accuracy: 0.4235\n",
      "Epoch 481/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4043 - accuracy: 0.5132 - val_loss: 1.9030 - val_accuracy: 0.4353\n",
      "Epoch 482/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3913 - accuracy: 0.5169 - val_loss: 1.9106 - val_accuracy: 0.4176\n",
      "Epoch 483/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4199 - accuracy: 0.5015 - val_loss: 1.9207 - val_accuracy: 0.4324\n",
      "Epoch 484/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.4046 - accuracy: 0.5118 - val_loss: 1.9025 - val_accuracy: 0.4353\n",
      "Epoch 485/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4175 - accuracy: 0.5103 - val_loss: 1.8866 - val_accuracy: 0.4412\n",
      "Epoch 486/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4186 - accuracy: 0.5294 - val_loss: 1.8863 - val_accuracy: 0.4265\n",
      "Epoch 487/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3687 - accuracy: 0.5397 - val_loss: 1.9092 - val_accuracy: 0.4412\n",
      "Epoch 488/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4251 - accuracy: 0.5059 - val_loss: 1.9017 - val_accuracy: 0.4441\n",
      "Epoch 489/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4088 - accuracy: 0.5154 - val_loss: 1.8783 - val_accuracy: 0.4382\n",
      "Epoch 490/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3934 - accuracy: 0.5154 - val_loss: 1.8833 - val_accuracy: 0.4324\n",
      "Epoch 491/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3981 - accuracy: 0.5066 - val_loss: 1.8684 - val_accuracy: 0.4324\n",
      "Epoch 492/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3994 - accuracy: 0.5206 - val_loss: 1.8907 - val_accuracy: 0.4382\n",
      "Epoch 493/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3952 - accuracy: 0.5132 - val_loss: 1.9055 - val_accuracy: 0.4324\n",
      "Epoch 494/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3783 - accuracy: 0.5272 - val_loss: 1.9045 - val_accuracy: 0.4176\n",
      "Epoch 495/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4070 - accuracy: 0.5066 - val_loss: 1.8794 - val_accuracy: 0.4265\n",
      "Epoch 496/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4116 - accuracy: 0.5066 - val_loss: 1.8805 - val_accuracy: 0.4265\n",
      "Epoch 497/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4071 - accuracy: 0.5103 - val_loss: 1.8843 - val_accuracy: 0.4206\n",
      "Epoch 498/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3715 - accuracy: 0.5206 - val_loss: 1.8904 - val_accuracy: 0.4353\n",
      "Epoch 499/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3786 - accuracy: 0.5199 - val_loss: 1.9012 - val_accuracy: 0.4353\n",
      "Epoch 500/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4339 - accuracy: 0.5088 - val_loss: 1.9036 - val_accuracy: 0.4265\n",
      "Epoch 501/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4004 - accuracy: 0.5265 - val_loss: 1.8851 - val_accuracy: 0.4382\n",
      "Epoch 502/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3921 - accuracy: 0.5088 - val_loss: 1.8878 - val_accuracy: 0.4324\n",
      "Epoch 503/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3794 - accuracy: 0.5162 - val_loss: 1.8843 - val_accuracy: 0.4294\n",
      "Epoch 504/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3996 - accuracy: 0.5206 - val_loss: 1.8995 - val_accuracy: 0.4353\n",
      "Epoch 505/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3932 - accuracy: 0.5250 - val_loss: 1.8761 - val_accuracy: 0.4294\n",
      "Epoch 506/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3876 - accuracy: 0.5118 - val_loss: 1.8743 - val_accuracy: 0.4353\n",
      "Epoch 507/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4130 - accuracy: 0.5147 - val_loss: 1.8849 - val_accuracy: 0.4412\n",
      "Epoch 508/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.4188 - accuracy: 0.4949 - val_loss: 1.8838 - val_accuracy: 0.4353\n",
      "Epoch 509/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4151 - accuracy: 0.5154 - val_loss: 1.8811 - val_accuracy: 0.4324\n",
      "Epoch 510/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3951 - accuracy: 0.5015 - val_loss: 1.8937 - val_accuracy: 0.4206\n",
      "Epoch 511/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3985 - accuracy: 0.5103 - val_loss: 1.9017 - val_accuracy: 0.4265\n",
      "Epoch 512/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3777 - accuracy: 0.5265 - val_loss: 1.9027 - val_accuracy: 0.4382\n",
      "Epoch 513/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4058 - accuracy: 0.5074 - val_loss: 1.8866 - val_accuracy: 0.4206\n",
      "Epoch 514/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3545 - accuracy: 0.5338 - val_loss: 1.8959 - val_accuracy: 0.4176\n",
      "Epoch 515/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3501 - accuracy: 0.5301 - val_loss: 1.8978 - val_accuracy: 0.4206\n",
      "Epoch 516/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3978 - accuracy: 0.5022 - val_loss: 1.9006 - val_accuracy: 0.4206\n",
      "Epoch 517/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3779 - accuracy: 0.5154 - val_loss: 1.8933 - val_accuracy: 0.4176\n",
      "Epoch 518/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3612 - accuracy: 0.5368 - val_loss: 1.8973 - val_accuracy: 0.4206\n",
      "Epoch 519/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3685 - accuracy: 0.5449 - val_loss: 1.8939 - val_accuracy: 0.4176\n",
      "Epoch 520/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3986 - accuracy: 0.5221 - val_loss: 1.8859 - val_accuracy: 0.4147\n",
      "Epoch 521/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3980 - accuracy: 0.5059 - val_loss: 1.9081 - val_accuracy: 0.4088\n",
      "Epoch 522/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4202 - accuracy: 0.5103 - val_loss: 1.8973 - val_accuracy: 0.4265\n",
      "Epoch 523/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4009 - accuracy: 0.5066 - val_loss: 1.8926 - val_accuracy: 0.4265\n",
      "Epoch 524/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3770 - accuracy: 0.5132 - val_loss: 1.8827 - val_accuracy: 0.4088\n",
      "Epoch 525/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4185 - accuracy: 0.5074 - val_loss: 1.8675 - val_accuracy: 0.4176\n",
      "Epoch 526/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4051 - accuracy: 0.5081 - val_loss: 1.8689 - val_accuracy: 0.4118\n",
      "Epoch 527/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3950 - accuracy: 0.5110 - val_loss: 1.8759 - val_accuracy: 0.4118\n",
      "Epoch 528/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4247 - accuracy: 0.5074 - val_loss: 1.8867 - val_accuracy: 0.4176\n",
      "Epoch 529/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4217 - accuracy: 0.5191 - val_loss: 1.8872 - val_accuracy: 0.4147\n",
      "Epoch 530/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3749 - accuracy: 0.5243 - val_loss: 1.8870 - val_accuracy: 0.4088\n",
      "Epoch 531/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3919 - accuracy: 0.5125 - val_loss: 1.8850 - val_accuracy: 0.4118\n",
      "Epoch 532/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4286 - accuracy: 0.5000 - val_loss: 1.8819 - val_accuracy: 0.4176\n",
      "Epoch 533/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3945 - accuracy: 0.5279 - val_loss: 1.9031 - val_accuracy: 0.4059\n",
      "Epoch 534/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4289 - accuracy: 0.5037 - val_loss: 1.9063 - val_accuracy: 0.4147\n",
      "Epoch 535/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3459 - accuracy: 0.5162 - val_loss: 1.9048 - val_accuracy: 0.4235\n",
      "Epoch 536/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3614 - accuracy: 0.5449 - val_loss: 1.9118 - val_accuracy: 0.4294\n",
      "Epoch 537/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3698 - accuracy: 0.5287 - val_loss: 1.9153 - val_accuracy: 0.4265\n",
      "Epoch 538/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3791 - accuracy: 0.5081 - val_loss: 1.9191 - val_accuracy: 0.4265\n",
      "Epoch 539/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4460 - accuracy: 0.5154 - val_loss: 1.8982 - val_accuracy: 0.4265\n",
      "Epoch 540/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4282 - accuracy: 0.5162 - val_loss: 1.8975 - val_accuracy: 0.4324\n",
      "Epoch 541/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3919 - accuracy: 0.5162 - val_loss: 1.9057 - val_accuracy: 0.4118\n",
      "Epoch 542/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3849 - accuracy: 0.5221 - val_loss: 1.9073 - val_accuracy: 0.4176\n",
      "Epoch 543/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3919 - accuracy: 0.5213 - val_loss: 1.9082 - val_accuracy: 0.4147\n",
      "Epoch 544/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3772 - accuracy: 0.5243 - val_loss: 1.8994 - val_accuracy: 0.4118\n",
      "Epoch 545/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4019 - accuracy: 0.5265 - val_loss: 1.9079 - val_accuracy: 0.4088\n",
      "Epoch 546/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3916 - accuracy: 0.5316 - val_loss: 1.9351 - val_accuracy: 0.4147\n",
      "Epoch 547/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3769 - accuracy: 0.5235 - val_loss: 1.9365 - val_accuracy: 0.4206\n",
      "Epoch 548/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4148 - accuracy: 0.5081 - val_loss: 1.9190 - val_accuracy: 0.4235\n",
      "Epoch 549/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3751 - accuracy: 0.5081 - val_loss: 1.9059 - val_accuracy: 0.4265\n",
      "Epoch 550/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3854 - accuracy: 0.5132 - val_loss: 1.9016 - val_accuracy: 0.4382\n",
      "Epoch 551/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3804 - accuracy: 0.5191 - val_loss: 1.9021 - val_accuracy: 0.4265\n",
      "Epoch 552/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3867 - accuracy: 0.5213 - val_loss: 1.9198 - val_accuracy: 0.4324\n",
      "Epoch 553/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3740 - accuracy: 0.5140 - val_loss: 1.9236 - val_accuracy: 0.4176\n",
      "Epoch 554/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3471 - accuracy: 0.5507 - val_loss: 1.9102 - val_accuracy: 0.4176\n",
      "Epoch 555/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3657 - accuracy: 0.5309 - val_loss: 1.9159 - val_accuracy: 0.4206\n",
      "Epoch 556/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3792 - accuracy: 0.5132 - val_loss: 1.9009 - val_accuracy: 0.4206\n",
      "Epoch 557/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3940 - accuracy: 0.5074 - val_loss: 1.9044 - val_accuracy: 0.4206\n",
      "Epoch 558/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3784 - accuracy: 0.5206 - val_loss: 1.9019 - val_accuracy: 0.4235\n",
      "Epoch 559/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4097 - accuracy: 0.5154 - val_loss: 1.8909 - val_accuracy: 0.4324\n",
      "Epoch 560/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3626 - accuracy: 0.5368 - val_loss: 1.8971 - val_accuracy: 0.4294\n",
      "Epoch 561/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3825 - accuracy: 0.5147 - val_loss: 1.9055 - val_accuracy: 0.4294\n",
      "Epoch 562/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3902 - accuracy: 0.5191 - val_loss: 1.9033 - val_accuracy: 0.4382\n",
      "Epoch 563/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3393 - accuracy: 0.5419 - val_loss: 1.8895 - val_accuracy: 0.4324\n",
      "Epoch 564/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3527 - accuracy: 0.5485 - val_loss: 1.8813 - val_accuracy: 0.4353\n",
      "Epoch 565/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3521 - accuracy: 0.5243 - val_loss: 1.8915 - val_accuracy: 0.4382\n",
      "Epoch 566/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3639 - accuracy: 0.5213 - val_loss: 1.9065 - val_accuracy: 0.4382\n",
      "Epoch 567/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4623 - accuracy: 0.5184 - val_loss: 1.9055 - val_accuracy: 0.4324\n",
      "Epoch 568/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3727 - accuracy: 0.5221 - val_loss: 1.8874 - val_accuracy: 0.4353\n",
      "Epoch 569/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3683 - accuracy: 0.5118 - val_loss: 1.9082 - val_accuracy: 0.4382\n",
      "Epoch 570/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3489 - accuracy: 0.5368 - val_loss: 1.8947 - val_accuracy: 0.4324\n",
      "Epoch 571/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3773 - accuracy: 0.5191 - val_loss: 1.9018 - val_accuracy: 0.4294\n",
      "Epoch 572/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3766 - accuracy: 0.5176 - val_loss: 1.9013 - val_accuracy: 0.4353\n",
      "Epoch 573/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3974 - accuracy: 0.5162 - val_loss: 1.9016 - val_accuracy: 0.4382\n",
      "Epoch 574/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3535 - accuracy: 0.5338 - val_loss: 1.8953 - val_accuracy: 0.4324\n",
      "Epoch 575/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3591 - accuracy: 0.5412 - val_loss: 1.8872 - val_accuracy: 0.4294\n",
      "Epoch 576/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3368 - accuracy: 0.5125 - val_loss: 1.8971 - val_accuracy: 0.4176\n",
      "Epoch 577/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4149 - accuracy: 0.5199 - val_loss: 1.9029 - val_accuracy: 0.4382\n",
      "Epoch 578/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3777 - accuracy: 0.5140 - val_loss: 1.8931 - val_accuracy: 0.4206\n",
      "Epoch 579/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3729 - accuracy: 0.5051 - val_loss: 1.8950 - val_accuracy: 0.4206\n",
      "Epoch 580/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4459 - accuracy: 0.5125 - val_loss: 1.8852 - val_accuracy: 0.4176\n",
      "Epoch 581/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3634 - accuracy: 0.5287 - val_loss: 1.8938 - val_accuracy: 0.4206\n",
      "Epoch 582/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3455 - accuracy: 0.5272 - val_loss: 1.8890 - val_accuracy: 0.4382\n",
      "Epoch 583/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3532 - accuracy: 0.5279 - val_loss: 1.9073 - val_accuracy: 0.4294\n",
      "Epoch 584/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3933 - accuracy: 0.5096 - val_loss: 1.9086 - val_accuracy: 0.4206\n",
      "Epoch 585/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3861 - accuracy: 0.5066 - val_loss: 1.8955 - val_accuracy: 0.4324\n",
      "Epoch 586/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3289 - accuracy: 0.5368 - val_loss: 1.9016 - val_accuracy: 0.4206\n",
      "Epoch 587/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3413 - accuracy: 0.5404 - val_loss: 1.8912 - val_accuracy: 0.4294\n",
      "Epoch 588/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3231 - accuracy: 0.5478 - val_loss: 1.9039 - val_accuracy: 0.4265\n",
      "Epoch 589/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3686 - accuracy: 0.5250 - val_loss: 1.9001 - val_accuracy: 0.4265\n",
      "Epoch 590/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3784 - accuracy: 0.5375 - val_loss: 1.8924 - val_accuracy: 0.4206\n",
      "Epoch 591/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3295 - accuracy: 0.5360 - val_loss: 1.8884 - val_accuracy: 0.4176\n",
      "Epoch 592/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3215 - accuracy: 0.5397 - val_loss: 1.8985 - val_accuracy: 0.4176\n",
      "Epoch 593/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3382 - accuracy: 0.5353 - val_loss: 1.8963 - val_accuracy: 0.4382\n",
      "Epoch 594/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3489 - accuracy: 0.5235 - val_loss: 1.8903 - val_accuracy: 0.4294\n",
      "Epoch 595/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3724 - accuracy: 0.5265 - val_loss: 1.8967 - val_accuracy: 0.4235\n",
      "Epoch 596/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3315 - accuracy: 0.5404 - val_loss: 1.8925 - val_accuracy: 0.4265\n",
      "Epoch 597/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3642 - accuracy: 0.5191 - val_loss: 1.8980 - val_accuracy: 0.4324\n",
      "Epoch 598/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3871 - accuracy: 0.5301 - val_loss: 1.9025 - val_accuracy: 0.4235\n",
      "Epoch 599/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3590 - accuracy: 0.5324 - val_loss: 1.8815 - val_accuracy: 0.4324\n",
      "Epoch 600/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3453 - accuracy: 0.5368 - val_loss: 1.8830 - val_accuracy: 0.4412\n",
      "Epoch 601/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3412 - accuracy: 0.5375 - val_loss: 1.8781 - val_accuracy: 0.4471\n",
      "Epoch 602/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3632 - accuracy: 0.5235 - val_loss: 1.8788 - val_accuracy: 0.4412\n",
      "Epoch 603/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4118 - accuracy: 0.5147 - val_loss: 1.8911 - val_accuracy: 0.4147\n",
      "Epoch 604/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3708 - accuracy: 0.5169 - val_loss: 1.8860 - val_accuracy: 0.4294\n",
      "Epoch 605/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3655 - accuracy: 0.5331 - val_loss: 1.8961 - val_accuracy: 0.4235\n",
      "Epoch 606/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3783 - accuracy: 0.5213 - val_loss: 1.8988 - val_accuracy: 0.4118\n",
      "Epoch 607/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3457 - accuracy: 0.5199 - val_loss: 1.8858 - val_accuracy: 0.4265\n",
      "Epoch 608/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3521 - accuracy: 0.5294 - val_loss: 1.8834 - val_accuracy: 0.4235\n",
      "Epoch 609/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3568 - accuracy: 0.5309 - val_loss: 1.8864 - val_accuracy: 0.4206\n",
      "Epoch 610/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3567 - accuracy: 0.5382 - val_loss: 1.8653 - val_accuracy: 0.4235\n",
      "Epoch 611/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3543 - accuracy: 0.5110 - val_loss: 1.8703 - val_accuracy: 0.4235\n",
      "Epoch 612/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3458 - accuracy: 0.5368 - val_loss: 1.8771 - val_accuracy: 0.4412\n",
      "Epoch 613/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3591 - accuracy: 0.5294 - val_loss: 1.8826 - val_accuracy: 0.4265\n",
      "Epoch 614/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3130 - accuracy: 0.5654 - val_loss: 1.8797 - val_accuracy: 0.4324\n",
      "Epoch 615/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3261 - accuracy: 0.5316 - val_loss: 1.8859 - val_accuracy: 0.4324\n",
      "Epoch 616/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3311 - accuracy: 0.5419 - val_loss: 1.8871 - val_accuracy: 0.4382\n",
      "Epoch 617/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3453 - accuracy: 0.5346 - val_loss: 1.8907 - val_accuracy: 0.4382\n",
      "Epoch 618/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3299 - accuracy: 0.5257 - val_loss: 1.8935 - val_accuracy: 0.4265\n",
      "Epoch 619/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3497 - accuracy: 0.5213 - val_loss: 1.8958 - val_accuracy: 0.4412\n",
      "Epoch 620/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3762 - accuracy: 0.5287 - val_loss: 1.8952 - val_accuracy: 0.4235\n",
      "Epoch 621/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3287 - accuracy: 0.5368 - val_loss: 1.8967 - val_accuracy: 0.4206\n",
      "Epoch 622/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3361 - accuracy: 0.5434 - val_loss: 1.8956 - val_accuracy: 0.4294\n",
      "Epoch 623/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3463 - accuracy: 0.5191 - val_loss: 1.8903 - val_accuracy: 0.4324\n",
      "Epoch 624/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3253 - accuracy: 0.5316 - val_loss: 1.8843 - val_accuracy: 0.4294\n",
      "Epoch 625/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3459 - accuracy: 0.5331 - val_loss: 1.8987 - val_accuracy: 0.4382\n",
      "Epoch 626/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3930 - accuracy: 0.5221 - val_loss: 1.8907 - val_accuracy: 0.4353\n",
      "Epoch 627/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2961 - accuracy: 0.5515 - val_loss: 1.8961 - val_accuracy: 0.4382\n",
      "Epoch 628/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3360 - accuracy: 0.5419 - val_loss: 1.9086 - val_accuracy: 0.4412\n",
      "Epoch 629/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3546 - accuracy: 0.5346 - val_loss: 1.9062 - val_accuracy: 0.4294\n",
      "Epoch 630/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3607 - accuracy: 0.5375 - val_loss: 1.9050 - val_accuracy: 0.4294\n",
      "Epoch 631/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4139 - accuracy: 0.5110 - val_loss: 1.9038 - val_accuracy: 0.4324\n",
      "Epoch 632/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3196 - accuracy: 0.5353 - val_loss: 1.9237 - val_accuracy: 0.4265\n",
      "Epoch 633/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3628 - accuracy: 0.5360 - val_loss: 1.9089 - val_accuracy: 0.4294\n",
      "Epoch 634/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3865 - accuracy: 0.5066 - val_loss: 1.9031 - val_accuracy: 0.4382\n",
      "Epoch 635/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3452 - accuracy: 0.5301 - val_loss: 1.9083 - val_accuracy: 0.4412\n",
      "Epoch 636/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3386 - accuracy: 0.5331 - val_loss: 1.9134 - val_accuracy: 0.4353\n",
      "Epoch 637/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3334 - accuracy: 0.5243 - val_loss: 1.9210 - val_accuracy: 0.4324\n",
      "Epoch 638/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3729 - accuracy: 0.5199 - val_loss: 1.8972 - val_accuracy: 0.4441\n",
      "Epoch 639/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3618 - accuracy: 0.5419 - val_loss: 1.9085 - val_accuracy: 0.4294\n",
      "Epoch 640/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3182 - accuracy: 0.5478 - val_loss: 1.9019 - val_accuracy: 0.4324\n",
      "Epoch 641/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3314 - accuracy: 0.5375 - val_loss: 1.9100 - val_accuracy: 0.4412\n",
      "Epoch 642/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3744 - accuracy: 0.5309 - val_loss: 1.9132 - val_accuracy: 0.4324\n",
      "Epoch 643/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3456 - accuracy: 0.5257 - val_loss: 1.8953 - val_accuracy: 0.4412\n",
      "Epoch 644/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3370 - accuracy: 0.5272 - val_loss: 1.9037 - val_accuracy: 0.4382\n",
      "Epoch 645/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2945 - accuracy: 0.5618 - val_loss: 1.9135 - val_accuracy: 0.4176\n",
      "Epoch 646/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3168 - accuracy: 0.5243 - val_loss: 1.9223 - val_accuracy: 0.4294\n",
      "Epoch 647/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3495 - accuracy: 0.5309 - val_loss: 1.9192 - val_accuracy: 0.4235\n",
      "Epoch 648/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3743 - accuracy: 0.5103 - val_loss: 1.9119 - val_accuracy: 0.4265\n",
      "Epoch 649/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3343 - accuracy: 0.5441 - val_loss: 1.9185 - val_accuracy: 0.4235\n",
      "Epoch 650/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3311 - accuracy: 0.5574 - val_loss: 1.9017 - val_accuracy: 0.4412\n",
      "Epoch 651/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3405 - accuracy: 0.5404 - val_loss: 1.9164 - val_accuracy: 0.4353\n",
      "Epoch 652/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3361 - accuracy: 0.5390 - val_loss: 1.9100 - val_accuracy: 0.4324\n",
      "Epoch 653/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3382 - accuracy: 0.5331 - val_loss: 1.9214 - val_accuracy: 0.4206\n",
      "Epoch 654/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3011 - accuracy: 0.5544 - val_loss: 1.9313 - val_accuracy: 0.4118\n",
      "Epoch 655/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3584 - accuracy: 0.5360 - val_loss: 1.9240 - val_accuracy: 0.4294\n",
      "Epoch 656/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3497 - accuracy: 0.5426 - val_loss: 1.9267 - val_accuracy: 0.4206\n",
      "Epoch 657/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3088 - accuracy: 0.5610 - val_loss: 1.9319 - val_accuracy: 0.4294\n",
      "Epoch 658/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3792 - accuracy: 0.5324 - val_loss: 1.9389 - val_accuracy: 0.4206\n",
      "Epoch 659/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3171 - accuracy: 0.5529 - val_loss: 1.9318 - val_accuracy: 0.4382\n",
      "Epoch 660/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4203 - accuracy: 0.5441 - val_loss: 1.9396 - val_accuracy: 0.4412\n",
      "Epoch 661/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3249 - accuracy: 0.5522 - val_loss: 1.9270 - val_accuracy: 0.4324\n",
      "Epoch 662/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3672 - accuracy: 0.5257 - val_loss: 1.9180 - val_accuracy: 0.4235\n",
      "Epoch 663/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2851 - accuracy: 0.5419 - val_loss: 1.9193 - val_accuracy: 0.4235\n",
      "Epoch 664/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3442 - accuracy: 0.5324 - val_loss: 1.9112 - val_accuracy: 0.4294\n",
      "Epoch 665/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3694 - accuracy: 0.5221 - val_loss: 1.9144 - val_accuracy: 0.4471\n",
      "Epoch 666/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3243 - accuracy: 0.5419 - val_loss: 1.9193 - val_accuracy: 0.4294\n",
      "Epoch 667/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3156 - accuracy: 0.5485 - val_loss: 1.9225 - val_accuracy: 0.4265\n",
      "Epoch 668/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2866 - accuracy: 0.5397 - val_loss: 1.9333 - val_accuracy: 0.4265\n",
      "Epoch 669/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3406 - accuracy: 0.5250 - val_loss: 1.9330 - val_accuracy: 0.4324\n",
      "Epoch 670/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3375 - accuracy: 0.5390 - val_loss: 1.9411 - val_accuracy: 0.4294\n",
      "Epoch 671/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3292 - accuracy: 0.5441 - val_loss: 1.9254 - val_accuracy: 0.4176\n",
      "Epoch 672/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3590 - accuracy: 0.5176 - val_loss: 1.9249 - val_accuracy: 0.4147\n",
      "Epoch 673/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2995 - accuracy: 0.5331 - val_loss: 1.9172 - val_accuracy: 0.4294\n",
      "Epoch 674/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3204 - accuracy: 0.5522 - val_loss: 1.9095 - val_accuracy: 0.4324\n",
      "Epoch 675/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3291 - accuracy: 0.5353 - val_loss: 1.9086 - val_accuracy: 0.4382\n",
      "Epoch 676/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3398 - accuracy: 0.5154 - val_loss: 1.9205 - val_accuracy: 0.4471\n",
      "Epoch 677/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3350 - accuracy: 0.5375 - val_loss: 1.9095 - val_accuracy: 0.4324\n",
      "Epoch 678/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3266 - accuracy: 0.5368 - val_loss: 1.9110 - val_accuracy: 0.4294\n",
      "Epoch 679/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3324 - accuracy: 0.5301 - val_loss: 1.9185 - val_accuracy: 0.4294\n",
      "Epoch 680/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3130 - accuracy: 0.5456 - val_loss: 1.9207 - val_accuracy: 0.4324\n",
      "Epoch 681/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3228 - accuracy: 0.5559 - val_loss: 1.9120 - val_accuracy: 0.4412\n",
      "Epoch 682/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3447 - accuracy: 0.5426 - val_loss: 1.9154 - val_accuracy: 0.4382\n",
      "Epoch 683/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3015 - accuracy: 0.5434 - val_loss: 1.9066 - val_accuracy: 0.4441\n",
      "Epoch 684/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3863 - accuracy: 0.5493 - val_loss: 1.9093 - val_accuracy: 0.4441\n",
      "Epoch 685/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3250 - accuracy: 0.5441 - val_loss: 1.9127 - val_accuracy: 0.4471\n",
      "Epoch 686/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3172 - accuracy: 0.5478 - val_loss: 1.9074 - val_accuracy: 0.4471\n",
      "Epoch 687/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3775 - accuracy: 0.5390 - val_loss: 1.9136 - val_accuracy: 0.4441\n",
      "Epoch 688/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3042 - accuracy: 0.5434 - val_loss: 1.9283 - val_accuracy: 0.4412\n",
      "Epoch 689/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3471 - accuracy: 0.5331 - val_loss: 1.9063 - val_accuracy: 0.4294\n",
      "Epoch 690/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3196 - accuracy: 0.5500 - val_loss: 1.9137 - val_accuracy: 0.4353\n",
      "Epoch 691/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3113 - accuracy: 0.5463 - val_loss: 1.9151 - val_accuracy: 0.4441\n",
      "Epoch 692/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3254 - accuracy: 0.5537 - val_loss: 1.9216 - val_accuracy: 0.4441\n",
      "Epoch 693/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3001 - accuracy: 0.5566 - val_loss: 1.9342 - val_accuracy: 0.4412\n",
      "Epoch 694/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3394 - accuracy: 0.5493 - val_loss: 1.9382 - val_accuracy: 0.4382\n",
      "Epoch 695/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3211 - accuracy: 0.5507 - val_loss: 1.9251 - val_accuracy: 0.4500\n",
      "Epoch 696/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3296 - accuracy: 0.5235 - val_loss: 1.9314 - val_accuracy: 0.4588\n",
      "Epoch 697/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3390 - accuracy: 0.5191 - val_loss: 1.9473 - val_accuracy: 0.4235\n",
      "Epoch 698/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2791 - accuracy: 0.5507 - val_loss: 1.9380 - val_accuracy: 0.4382\n",
      "Epoch 699/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2979 - accuracy: 0.5368 - val_loss: 1.9502 - val_accuracy: 0.4412\n",
      "Epoch 700/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3554 - accuracy: 0.5257 - val_loss: 1.9489 - val_accuracy: 0.4500\n",
      "Epoch 701/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2915 - accuracy: 0.5654 - val_loss: 1.9576 - val_accuracy: 0.4441\n",
      "Epoch 702/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3179 - accuracy: 0.5353 - val_loss: 1.9540 - val_accuracy: 0.4382\n",
      "Epoch 703/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3060 - accuracy: 0.5471 - val_loss: 1.9475 - val_accuracy: 0.4500\n",
      "Epoch 704/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3187 - accuracy: 0.5353 - val_loss: 1.9523 - val_accuracy: 0.4471\n",
      "Epoch 705/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3465 - accuracy: 0.5338 - val_loss: 1.9537 - val_accuracy: 0.4353\n",
      "Epoch 706/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3047 - accuracy: 0.5368 - val_loss: 1.9306 - val_accuracy: 0.4294\n",
      "Epoch 707/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3185 - accuracy: 0.5507 - val_loss: 1.9375 - val_accuracy: 0.4353\n",
      "Epoch 708/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2970 - accuracy: 0.5507 - val_loss: 1.9389 - val_accuracy: 0.4441\n",
      "Epoch 709/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3438 - accuracy: 0.5346 - val_loss: 1.9476 - val_accuracy: 0.4441\n",
      "Epoch 710/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3608 - accuracy: 0.5338 - val_loss: 1.9414 - val_accuracy: 0.4441\n",
      "Epoch 711/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3193 - accuracy: 0.5529 - val_loss: 1.9410 - val_accuracy: 0.4382\n",
      "Epoch 712/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3232 - accuracy: 0.5316 - val_loss: 1.9368 - val_accuracy: 0.4412\n",
      "Epoch 713/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3627 - accuracy: 0.5221 - val_loss: 1.9377 - val_accuracy: 0.4382\n",
      "Epoch 714/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3252 - accuracy: 0.5441 - val_loss: 1.9360 - val_accuracy: 0.4412\n",
      "Epoch 715/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3515 - accuracy: 0.5316 - val_loss: 1.9489 - val_accuracy: 0.4441\n",
      "Epoch 716/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3247 - accuracy: 0.5529 - val_loss: 1.9397 - val_accuracy: 0.4529\n",
      "Epoch 717/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3174 - accuracy: 0.5603 - val_loss: 1.9284 - val_accuracy: 0.4471\n",
      "Epoch 718/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3183 - accuracy: 0.5456 - val_loss: 1.9255 - val_accuracy: 0.4382\n",
      "Epoch 719/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2641 - accuracy: 0.5625 - val_loss: 1.9310 - val_accuracy: 0.4294\n",
      "Epoch 720/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3006 - accuracy: 0.5500 - val_loss: 1.9420 - val_accuracy: 0.4324\n",
      "Epoch 721/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3000 - accuracy: 0.5507 - val_loss: 1.9379 - val_accuracy: 0.4353\n",
      "Epoch 722/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3017 - accuracy: 0.5397 - val_loss: 1.9572 - val_accuracy: 0.4353\n",
      "Epoch 723/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3303 - accuracy: 0.5456 - val_loss: 1.9573 - val_accuracy: 0.4382\n",
      "Epoch 724/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3041 - accuracy: 0.5537 - val_loss: 1.9560 - val_accuracy: 0.4412\n",
      "Epoch 725/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3284 - accuracy: 0.5449 - val_loss: 1.9693 - val_accuracy: 0.4353\n",
      "Epoch 726/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2936 - accuracy: 0.5493 - val_loss: 1.9550 - val_accuracy: 0.4353\n",
      "Epoch 727/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2953 - accuracy: 0.5507 - val_loss: 1.9519 - val_accuracy: 0.4382\n",
      "Epoch 728/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3193 - accuracy: 0.5500 - val_loss: 1.9629 - val_accuracy: 0.4235\n",
      "Epoch 729/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3051 - accuracy: 0.5522 - val_loss: 1.9592 - val_accuracy: 0.4353\n",
      "Epoch 730/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2932 - accuracy: 0.5596 - val_loss: 1.9587 - val_accuracy: 0.4382\n",
      "Epoch 731/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3161 - accuracy: 0.5515 - val_loss: 1.9497 - val_accuracy: 0.4235\n",
      "Epoch 732/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2884 - accuracy: 0.5581 - val_loss: 1.9578 - val_accuracy: 0.4265\n",
      "Epoch 733/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3275 - accuracy: 0.5515 - val_loss: 1.9484 - val_accuracy: 0.4412\n",
      "Epoch 734/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3410 - accuracy: 0.5574 - val_loss: 1.9498 - val_accuracy: 0.4500\n",
      "Epoch 735/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2834 - accuracy: 0.5346 - val_loss: 1.9605 - val_accuracy: 0.4324\n",
      "Epoch 736/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3355 - accuracy: 0.5368 - val_loss: 1.9678 - val_accuracy: 0.4382\n",
      "Epoch 737/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2637 - accuracy: 0.5566 - val_loss: 1.9695 - val_accuracy: 0.4441\n",
      "Epoch 738/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3302 - accuracy: 0.5426 - val_loss: 1.9604 - val_accuracy: 0.4441\n",
      "Epoch 739/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3181 - accuracy: 0.5368 - val_loss: 1.9542 - val_accuracy: 0.4382\n",
      "Epoch 740/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3080 - accuracy: 0.5375 - val_loss: 1.9652 - val_accuracy: 0.4265\n",
      "Epoch 741/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3022 - accuracy: 0.5449 - val_loss: 1.9536 - val_accuracy: 0.4412\n",
      "Epoch 742/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3210 - accuracy: 0.5404 - val_loss: 1.9488 - val_accuracy: 0.4412\n",
      "Epoch 743/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2879 - accuracy: 0.5618 - val_loss: 1.9438 - val_accuracy: 0.4324\n",
      "Epoch 744/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3055 - accuracy: 0.5397 - val_loss: 1.9606 - val_accuracy: 0.4412\n",
      "Epoch 745/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3153 - accuracy: 0.5441 - val_loss: 1.9617 - val_accuracy: 0.4265\n",
      "Epoch 746/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3010 - accuracy: 0.5463 - val_loss: 1.9666 - val_accuracy: 0.4206\n",
      "Epoch 747/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3245 - accuracy: 0.5603 - val_loss: 1.9542 - val_accuracy: 0.4206\n",
      "Epoch 748/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2845 - accuracy: 0.5603 - val_loss: 1.9731 - val_accuracy: 0.4235\n",
      "Epoch 749/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2715 - accuracy: 0.5699 - val_loss: 1.9671 - val_accuracy: 0.4412\n",
      "Epoch 750/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3303 - accuracy: 0.5368 - val_loss: 1.9856 - val_accuracy: 0.4353\n",
      "Epoch 751/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2948 - accuracy: 0.5441 - val_loss: 1.9780 - val_accuracy: 0.4353\n",
      "Epoch 752/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3327 - accuracy: 0.5353 - val_loss: 1.9560 - val_accuracy: 0.4382\n",
      "Epoch 753/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2973 - accuracy: 0.5625 - val_loss: 1.9556 - val_accuracy: 0.4412\n",
      "Epoch 754/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3195 - accuracy: 0.5287 - val_loss: 1.9608 - val_accuracy: 0.4500\n",
      "Epoch 755/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2974 - accuracy: 0.5441 - val_loss: 1.9609 - val_accuracy: 0.4412\n",
      "Epoch 756/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2906 - accuracy: 0.5500 - val_loss: 1.9586 - val_accuracy: 0.4382\n",
      "Epoch 757/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3283 - accuracy: 0.5640 - val_loss: 1.9591 - val_accuracy: 0.4529\n",
      "Epoch 758/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3422 - accuracy: 0.5426 - val_loss: 1.9727 - val_accuracy: 0.4353\n",
      "Epoch 759/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2808 - accuracy: 0.5507 - val_loss: 1.9668 - val_accuracy: 0.4265\n",
      "Epoch 760/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2880 - accuracy: 0.5610 - val_loss: 1.9818 - val_accuracy: 0.4324\n",
      "Epoch 761/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3124 - accuracy: 0.5559 - val_loss: 1.9968 - val_accuracy: 0.4412\n",
      "Epoch 762/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3209 - accuracy: 0.5382 - val_loss: 1.9867 - val_accuracy: 0.4412\n",
      "Epoch 763/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3186 - accuracy: 0.5331 - val_loss: 1.9682 - val_accuracy: 0.4441\n",
      "Epoch 764/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3291 - accuracy: 0.5500 - val_loss: 1.9879 - val_accuracy: 0.4353\n",
      "Epoch 765/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2511 - accuracy: 0.5515 - val_loss: 1.9783 - val_accuracy: 0.4294\n",
      "Epoch 766/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.4526 - accuracy: 0.5390 - val_loss: 1.9982 - val_accuracy: 0.4235\n",
      "Epoch 767/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3552 - accuracy: 0.5346 - val_loss: 1.9825 - val_accuracy: 0.4265\n",
      "Epoch 768/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3049 - accuracy: 0.5419 - val_loss: 1.9715 - val_accuracy: 0.4382\n",
      "Epoch 769/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2546 - accuracy: 0.5654 - val_loss: 1.9703 - val_accuracy: 0.4265\n",
      "Epoch 770/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2885 - accuracy: 0.5375 - val_loss: 1.9690 - val_accuracy: 0.4412\n",
      "Epoch 771/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2713 - accuracy: 0.5574 - val_loss: 1.9572 - val_accuracy: 0.4529\n",
      "Epoch 772/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3006 - accuracy: 0.5390 - val_loss: 1.9524 - val_accuracy: 0.4441\n",
      "Epoch 773/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3006 - accuracy: 0.5618 - val_loss: 1.9595 - val_accuracy: 0.4441\n",
      "Epoch 774/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3162 - accuracy: 0.5309 - val_loss: 1.9539 - val_accuracy: 0.4324\n",
      "Epoch 775/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3087 - accuracy: 0.5353 - val_loss: 1.9534 - val_accuracy: 0.4441\n",
      "Epoch 776/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3321 - accuracy: 0.5346 - val_loss: 1.9621 - val_accuracy: 0.4324\n",
      "Epoch 777/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2878 - accuracy: 0.5647 - val_loss: 1.9698 - val_accuracy: 0.4382\n",
      "Epoch 778/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2717 - accuracy: 0.5868 - val_loss: 1.9699 - val_accuracy: 0.4441\n",
      "Epoch 779/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2860 - accuracy: 0.5625 - val_loss: 1.9583 - val_accuracy: 0.4206\n",
      "Epoch 780/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2950 - accuracy: 0.5662 - val_loss: 1.9725 - val_accuracy: 0.4382\n",
      "Epoch 781/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3204 - accuracy: 0.5324 - val_loss: 1.9650 - val_accuracy: 0.4353\n",
      "Epoch 782/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2724 - accuracy: 0.5493 - val_loss: 1.9649 - val_accuracy: 0.4324\n",
      "Epoch 783/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3029 - accuracy: 0.5426 - val_loss: 1.9617 - val_accuracy: 0.4353\n",
      "Epoch 784/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2600 - accuracy: 0.5676 - val_loss: 1.9670 - val_accuracy: 0.4324\n",
      "Epoch 785/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2814 - accuracy: 0.5500 - val_loss: 1.9651 - val_accuracy: 0.4324\n",
      "Epoch 786/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2593 - accuracy: 0.5507 - val_loss: 1.9670 - val_accuracy: 0.4265\n",
      "Epoch 787/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3407 - accuracy: 0.5360 - val_loss: 1.9741 - val_accuracy: 0.4382\n",
      "Epoch 788/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2595 - accuracy: 0.5691 - val_loss: 1.9696 - val_accuracy: 0.4324\n",
      "Epoch 789/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3348 - accuracy: 0.5500 - val_loss: 1.9603 - val_accuracy: 0.4235\n",
      "Epoch 790/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3095 - accuracy: 0.5353 - val_loss: 1.9580 - val_accuracy: 0.4412\n",
      "Epoch 791/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3143 - accuracy: 0.5559 - val_loss: 1.9559 - val_accuracy: 0.4353\n",
      "Epoch 792/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3133 - accuracy: 0.5618 - val_loss: 1.9510 - val_accuracy: 0.4353\n",
      "Epoch 793/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3484 - accuracy: 0.5353 - val_loss: 1.9459 - val_accuracy: 0.4441\n",
      "Epoch 794/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3075 - accuracy: 0.5441 - val_loss: 1.9537 - val_accuracy: 0.4353\n",
      "Epoch 795/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3156 - accuracy: 0.5434 - val_loss: 1.9542 - val_accuracy: 0.4265\n",
      "Epoch 796/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2868 - accuracy: 0.5588 - val_loss: 1.9559 - val_accuracy: 0.4294\n",
      "Epoch 797/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3191 - accuracy: 0.5559 - val_loss: 1.9555 - val_accuracy: 0.4294\n",
      "Epoch 798/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2859 - accuracy: 0.5529 - val_loss: 1.9548 - val_accuracy: 0.4294\n",
      "Epoch 799/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3242 - accuracy: 0.5478 - val_loss: 1.9609 - val_accuracy: 0.4294\n",
      "Epoch 800/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2624 - accuracy: 0.5588 - val_loss: 1.9700 - val_accuracy: 0.4353\n",
      "Epoch 801/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2954 - accuracy: 0.5426 - val_loss: 1.9676 - val_accuracy: 0.4265\n",
      "Epoch 802/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2654 - accuracy: 0.5515 - val_loss: 1.9715 - val_accuracy: 0.4382\n",
      "Epoch 803/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3234 - accuracy: 0.5529 - val_loss: 1.9873 - val_accuracy: 0.4206\n",
      "Epoch 804/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2957 - accuracy: 0.5544 - val_loss: 1.9808 - val_accuracy: 0.4206\n",
      "Epoch 805/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3295 - accuracy: 0.5294 - val_loss: 1.9816 - val_accuracy: 0.4265\n",
      "Epoch 806/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2904 - accuracy: 0.5478 - val_loss: 1.9695 - val_accuracy: 0.4382\n",
      "Epoch 807/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2457 - accuracy: 0.5750 - val_loss: 1.9797 - val_accuracy: 0.4324\n",
      "Epoch 808/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2997 - accuracy: 0.5640 - val_loss: 1.9651 - val_accuracy: 0.4294\n",
      "Epoch 809/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3050 - accuracy: 0.5522 - val_loss: 1.9667 - val_accuracy: 0.4471\n",
      "Epoch 810/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3220 - accuracy: 0.5441 - val_loss: 1.9847 - val_accuracy: 0.4353\n",
      "Epoch 811/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3187 - accuracy: 0.5426 - val_loss: 1.9846 - val_accuracy: 0.4412\n",
      "Epoch 812/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2718 - accuracy: 0.5684 - val_loss: 1.9860 - val_accuracy: 0.4235\n",
      "Epoch 813/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3031 - accuracy: 0.5485 - val_loss: 1.9821 - val_accuracy: 0.4206\n",
      "Epoch 814/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3672 - accuracy: 0.5360 - val_loss: 1.9840 - val_accuracy: 0.4265\n",
      "Epoch 815/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3343 - accuracy: 0.5346 - val_loss: 1.9922 - val_accuracy: 0.4235\n",
      "Epoch 816/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2478 - accuracy: 0.5551 - val_loss: 1.9949 - val_accuracy: 0.4118\n",
      "Epoch 817/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2600 - accuracy: 0.5603 - val_loss: 2.0091 - val_accuracy: 0.4176\n",
      "Epoch 818/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2860 - accuracy: 0.5559 - val_loss: 2.0028 - val_accuracy: 0.4353\n",
      "Epoch 819/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3138 - accuracy: 0.5449 - val_loss: 2.0037 - val_accuracy: 0.4265\n",
      "Epoch 820/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3043 - accuracy: 0.5588 - val_loss: 2.0153 - val_accuracy: 0.4147\n",
      "Epoch 821/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2726 - accuracy: 0.5537 - val_loss: 2.0218 - val_accuracy: 0.4118\n",
      "Epoch 822/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2841 - accuracy: 0.5500 - val_loss: 2.0174 - val_accuracy: 0.4147\n",
      "Epoch 823/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2803 - accuracy: 0.5596 - val_loss: 2.0233 - val_accuracy: 0.4029\n",
      "Epoch 824/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2695 - accuracy: 0.5581 - val_loss: 2.0241 - val_accuracy: 0.4029\n",
      "Epoch 825/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2808 - accuracy: 0.5566 - val_loss: 2.0136 - val_accuracy: 0.4059\n",
      "Epoch 826/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2784 - accuracy: 0.5463 - val_loss: 2.0108 - val_accuracy: 0.4088\n",
      "Epoch 827/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2981 - accuracy: 0.5485 - val_loss: 2.0062 - val_accuracy: 0.4118\n",
      "Epoch 828/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2930 - accuracy: 0.5434 - val_loss: 2.0163 - val_accuracy: 0.4088\n",
      "Epoch 829/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2890 - accuracy: 0.5574 - val_loss: 2.0255 - val_accuracy: 0.4088\n",
      "Epoch 830/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2753 - accuracy: 0.5566 - val_loss: 2.0087 - val_accuracy: 0.4176\n",
      "Epoch 831/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2721 - accuracy: 0.5640 - val_loss: 2.0248 - val_accuracy: 0.4206\n",
      "Epoch 832/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2554 - accuracy: 0.5699 - val_loss: 2.0307 - val_accuracy: 0.4206\n",
      "Epoch 833/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2544 - accuracy: 0.5515 - val_loss: 2.0152 - val_accuracy: 0.4235\n",
      "Epoch 834/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2533 - accuracy: 0.5581 - val_loss: 2.0067 - val_accuracy: 0.4353\n",
      "Epoch 835/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2649 - accuracy: 0.5669 - val_loss: 2.0197 - val_accuracy: 0.4294\n",
      "Epoch 836/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2650 - accuracy: 0.5662 - val_loss: 2.0275 - val_accuracy: 0.4235\n",
      "Epoch 837/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3013 - accuracy: 0.5529 - val_loss: 2.0121 - val_accuracy: 0.4147\n",
      "Epoch 838/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3244 - accuracy: 0.5382 - val_loss: 2.0143 - val_accuracy: 0.4147\n",
      "Epoch 839/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2989 - accuracy: 0.5603 - val_loss: 2.0053 - val_accuracy: 0.4265\n",
      "Epoch 840/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2772 - accuracy: 0.5581 - val_loss: 1.9880 - val_accuracy: 0.4324\n",
      "Epoch 841/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3024 - accuracy: 0.5640 - val_loss: 2.0025 - val_accuracy: 0.4353\n",
      "Epoch 842/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2777 - accuracy: 0.5551 - val_loss: 1.9951 - val_accuracy: 0.4294\n",
      "Epoch 843/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3000 - accuracy: 0.5500 - val_loss: 2.0026 - val_accuracy: 0.4176\n",
      "Epoch 844/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2492 - accuracy: 0.5669 - val_loss: 2.0040 - val_accuracy: 0.4118\n",
      "Epoch 845/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2659 - accuracy: 0.5551 - val_loss: 2.0066 - val_accuracy: 0.4382\n",
      "Epoch 846/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3137 - accuracy: 0.5500 - val_loss: 2.0205 - val_accuracy: 0.4324\n",
      "Epoch 847/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2920 - accuracy: 0.5596 - val_loss: 2.0048 - val_accuracy: 0.4206\n",
      "Epoch 848/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2436 - accuracy: 0.5478 - val_loss: 2.0252 - val_accuracy: 0.4176\n",
      "Epoch 849/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2823 - accuracy: 0.5551 - val_loss: 2.0027 - val_accuracy: 0.4235\n",
      "Epoch 850/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2531 - accuracy: 0.5750 - val_loss: 2.0079 - val_accuracy: 0.4176\n",
      "Epoch 851/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2814 - accuracy: 0.5544 - val_loss: 2.0062 - val_accuracy: 0.4147\n",
      "Epoch 852/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2440 - accuracy: 0.5603 - val_loss: 2.0185 - val_accuracy: 0.4294\n",
      "Epoch 853/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2637 - accuracy: 0.5581 - val_loss: 2.0271 - val_accuracy: 0.4265\n",
      "Epoch 854/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2923 - accuracy: 0.5522 - val_loss: 2.0230 - val_accuracy: 0.4265\n",
      "Epoch 855/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2542 - accuracy: 0.5574 - val_loss: 2.0152 - val_accuracy: 0.4471\n",
      "Epoch 856/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2711 - accuracy: 0.5456 - val_loss: 2.0219 - val_accuracy: 0.4441\n",
      "Epoch 857/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2563 - accuracy: 0.5588 - val_loss: 2.0331 - val_accuracy: 0.4412\n",
      "Epoch 858/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2508 - accuracy: 0.5522 - val_loss: 2.0334 - val_accuracy: 0.4353\n",
      "Epoch 859/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2372 - accuracy: 0.5669 - val_loss: 2.0255 - val_accuracy: 0.4382\n",
      "Epoch 860/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2881 - accuracy: 0.5551 - val_loss: 2.0275 - val_accuracy: 0.4353\n",
      "Epoch 861/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2879 - accuracy: 0.5551 - val_loss: 2.0293 - val_accuracy: 0.4265\n",
      "Epoch 862/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3456 - accuracy: 0.5346 - val_loss: 2.0042 - val_accuracy: 0.4471\n",
      "Epoch 863/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2603 - accuracy: 0.5787 - val_loss: 2.0133 - val_accuracy: 0.4324\n",
      "Epoch 864/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3549 - accuracy: 0.5360 - val_loss: 2.0172 - val_accuracy: 0.4235\n",
      "Epoch 865/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3295 - accuracy: 0.5551 - val_loss: 2.0101 - val_accuracy: 0.4294\n",
      "Epoch 866/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2763 - accuracy: 0.5662 - val_loss: 2.0151 - val_accuracy: 0.4294\n",
      "Epoch 867/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2833 - accuracy: 0.5581 - val_loss: 2.0337 - val_accuracy: 0.4353\n",
      "Epoch 868/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2590 - accuracy: 0.5676 - val_loss: 2.0376 - val_accuracy: 0.4294\n",
      "Epoch 869/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2482 - accuracy: 0.5779 - val_loss: 2.0352 - val_accuracy: 0.4265\n",
      "Epoch 870/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2995 - accuracy: 0.5360 - val_loss: 2.0339 - val_accuracy: 0.4206\n",
      "Epoch 871/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2916 - accuracy: 0.5522 - val_loss: 2.0142 - val_accuracy: 0.4265\n",
      "Epoch 872/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2665 - accuracy: 0.5618 - val_loss: 2.0075 - val_accuracy: 0.4235\n",
      "Epoch 873/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2922 - accuracy: 0.5478 - val_loss: 2.0172 - val_accuracy: 0.4176\n",
      "Epoch 874/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2698 - accuracy: 0.5515 - val_loss: 2.0188 - val_accuracy: 0.4294\n",
      "Epoch 875/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2511 - accuracy: 0.5625 - val_loss: 2.0352 - val_accuracy: 0.4324\n",
      "Epoch 876/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2640 - accuracy: 0.5691 - val_loss: 2.0372 - val_accuracy: 0.4206\n",
      "Epoch 877/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2939 - accuracy: 0.5566 - val_loss: 2.0268 - val_accuracy: 0.4265\n",
      "Epoch 878/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2388 - accuracy: 0.5735 - val_loss: 2.0178 - val_accuracy: 0.4324\n",
      "Epoch 879/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2908 - accuracy: 0.5463 - val_loss: 2.0100 - val_accuracy: 0.4235\n",
      "Epoch 880/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2491 - accuracy: 0.5559 - val_loss: 2.0258 - val_accuracy: 0.4382\n",
      "Epoch 881/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2465 - accuracy: 0.5566 - val_loss: 2.0174 - val_accuracy: 0.4265\n",
      "Epoch 882/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2843 - accuracy: 0.5588 - val_loss: 2.0280 - val_accuracy: 0.4353\n",
      "Epoch 883/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3018 - accuracy: 0.5346 - val_loss: 2.0255 - val_accuracy: 0.4294\n",
      "Epoch 884/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2956 - accuracy: 0.5471 - val_loss: 2.0246 - val_accuracy: 0.4235\n",
      "Epoch 885/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3011 - accuracy: 0.5324 - val_loss: 2.0196 - val_accuracy: 0.4206\n",
      "Epoch 886/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2916 - accuracy: 0.5426 - val_loss: 2.0113 - val_accuracy: 0.4265\n",
      "Epoch 887/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2651 - accuracy: 0.5654 - val_loss: 2.0118 - val_accuracy: 0.4324\n",
      "Epoch 888/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2925 - accuracy: 0.5507 - val_loss: 2.0140 - val_accuracy: 0.4294\n",
      "Epoch 889/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2377 - accuracy: 0.5772 - val_loss: 2.0318 - val_accuracy: 0.4235\n",
      "Epoch 890/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2651 - accuracy: 0.5647 - val_loss: 2.0404 - val_accuracy: 0.4324\n",
      "Epoch 891/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2374 - accuracy: 0.5669 - val_loss: 2.0511 - val_accuracy: 0.4265\n",
      "Epoch 892/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2602 - accuracy: 0.5551 - val_loss: 2.0673 - val_accuracy: 0.4147\n",
      "Epoch 893/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2680 - accuracy: 0.5537 - val_loss: 2.0638 - val_accuracy: 0.4088\n",
      "Epoch 894/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2577 - accuracy: 0.5588 - val_loss: 2.0491 - val_accuracy: 0.4235\n",
      "Epoch 895/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2945 - accuracy: 0.5441 - val_loss: 2.0634 - val_accuracy: 0.4147\n",
      "Epoch 896/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3101 - accuracy: 0.5419 - val_loss: 2.0427 - val_accuracy: 0.4206\n",
      "Epoch 897/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2577 - accuracy: 0.5449 - val_loss: 2.0352 - val_accuracy: 0.4147\n",
      "Epoch 898/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2564 - accuracy: 0.5713 - val_loss: 2.0403 - val_accuracy: 0.4147\n",
      "Epoch 899/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2122 - accuracy: 0.5647 - val_loss: 2.0585 - val_accuracy: 0.4206\n",
      "Epoch 900/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2382 - accuracy: 0.5699 - val_loss: 2.0440 - val_accuracy: 0.4235\n",
      "Epoch 901/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2940 - accuracy: 0.5522 - val_loss: 2.0369 - val_accuracy: 0.4294\n",
      "Epoch 902/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2904 - accuracy: 0.5500 - val_loss: 2.0328 - val_accuracy: 0.4235\n",
      "Epoch 903/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2659 - accuracy: 0.5669 - val_loss: 2.0226 - val_accuracy: 0.4353\n",
      "Epoch 904/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2750 - accuracy: 0.5618 - val_loss: 2.0293 - val_accuracy: 0.4235\n",
      "Epoch 905/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2169 - accuracy: 0.5691 - val_loss: 2.0315 - val_accuracy: 0.4294\n",
      "Epoch 906/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2253 - accuracy: 0.5706 - val_loss: 2.0581 - val_accuracy: 0.4294\n",
      "Epoch 907/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2581 - accuracy: 0.5618 - val_loss: 2.0606 - val_accuracy: 0.4235\n",
      "Epoch 908/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2678 - accuracy: 0.5618 - val_loss: 2.0597 - val_accuracy: 0.4235\n",
      "Epoch 909/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3335 - accuracy: 0.5625 - val_loss: 2.0501 - val_accuracy: 0.4235\n",
      "Epoch 910/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2709 - accuracy: 0.5779 - val_loss: 2.0583 - val_accuracy: 0.4294\n",
      "Epoch 911/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2520 - accuracy: 0.5515 - val_loss: 2.0547 - val_accuracy: 0.4500\n",
      "Epoch 912/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2520 - accuracy: 0.5632 - val_loss: 2.0410 - val_accuracy: 0.4412\n",
      "Epoch 913/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2742 - accuracy: 0.5515 - val_loss: 2.0275 - val_accuracy: 0.4382\n",
      "Epoch 914/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2022 - accuracy: 0.5875 - val_loss: 2.0244 - val_accuracy: 0.4294\n",
      "Epoch 915/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2324 - accuracy: 0.5735 - val_loss: 2.0304 - val_accuracy: 0.4500\n",
      "Epoch 916/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3655 - accuracy: 0.5353 - val_loss: 2.0306 - val_accuracy: 0.4353\n",
      "Epoch 917/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2309 - accuracy: 0.5706 - val_loss: 2.0522 - val_accuracy: 0.4294\n",
      "Epoch 918/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2832 - accuracy: 0.5551 - val_loss: 2.0532 - val_accuracy: 0.4265\n",
      "Epoch 919/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2408 - accuracy: 0.5831 - val_loss: 2.0456 - val_accuracy: 0.4324\n",
      "Epoch 920/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2573 - accuracy: 0.5581 - val_loss: 2.0403 - val_accuracy: 0.4353\n",
      "Epoch 921/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2579 - accuracy: 0.5537 - val_loss: 2.0392 - val_accuracy: 0.4294\n",
      "Epoch 922/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2629 - accuracy: 0.5618 - val_loss: 2.0327 - val_accuracy: 0.4353\n",
      "Epoch 923/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2805 - accuracy: 0.5654 - val_loss: 2.0463 - val_accuracy: 0.4324\n",
      "Epoch 924/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2900 - accuracy: 0.5426 - val_loss: 2.0395 - val_accuracy: 0.4324\n",
      "Epoch 925/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2926 - accuracy: 0.5537 - val_loss: 2.0342 - val_accuracy: 0.4353\n",
      "Epoch 926/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2468 - accuracy: 0.5559 - val_loss: 2.0214 - val_accuracy: 0.4235\n",
      "Epoch 927/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2372 - accuracy: 0.5691 - val_loss: 2.0192 - val_accuracy: 0.4324\n",
      "Epoch 928/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2709 - accuracy: 0.5625 - val_loss: 2.0305 - val_accuracy: 0.4324\n",
      "Epoch 929/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2387 - accuracy: 0.5934 - val_loss: 2.0340 - val_accuracy: 0.4265\n",
      "Epoch 930/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2913 - accuracy: 0.5441 - val_loss: 2.0351 - val_accuracy: 0.4382\n",
      "Epoch 931/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2897 - accuracy: 0.5449 - val_loss: 2.0514 - val_accuracy: 0.4235\n",
      "Epoch 932/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3442 - accuracy: 0.5485 - val_loss: 2.0631 - val_accuracy: 0.4206\n",
      "Epoch 933/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2368 - accuracy: 0.5588 - val_loss: 2.0592 - val_accuracy: 0.4206\n",
      "Epoch 934/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2726 - accuracy: 0.5662 - val_loss: 2.0649 - val_accuracy: 0.4118\n",
      "Epoch 935/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2975 - accuracy: 0.5787 - val_loss: 2.0642 - val_accuracy: 0.4235\n",
      "Epoch 936/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2658 - accuracy: 0.5551 - val_loss: 2.0610 - val_accuracy: 0.4176\n",
      "Epoch 937/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2498 - accuracy: 0.5515 - val_loss: 2.0484 - val_accuracy: 0.4059\n",
      "Epoch 938/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3008 - accuracy: 0.5346 - val_loss: 2.0365 - val_accuracy: 0.4206\n",
      "Epoch 939/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2114 - accuracy: 0.5868 - val_loss: 2.0502 - val_accuracy: 0.4324\n",
      "Epoch 940/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2417 - accuracy: 0.5654 - val_loss: 2.0397 - val_accuracy: 0.4265\n",
      "Epoch 941/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2617 - accuracy: 0.5603 - val_loss: 2.0577 - val_accuracy: 0.4235\n",
      "Epoch 942/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2630 - accuracy: 0.5515 - val_loss: 2.0596 - val_accuracy: 0.4147\n",
      "Epoch 943/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2994 - accuracy: 0.5485 - val_loss: 2.0459 - val_accuracy: 0.4412\n",
      "Epoch 944/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2221 - accuracy: 0.5603 - val_loss: 2.0449 - val_accuracy: 0.4324\n",
      "Epoch 945/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2268 - accuracy: 0.5904 - val_loss: 2.0477 - val_accuracy: 0.4265\n",
      "Epoch 946/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2859 - accuracy: 0.5537 - val_loss: 2.0700 - val_accuracy: 0.4235\n",
      "Epoch 947/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2365 - accuracy: 0.5662 - val_loss: 2.0632 - val_accuracy: 0.4235\n",
      "Epoch 948/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2612 - accuracy: 0.5824 - val_loss: 2.0586 - val_accuracy: 0.4324\n",
      "Epoch 949/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2383 - accuracy: 0.5779 - val_loss: 2.0483 - val_accuracy: 0.4206\n",
      "Epoch 950/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2501 - accuracy: 0.5551 - val_loss: 2.0509 - val_accuracy: 0.4088\n",
      "Epoch 951/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2720 - accuracy: 0.5610 - val_loss: 2.0593 - val_accuracy: 0.4265\n",
      "Epoch 952/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2571 - accuracy: 0.5566 - val_loss: 2.0630 - val_accuracy: 0.4235\n",
      "Epoch 953/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2265 - accuracy: 0.5625 - val_loss: 2.0706 - val_accuracy: 0.4265\n",
      "Epoch 954/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2153 - accuracy: 0.5728 - val_loss: 2.0627 - val_accuracy: 0.4382\n",
      "Epoch 955/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2698 - accuracy: 0.5559 - val_loss: 2.0640 - val_accuracy: 0.4382\n",
      "Epoch 956/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2658 - accuracy: 0.5537 - val_loss: 2.0624 - val_accuracy: 0.4471\n",
      "Epoch 957/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2551 - accuracy: 0.5743 - val_loss: 2.0589 - val_accuracy: 0.4441\n",
      "Epoch 958/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2462 - accuracy: 0.5676 - val_loss: 2.0640 - val_accuracy: 0.4235\n",
      "Epoch 959/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2214 - accuracy: 0.5625 - val_loss: 2.0512 - val_accuracy: 0.4206\n",
      "Epoch 960/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2282 - accuracy: 0.5632 - val_loss: 2.0590 - val_accuracy: 0.4118\n",
      "Epoch 961/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2823 - accuracy: 0.5544 - val_loss: 2.0661 - val_accuracy: 0.4147\n",
      "Epoch 962/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2133 - accuracy: 0.5816 - val_loss: 2.0481 - val_accuracy: 0.4294\n",
      "Epoch 963/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2143 - accuracy: 0.5706 - val_loss: 2.0506 - val_accuracy: 0.4382\n",
      "Epoch 964/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2289 - accuracy: 0.5794 - val_loss: 2.0439 - val_accuracy: 0.4353\n",
      "Epoch 965/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2652 - accuracy: 0.5625 - val_loss: 2.0200 - val_accuracy: 0.4235\n",
      "Epoch 966/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2334 - accuracy: 0.5654 - val_loss: 2.0156 - val_accuracy: 0.4294\n",
      "Epoch 967/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.3162 - accuracy: 0.5419 - val_loss: 2.0153 - val_accuracy: 0.4147\n",
      "Epoch 968/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2514 - accuracy: 0.5676 - val_loss: 2.0141 - val_accuracy: 0.4235\n",
      "Epoch 969/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2301 - accuracy: 0.5691 - val_loss: 2.0189 - val_accuracy: 0.4324\n",
      "Epoch 970/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2442 - accuracy: 0.5551 - val_loss: 2.0200 - val_accuracy: 0.4235\n",
      "Epoch 971/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2395 - accuracy: 0.5824 - val_loss: 2.0276 - val_accuracy: 0.4265\n",
      "Epoch 972/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2700 - accuracy: 0.5478 - val_loss: 2.0228 - val_accuracy: 0.4206\n",
      "Epoch 973/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2896 - accuracy: 0.5669 - val_loss: 2.0217 - val_accuracy: 0.4206\n",
      "Epoch 974/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2158 - accuracy: 0.5904 - val_loss: 2.0396 - val_accuracy: 0.4235\n",
      "Epoch 975/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2530 - accuracy: 0.5500 - val_loss: 2.0468 - val_accuracy: 0.4324\n",
      "Epoch 976/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2747 - accuracy: 0.5632 - val_loss: 2.0541 - val_accuracy: 0.4235\n",
      "Epoch 977/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2653 - accuracy: 0.5676 - val_loss: 2.0635 - val_accuracy: 0.4265\n",
      "Epoch 978/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2394 - accuracy: 0.5632 - val_loss: 2.0607 - val_accuracy: 0.4206\n",
      "Epoch 979/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2357 - accuracy: 0.5684 - val_loss: 2.0502 - val_accuracy: 0.4029\n",
      "Epoch 980/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2381 - accuracy: 0.5779 - val_loss: 2.0621 - val_accuracy: 0.4294\n",
      "Epoch 981/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2434 - accuracy: 0.5551 - val_loss: 2.0566 - val_accuracy: 0.4235\n",
      "Epoch 982/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.1803 - accuracy: 0.5757 - val_loss: 2.0508 - val_accuracy: 0.4324\n",
      "Epoch 983/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2264 - accuracy: 0.5728 - val_loss: 2.0665 - val_accuracy: 0.4206\n",
      "Epoch 984/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2741 - accuracy: 0.5551 - val_loss: 2.0417 - val_accuracy: 0.4382\n",
      "Epoch 985/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2104 - accuracy: 0.5882 - val_loss: 2.0602 - val_accuracy: 0.4294\n",
      "Epoch 986/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2659 - accuracy: 0.5662 - val_loss: 2.0594 - val_accuracy: 0.4382\n",
      "Epoch 987/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2067 - accuracy: 0.5853 - val_loss: 2.0545 - val_accuracy: 0.4324\n",
      "Epoch 988/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2901 - accuracy: 0.5618 - val_loss: 2.0494 - val_accuracy: 0.4206\n",
      "Epoch 989/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2491 - accuracy: 0.5787 - val_loss: 2.0556 - val_accuracy: 0.4059\n",
      "Epoch 990/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2785 - accuracy: 0.5507 - val_loss: 2.0469 - val_accuracy: 0.4206\n",
      "Epoch 991/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2566 - accuracy: 0.5485 - val_loss: 2.0552 - val_accuracy: 0.4118\n",
      "Epoch 992/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2392 - accuracy: 0.5831 - val_loss: 2.0532 - val_accuracy: 0.4294\n",
      "Epoch 993/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2627 - accuracy: 0.5662 - val_loss: 2.0704 - val_accuracy: 0.4147\n",
      "Epoch 994/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2155 - accuracy: 0.5750 - val_loss: 2.0651 - val_accuracy: 0.4206\n",
      "Epoch 995/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2426 - accuracy: 0.5566 - val_loss: 2.0545 - val_accuracy: 0.4206\n",
      "Epoch 996/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2263 - accuracy: 0.5890 - val_loss: 2.0458 - val_accuracy: 0.4206\n",
      "Epoch 997/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2298 - accuracy: 0.5647 - val_loss: 2.0380 - val_accuracy: 0.4147\n",
      "Epoch 998/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2452 - accuracy: 0.5596 - val_loss: 2.0479 - val_accuracy: 0.4294\n",
      "Epoch 999/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2723 - accuracy: 0.5728 - val_loss: 2.0594 - val_accuracy: 0.4206\n",
      "Epoch 1000/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 1.2167 - accuracy: 0.5831 - val_loss: 2.0613 - val_accuracy: 0.4118\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.0613 - accuracy: 0.4118\n",
      "Accuracy for credit rating classification: 41.18%\n",
      "11/11 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train_rating, epochs=1000, batch_size=32, validation_data=(X_test, y_test_rating))\n",
    "\n",
    "# evaluate the model for credit rating classification\n",
    "_, accuracy = model.evaluate(X_test, y_test_rating)\n",
    "print('Accuracy for credit rating classification: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "# predict the credit ratings for the test set\n",
    "y_pred_rating = model.predict(X_test)\n",
    "y_pred_rating = label_encoder.inverse_transform(y_pred_rating.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code defines and trains a neural network model to classify whether a company's credit rating is investment grade. The first layer of the model architecture consists of 64 neurons with ReLU activation function and accepts input data in the same form as training data, consisting of three thick layers. The 32 second-layer neurons have a ReLU activation function with a dropout rate of 0.2, while one third-layer neuron has a sigmoid activation function. Accuracy is chosen as the evaluation metric for the model built using the Adam optimizer and the binary cross-entropy loss function. After validating the model on the training data for 1000 epochs with a batch size of 32, the model is tested on the test data. Evaluate and print the correctness of the model on the test data. Predict asset class membership probabilities, threshold using a decision limit of 0.5, and generate asset class predictions for the test set. Overall, this code demonstrates how to use the Keras library and a neural network model for binary classification of investment-grade credit ratings. The parameters used are activation function, optimizer, loss function, stack size, number of epochs and number of neurons in each layer.\n",
    "After implementing the model, we get the Accuracy for investment grade classification: 83.53%\n",
    "\n",
    "- Reference  https://towardsdatascience.com/math-neural-network-from-scratch-in-python-d6da9f29ce65\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "egmEQIqDxr9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "43/43 [==============================] - 1s 7ms/step - loss: 0.6596 - accuracy: 0.7412 - val_loss: 0.5879 - val_accuracy: 0.7735\n",
      "Epoch 2/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.6004 - accuracy: 0.7676 - val_loss: 0.5507 - val_accuracy: 0.7706\n",
      "Epoch 3/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5726 - accuracy: 0.7669 - val_loss: 0.5301 - val_accuracy: 0.7735\n",
      "Epoch 4/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5446 - accuracy: 0.7610 - val_loss: 0.5207 - val_accuracy: 0.7794\n",
      "Epoch 5/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7728 - val_loss: 0.5163 - val_accuracy: 0.7735\n",
      "Epoch 6/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7721 - val_loss: 0.5175 - val_accuracy: 0.7706\n",
      "Epoch 7/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7772 - val_loss: 0.5107 - val_accuracy: 0.7706\n",
      "Epoch 8/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7757 - val_loss: 0.5080 - val_accuracy: 0.7676\n",
      "Epoch 9/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.7779 - val_loss: 0.5054 - val_accuracy: 0.7706\n",
      "Epoch 10/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7787 - val_loss: 0.5039 - val_accuracy: 0.7706\n",
      "Epoch 11/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7816 - val_loss: 0.5024 - val_accuracy: 0.7676\n",
      "Epoch 12/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7765 - val_loss: 0.5031 - val_accuracy: 0.7706\n",
      "Epoch 13/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7890 - val_loss: 0.5044 - val_accuracy: 0.7676\n",
      "Epoch 14/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7816 - val_loss: 0.5042 - val_accuracy: 0.7618\n",
      "Epoch 15/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.7868 - val_loss: 0.5009 - val_accuracy: 0.7618\n",
      "Epoch 16/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7868 - val_loss: 0.5031 - val_accuracy: 0.7618\n",
      "Epoch 17/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.7934 - val_loss: 0.5026 - val_accuracy: 0.7588\n",
      "Epoch 18/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7941 - val_loss: 0.5065 - val_accuracy: 0.7588\n",
      "Epoch 19/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7949 - val_loss: 0.5032 - val_accuracy: 0.7618\n",
      "Epoch 20/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7890 - val_loss: 0.5046 - val_accuracy: 0.7529\n",
      "Epoch 21/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4455 - accuracy: 0.7897 - val_loss: 0.5063 - val_accuracy: 0.7471\n",
      "Epoch 22/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.8000 - val_loss: 0.5023 - val_accuracy: 0.7676\n",
      "Epoch 23/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.8000 - val_loss: 0.5016 - val_accuracy: 0.7588\n",
      "Epoch 24/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8059 - val_loss: 0.5049 - val_accuracy: 0.7647\n",
      "Epoch 25/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.8103 - val_loss: 0.5079 - val_accuracy: 0.7559\n",
      "Epoch 26/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8066 - val_loss: 0.5062 - val_accuracy: 0.7529\n",
      "Epoch 27/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8081 - val_loss: 0.5035 - val_accuracy: 0.7529\n",
      "Epoch 28/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7978 - val_loss: 0.5089 - val_accuracy: 0.7618\n",
      "Epoch 29/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8154 - val_loss: 0.5032 - val_accuracy: 0.7618\n",
      "Epoch 30/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4329 - accuracy: 0.8081 - val_loss: 0.5021 - val_accuracy: 0.7559\n",
      "Epoch 31/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8000 - val_loss: 0.4925 - val_accuracy: 0.7706\n",
      "Epoch 32/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4251 - accuracy: 0.8096 - val_loss: 0.4919 - val_accuracy: 0.7618\n",
      "Epoch 33/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4255 - accuracy: 0.8132 - val_loss: 0.4979 - val_accuracy: 0.7706\n",
      "Epoch 34/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8074 - val_loss: 0.4950 - val_accuracy: 0.7618\n",
      "Epoch 35/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8206 - val_loss: 0.4945 - val_accuracy: 0.7559\n",
      "Epoch 36/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4175 - accuracy: 0.8184 - val_loss: 0.4959 - val_accuracy: 0.7618\n",
      "Epoch 37/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4240 - accuracy: 0.8037 - val_loss: 0.4975 - val_accuracy: 0.7706\n",
      "Epoch 38/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8169 - val_loss: 0.4972 - val_accuracy: 0.7706\n",
      "Epoch 39/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8154 - val_loss: 0.5017 - val_accuracy: 0.7735\n",
      "Epoch 40/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8257 - val_loss: 0.5007 - val_accuracy: 0.7647\n",
      "Epoch 41/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4079 - accuracy: 0.8228 - val_loss: 0.4989 - val_accuracy: 0.7676\n",
      "Epoch 42/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8221 - val_loss: 0.4964 - val_accuracy: 0.7618\n",
      "Epoch 43/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8154 - val_loss: 0.4963 - val_accuracy: 0.7735\n",
      "Epoch 44/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4088 - accuracy: 0.8118 - val_loss: 0.4887 - val_accuracy: 0.7647\n",
      "Epoch 45/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4094 - accuracy: 0.8176 - val_loss: 0.4866 - val_accuracy: 0.7824\n",
      "Epoch 46/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4117 - accuracy: 0.8213 - val_loss: 0.4856 - val_accuracy: 0.7735\n",
      "Epoch 47/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3959 - accuracy: 0.8338 - val_loss: 0.4899 - val_accuracy: 0.7735\n",
      "Epoch 48/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8176 - val_loss: 0.4868 - val_accuracy: 0.7794\n",
      "Epoch 49/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8287 - val_loss: 0.4905 - val_accuracy: 0.7706\n",
      "Epoch 50/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8309 - val_loss: 0.4925 - val_accuracy: 0.7735\n",
      "Epoch 51/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3938 - accuracy: 0.8353 - val_loss: 0.4965 - val_accuracy: 0.7706\n",
      "Epoch 52/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4080 - accuracy: 0.8125 - val_loss: 0.4930 - val_accuracy: 0.7706\n",
      "Epoch 53/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3860 - accuracy: 0.8309 - val_loss: 0.4918 - val_accuracy: 0.7706\n",
      "Epoch 54/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.8301 - val_loss: 0.4848 - val_accuracy: 0.7824\n",
      "Epoch 55/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.4011 - accuracy: 0.8221 - val_loss: 0.4889 - val_accuracy: 0.7735\n",
      "Epoch 56/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8316 - val_loss: 0.4856 - val_accuracy: 0.7765\n",
      "Epoch 57/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3868 - accuracy: 0.8368 - val_loss: 0.4920 - val_accuracy: 0.7706\n",
      "Epoch 58/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3816 - accuracy: 0.8375 - val_loss: 0.4868 - val_accuracy: 0.7882\n",
      "Epoch 59/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3979 - accuracy: 0.8316 - val_loss: 0.4919 - val_accuracy: 0.7676\n",
      "Epoch 60/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3774 - accuracy: 0.8353 - val_loss: 0.4933 - val_accuracy: 0.7676\n",
      "Epoch 61/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3923 - accuracy: 0.8257 - val_loss: 0.4833 - val_accuracy: 0.7824\n",
      "Epoch 62/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3858 - accuracy: 0.8250 - val_loss: 0.4903 - val_accuracy: 0.7588\n",
      "Epoch 63/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8368 - val_loss: 0.4811 - val_accuracy: 0.7853\n",
      "Epoch 64/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3934 - accuracy: 0.8184 - val_loss: 0.4798 - val_accuracy: 0.7765\n",
      "Epoch 65/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.8375 - val_loss: 0.4759 - val_accuracy: 0.7882\n",
      "Epoch 66/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3809 - accuracy: 0.8368 - val_loss: 0.4840 - val_accuracy: 0.7794\n",
      "Epoch 67/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3760 - accuracy: 0.8294 - val_loss: 0.4786 - val_accuracy: 0.7824\n",
      "Epoch 68/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3788 - accuracy: 0.8353 - val_loss: 0.4830 - val_accuracy: 0.7706\n",
      "Epoch 69/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8309 - val_loss: 0.4737 - val_accuracy: 0.7824\n",
      "Epoch 70/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3884 - accuracy: 0.8397 - val_loss: 0.4861 - val_accuracy: 0.7529\n",
      "Epoch 71/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3754 - accuracy: 0.8404 - val_loss: 0.4763 - val_accuracy: 0.7647\n",
      "Epoch 72/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3629 - accuracy: 0.8404 - val_loss: 0.4741 - val_accuracy: 0.7706\n",
      "Epoch 73/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3719 - accuracy: 0.8390 - val_loss: 0.4724 - val_accuracy: 0.7735\n",
      "Epoch 74/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8353 - val_loss: 0.4658 - val_accuracy: 0.7706\n",
      "Epoch 75/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3713 - accuracy: 0.8346 - val_loss: 0.4778 - val_accuracy: 0.7588\n",
      "Epoch 76/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3700 - accuracy: 0.8419 - val_loss: 0.4710 - val_accuracy: 0.7735\n",
      "Epoch 77/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3676 - accuracy: 0.8463 - val_loss: 0.4754 - val_accuracy: 0.7588\n",
      "Epoch 78/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8419 - val_loss: 0.4604 - val_accuracy: 0.7853\n",
      "Epoch 79/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8441 - val_loss: 0.4719 - val_accuracy: 0.7735\n",
      "Epoch 80/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3560 - accuracy: 0.8493 - val_loss: 0.4694 - val_accuracy: 0.7794\n",
      "Epoch 81/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8382 - val_loss: 0.4694 - val_accuracy: 0.7794\n",
      "Epoch 82/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8353 - val_loss: 0.4686 - val_accuracy: 0.7853\n",
      "Epoch 83/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8566 - val_loss: 0.4753 - val_accuracy: 0.7765\n",
      "Epoch 84/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.8338 - val_loss: 0.4768 - val_accuracy: 0.7794\n",
      "Epoch 85/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3611 - accuracy: 0.8449 - val_loss: 0.4715 - val_accuracy: 0.7824\n",
      "Epoch 86/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3533 - accuracy: 0.8463 - val_loss: 0.4706 - val_accuracy: 0.7794\n",
      "Epoch 87/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3577 - accuracy: 0.8493 - val_loss: 0.4698 - val_accuracy: 0.7706\n",
      "Epoch 88/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8507 - val_loss: 0.4736 - val_accuracy: 0.7706\n",
      "Epoch 89/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8397 - val_loss: 0.4670 - val_accuracy: 0.7647\n",
      "Epoch 90/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3451 - accuracy: 0.8485 - val_loss: 0.4677 - val_accuracy: 0.7706\n",
      "Epoch 91/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8522 - val_loss: 0.4688 - val_accuracy: 0.7735\n",
      "Epoch 92/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8412 - val_loss: 0.4734 - val_accuracy: 0.7706\n",
      "Epoch 93/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3512 - accuracy: 0.8522 - val_loss: 0.4666 - val_accuracy: 0.7824\n",
      "Epoch 94/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8404 - val_loss: 0.4646 - val_accuracy: 0.7882\n",
      "Epoch 95/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8419 - val_loss: 0.4622 - val_accuracy: 0.7794\n",
      "Epoch 96/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8493 - val_loss: 0.4732 - val_accuracy: 0.7765\n",
      "Epoch 97/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3386 - accuracy: 0.8456 - val_loss: 0.4683 - val_accuracy: 0.7824\n",
      "Epoch 98/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3413 - accuracy: 0.8493 - val_loss: 0.4671 - val_accuracy: 0.7794\n",
      "Epoch 99/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8551 - val_loss: 0.4565 - val_accuracy: 0.7706\n",
      "Epoch 100/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3345 - accuracy: 0.8654 - val_loss: 0.4617 - val_accuracy: 0.7735\n",
      "Epoch 101/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8603 - val_loss: 0.4659 - val_accuracy: 0.7735\n",
      "Epoch 102/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8500 - val_loss: 0.4521 - val_accuracy: 0.7853\n",
      "Epoch 103/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8493 - val_loss: 0.4622 - val_accuracy: 0.7676\n",
      "Epoch 104/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8632 - val_loss: 0.4505 - val_accuracy: 0.7853\n",
      "Epoch 105/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8559 - val_loss: 0.4473 - val_accuracy: 0.7882\n",
      "Epoch 106/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3415 - accuracy: 0.8647 - val_loss: 0.4635 - val_accuracy: 0.7853\n",
      "Epoch 107/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8522 - val_loss: 0.4561 - val_accuracy: 0.7824\n",
      "Epoch 108/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8529 - val_loss: 0.4534 - val_accuracy: 0.7824\n",
      "Epoch 109/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3444 - accuracy: 0.8581 - val_loss: 0.4600 - val_accuracy: 0.7765\n",
      "Epoch 110/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8551 - val_loss: 0.4512 - val_accuracy: 0.7794\n",
      "Epoch 111/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8529 - val_loss: 0.4509 - val_accuracy: 0.7794\n",
      "Epoch 112/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8588 - val_loss: 0.4519 - val_accuracy: 0.7735\n",
      "Epoch 113/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8618 - val_loss: 0.4515 - val_accuracy: 0.7853\n",
      "Epoch 114/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8603 - val_loss: 0.4660 - val_accuracy: 0.7735\n",
      "Epoch 115/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8610 - val_loss: 0.4431 - val_accuracy: 0.7794\n",
      "Epoch 116/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8603 - val_loss: 0.4529 - val_accuracy: 0.7853\n",
      "Epoch 117/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8581 - val_loss: 0.4595 - val_accuracy: 0.7824\n",
      "Epoch 118/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8522 - val_loss: 0.4434 - val_accuracy: 0.7853\n",
      "Epoch 119/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8522 - val_loss: 0.4505 - val_accuracy: 0.7882\n",
      "Epoch 120/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3207 - accuracy: 0.8610 - val_loss: 0.4509 - val_accuracy: 0.7824\n",
      "Epoch 121/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8632 - val_loss: 0.4465 - val_accuracy: 0.7824\n",
      "Epoch 122/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8647 - val_loss: 0.4607 - val_accuracy: 0.7853\n",
      "Epoch 123/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8618 - val_loss: 0.4550 - val_accuracy: 0.7794\n",
      "Epoch 124/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8588 - val_loss: 0.4452 - val_accuracy: 0.7794\n",
      "Epoch 125/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8676 - val_loss: 0.4580 - val_accuracy: 0.7706\n",
      "Epoch 126/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8654 - val_loss: 0.4409 - val_accuracy: 0.7824\n",
      "Epoch 127/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8654 - val_loss: 0.4526 - val_accuracy: 0.7882\n",
      "Epoch 128/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3111 - accuracy: 0.8684 - val_loss: 0.4551 - val_accuracy: 0.7882\n",
      "Epoch 129/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8603 - val_loss: 0.4495 - val_accuracy: 0.7794\n",
      "Epoch 130/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8618 - val_loss: 0.4468 - val_accuracy: 0.7824\n",
      "Epoch 131/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8654 - val_loss: 0.4534 - val_accuracy: 0.7853\n",
      "Epoch 132/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3114 - accuracy: 0.8662 - val_loss: 0.4466 - val_accuracy: 0.7882\n",
      "Epoch 133/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3070 - accuracy: 0.8662 - val_loss: 0.4488 - val_accuracy: 0.7824\n",
      "Epoch 134/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8647 - val_loss: 0.4495 - val_accuracy: 0.7853\n",
      "Epoch 135/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8676 - val_loss: 0.4483 - val_accuracy: 0.7765\n",
      "Epoch 136/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8721 - val_loss: 0.4550 - val_accuracy: 0.7794\n",
      "Epoch 137/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8544 - val_loss: 0.4435 - val_accuracy: 0.7706\n",
      "Epoch 138/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 0.8669 - val_loss: 0.4383 - val_accuracy: 0.7735\n",
      "Epoch 139/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8640 - val_loss: 0.4353 - val_accuracy: 0.7794\n",
      "Epoch 140/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8669 - val_loss: 0.4549 - val_accuracy: 0.7882\n",
      "Epoch 141/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8743 - val_loss: 0.4518 - val_accuracy: 0.7853\n",
      "Epoch 142/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8662 - val_loss: 0.4401 - val_accuracy: 0.7794\n",
      "Epoch 143/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8676 - val_loss: 0.4409 - val_accuracy: 0.7794\n",
      "Epoch 144/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8566 - val_loss: 0.4415 - val_accuracy: 0.7882\n",
      "Epoch 145/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8662 - val_loss: 0.4367 - val_accuracy: 0.7941\n",
      "Epoch 146/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8706 - val_loss: 0.4370 - val_accuracy: 0.7824\n",
      "Epoch 147/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.8757 - val_loss: 0.4311 - val_accuracy: 0.7824\n",
      "Epoch 148/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8728 - val_loss: 0.4308 - val_accuracy: 0.7853\n",
      "Epoch 149/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.8706 - val_loss: 0.4360 - val_accuracy: 0.7765\n",
      "Epoch 150/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8794 - val_loss: 0.4370 - val_accuracy: 0.7824\n",
      "Epoch 151/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8824 - val_loss: 0.4368 - val_accuracy: 0.7882\n",
      "Epoch 152/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8676 - val_loss: 0.4430 - val_accuracy: 0.7735\n",
      "Epoch 153/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8735 - val_loss: 0.4468 - val_accuracy: 0.7794\n",
      "Epoch 154/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.8735 - val_loss: 0.4470 - val_accuracy: 0.7853\n",
      "Epoch 155/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.8684 - val_loss: 0.4434 - val_accuracy: 0.7941\n",
      "Epoch 156/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8676 - val_loss: 0.4506 - val_accuracy: 0.7882\n",
      "Epoch 157/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8647 - val_loss: 0.4391 - val_accuracy: 0.7912\n",
      "Epoch 158/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8801 - val_loss: 0.4433 - val_accuracy: 0.7912\n",
      "Epoch 159/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.8706 - val_loss: 0.4373 - val_accuracy: 0.7971\n",
      "Epoch 160/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2883 - accuracy: 0.8794 - val_loss: 0.4431 - val_accuracy: 0.7853\n",
      "Epoch 161/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8699 - val_loss: 0.4534 - val_accuracy: 0.7824\n",
      "Epoch 162/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8750 - val_loss: 0.4505 - val_accuracy: 0.7941\n",
      "Epoch 163/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8757 - val_loss: 0.4371 - val_accuracy: 0.7735\n",
      "Epoch 164/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8750 - val_loss: 0.4408 - val_accuracy: 0.7853\n",
      "Epoch 165/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8735 - val_loss: 0.4448 - val_accuracy: 0.7794\n",
      "Epoch 166/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3036 - accuracy: 0.8706 - val_loss: 0.4375 - val_accuracy: 0.7794\n",
      "Epoch 167/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2880 - accuracy: 0.8831 - val_loss: 0.4416 - val_accuracy: 0.7882\n",
      "Epoch 168/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8809 - val_loss: 0.4441 - val_accuracy: 0.7971\n",
      "Epoch 169/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.8809 - val_loss: 0.4486 - val_accuracy: 0.7912\n",
      "Epoch 170/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8794 - val_loss: 0.4346 - val_accuracy: 0.8000\n",
      "Epoch 171/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.8772 - val_loss: 0.4377 - val_accuracy: 0.7941\n",
      "Epoch 172/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.8897 - val_loss: 0.4347 - val_accuracy: 0.8059\n",
      "Epoch 173/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2723 - accuracy: 0.8853 - val_loss: 0.4492 - val_accuracy: 0.7882\n",
      "Epoch 174/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8779 - val_loss: 0.4525 - val_accuracy: 0.8000\n",
      "Epoch 175/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8794 - val_loss: 0.4460 - val_accuracy: 0.7941\n",
      "Epoch 176/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8779 - val_loss: 0.4477 - val_accuracy: 0.7941\n",
      "Epoch 177/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.8750 - val_loss: 0.4505 - val_accuracy: 0.8000\n",
      "Epoch 178/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8728 - val_loss: 0.4386 - val_accuracy: 0.7912\n",
      "Epoch 179/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8787 - val_loss: 0.4323 - val_accuracy: 0.7971\n",
      "Epoch 180/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2901 - accuracy: 0.8713 - val_loss: 0.4403 - val_accuracy: 0.7794\n",
      "Epoch 181/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8728 - val_loss: 0.4450 - val_accuracy: 0.7941\n",
      "Epoch 182/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.8882 - val_loss: 0.4471 - val_accuracy: 0.7794\n",
      "Epoch 183/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8838 - val_loss: 0.4431 - val_accuracy: 0.7971\n",
      "Epoch 184/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2985 - accuracy: 0.8890 - val_loss: 0.4549 - val_accuracy: 0.7824\n",
      "Epoch 185/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8801 - val_loss: 0.4565 - val_accuracy: 0.7882\n",
      "Epoch 186/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.8662 - val_loss: 0.4667 - val_accuracy: 0.7853\n",
      "Epoch 187/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2856 - accuracy: 0.8853 - val_loss: 0.4614 - val_accuracy: 0.7971\n",
      "Epoch 188/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8801 - val_loss: 0.4663 - val_accuracy: 0.7853\n",
      "Epoch 189/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8853 - val_loss: 0.4558 - val_accuracy: 0.7824\n",
      "Epoch 190/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2888 - accuracy: 0.8816 - val_loss: 0.4433 - val_accuracy: 0.7853\n",
      "Epoch 191/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.8868 - val_loss: 0.4532 - val_accuracy: 0.7735\n",
      "Epoch 192/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.8838 - val_loss: 0.4682 - val_accuracy: 0.7794\n",
      "Epoch 193/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8860 - val_loss: 0.4689 - val_accuracy: 0.7794\n",
      "Epoch 194/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8743 - val_loss: 0.4507 - val_accuracy: 0.7794\n",
      "Epoch 195/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8809 - val_loss: 0.4531 - val_accuracy: 0.7824\n",
      "Epoch 196/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8831 - val_loss: 0.4552 - val_accuracy: 0.7824\n",
      "Epoch 197/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.8875 - val_loss: 0.4582 - val_accuracy: 0.7853\n",
      "Epoch 198/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8853 - val_loss: 0.4427 - val_accuracy: 0.7882\n",
      "Epoch 199/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8831 - val_loss: 0.4403 - val_accuracy: 0.7912\n",
      "Epoch 200/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8875 - val_loss: 0.4471 - val_accuracy: 0.7971\n",
      "Epoch 201/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8743 - val_loss: 0.4493 - val_accuracy: 0.7853\n",
      "Epoch 202/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8838 - val_loss: 0.4659 - val_accuracy: 0.7824\n",
      "Epoch 203/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8816 - val_loss: 0.4539 - val_accuracy: 0.7882\n",
      "Epoch 204/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8846 - val_loss: 0.4478 - val_accuracy: 0.7853\n",
      "Epoch 205/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 0.8934 - val_loss: 0.4392 - val_accuracy: 0.7882\n",
      "Epoch 206/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2679 - accuracy: 0.8882 - val_loss: 0.4530 - val_accuracy: 0.7882\n",
      "Epoch 207/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8824 - val_loss: 0.4514 - val_accuracy: 0.7853\n",
      "Epoch 208/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.8904 - val_loss: 0.4513 - val_accuracy: 0.7882\n",
      "Epoch 209/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8882 - val_loss: 0.4577 - val_accuracy: 0.7765\n",
      "Epoch 210/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8860 - val_loss: 0.4554 - val_accuracy: 0.7912\n",
      "Epoch 211/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.8993 - val_loss: 0.4431 - val_accuracy: 0.7853\n",
      "Epoch 212/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2600 - accuracy: 0.8846 - val_loss: 0.4478 - val_accuracy: 0.7882\n",
      "Epoch 213/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2844 - accuracy: 0.8860 - val_loss: 0.4402 - val_accuracy: 0.7882\n",
      "Epoch 214/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.8963 - val_loss: 0.4439 - val_accuracy: 0.7882\n",
      "Epoch 215/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8897 - val_loss: 0.4507 - val_accuracy: 0.7853\n",
      "Epoch 216/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.8882 - val_loss: 0.4495 - val_accuracy: 0.7794\n",
      "Epoch 217/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.8956 - val_loss: 0.4306 - val_accuracy: 0.8029\n",
      "Epoch 218/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.8890 - val_loss: 0.4307 - val_accuracy: 0.7971\n",
      "Epoch 219/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.8860 - val_loss: 0.4408 - val_accuracy: 0.7971\n",
      "Epoch 220/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2565 - accuracy: 0.8860 - val_loss: 0.4546 - val_accuracy: 0.7941\n",
      "Epoch 221/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.8801 - val_loss: 0.4475 - val_accuracy: 0.8029\n",
      "Epoch 222/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2660 - accuracy: 0.8912 - val_loss: 0.4446 - val_accuracy: 0.7941\n",
      "Epoch 223/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.8794 - val_loss: 0.4489 - val_accuracy: 0.7971\n",
      "Epoch 224/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8926 - val_loss: 0.4582 - val_accuracy: 0.7853\n",
      "Epoch 225/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.8860 - val_loss: 0.4447 - val_accuracy: 0.7882\n",
      "Epoch 226/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.9007 - val_loss: 0.4432 - val_accuracy: 0.7912\n",
      "Epoch 227/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.8985 - val_loss: 0.4308 - val_accuracy: 0.7941\n",
      "Epoch 228/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8904 - val_loss: 0.4405 - val_accuracy: 0.8000\n",
      "Epoch 229/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8934 - val_loss: 0.4568 - val_accuracy: 0.7882\n",
      "Epoch 230/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8926 - val_loss: 0.4476 - val_accuracy: 0.8000\n",
      "Epoch 231/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.8978 - val_loss: 0.4387 - val_accuracy: 0.7941\n",
      "Epoch 232/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.8985 - val_loss: 0.4449 - val_accuracy: 0.7941\n",
      "Epoch 233/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.8860 - val_loss: 0.4390 - val_accuracy: 0.7912\n",
      "Epoch 234/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2632 - accuracy: 0.8926 - val_loss: 0.4444 - val_accuracy: 0.7941\n",
      "Epoch 235/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2550 - accuracy: 0.8926 - val_loss: 0.4455 - val_accuracy: 0.7882\n",
      "Epoch 236/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2730 - accuracy: 0.8853 - val_loss: 0.4384 - val_accuracy: 0.8000\n",
      "Epoch 237/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2449 - accuracy: 0.8993 - val_loss: 0.4474 - val_accuracy: 0.8059\n",
      "Epoch 238/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8934 - val_loss: 0.4321 - val_accuracy: 0.8088\n",
      "Epoch 239/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2542 - accuracy: 0.8993 - val_loss: 0.4339 - val_accuracy: 0.8029\n",
      "Epoch 240/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2563 - accuracy: 0.9029 - val_loss: 0.4498 - val_accuracy: 0.7941\n",
      "Epoch 241/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8993 - val_loss: 0.4376 - val_accuracy: 0.7971\n",
      "Epoch 242/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2467 - accuracy: 0.9015 - val_loss: 0.4489 - val_accuracy: 0.7912\n",
      "Epoch 243/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2486 - accuracy: 0.8978 - val_loss: 0.4501 - val_accuracy: 0.7971\n",
      "Epoch 244/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.8941 - val_loss: 0.4594 - val_accuracy: 0.8000\n",
      "Epoch 245/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2506 - accuracy: 0.8971 - val_loss: 0.4597 - val_accuracy: 0.7941\n",
      "Epoch 246/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2629 - accuracy: 0.8926 - val_loss: 0.4486 - val_accuracy: 0.8029\n",
      "Epoch 247/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2569 - accuracy: 0.9037 - val_loss: 0.4608 - val_accuracy: 0.7971\n",
      "Epoch 248/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2520 - accuracy: 0.9029 - val_loss: 0.4462 - val_accuracy: 0.7971\n",
      "Epoch 249/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2635 - accuracy: 0.9044 - val_loss: 0.4508 - val_accuracy: 0.7912\n",
      "Epoch 250/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2601 - accuracy: 0.8941 - val_loss: 0.4511 - val_accuracy: 0.7971\n",
      "Epoch 251/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.8985 - val_loss: 0.4645 - val_accuracy: 0.7941\n",
      "Epoch 252/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2483 - accuracy: 0.8993 - val_loss: 0.4593 - val_accuracy: 0.7941\n",
      "Epoch 253/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2439 - accuracy: 0.8949 - val_loss: 0.4476 - val_accuracy: 0.7971\n",
      "Epoch 254/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8971 - val_loss: 0.4511 - val_accuracy: 0.8000\n",
      "Epoch 255/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.8941 - val_loss: 0.4281 - val_accuracy: 0.8000\n",
      "Epoch 256/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2445 - accuracy: 0.8941 - val_loss: 0.4309 - val_accuracy: 0.7941\n",
      "Epoch 257/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2577 - accuracy: 0.8897 - val_loss: 0.4399 - val_accuracy: 0.8029\n",
      "Epoch 258/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2400 - accuracy: 0.9007 - val_loss: 0.4277 - val_accuracy: 0.8088\n",
      "Epoch 259/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.9007 - val_loss: 0.4464 - val_accuracy: 0.7941\n",
      "Epoch 260/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.9051 - val_loss: 0.4363 - val_accuracy: 0.8029\n",
      "Epoch 261/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2545 - accuracy: 0.9022 - val_loss: 0.4385 - val_accuracy: 0.8059\n",
      "Epoch 262/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2590 - accuracy: 0.8963 - val_loss: 0.4534 - val_accuracy: 0.8088\n",
      "Epoch 263/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2492 - accuracy: 0.8978 - val_loss: 0.4415 - val_accuracy: 0.8118\n",
      "Epoch 264/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2316 - accuracy: 0.9044 - val_loss: 0.4482 - val_accuracy: 0.8088\n",
      "Epoch 265/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2475 - accuracy: 0.9125 - val_loss: 0.4403 - val_accuracy: 0.8088\n",
      "Epoch 266/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9022 - val_loss: 0.4483 - val_accuracy: 0.8029\n",
      "Epoch 267/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2519 - accuracy: 0.8993 - val_loss: 0.4251 - val_accuracy: 0.8059\n",
      "Epoch 268/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9051 - val_loss: 0.4243 - val_accuracy: 0.8088\n",
      "Epoch 269/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.8949 - val_loss: 0.4323 - val_accuracy: 0.8029\n",
      "Epoch 270/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2416 - accuracy: 0.9059 - val_loss: 0.4383 - val_accuracy: 0.8088\n",
      "Epoch 271/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.9029 - val_loss: 0.4661 - val_accuracy: 0.8029\n",
      "Epoch 272/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2502 - accuracy: 0.9029 - val_loss: 0.4675 - val_accuracy: 0.8000\n",
      "Epoch 273/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2389 - accuracy: 0.9088 - val_loss: 0.4548 - val_accuracy: 0.7941\n",
      "Epoch 274/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.8963 - val_loss: 0.4580 - val_accuracy: 0.7941\n",
      "Epoch 275/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.8993 - val_loss: 0.4452 - val_accuracy: 0.8029\n",
      "Epoch 276/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.8993 - val_loss: 0.4496 - val_accuracy: 0.8118\n",
      "Epoch 277/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2518 - accuracy: 0.9000 - val_loss: 0.4473 - val_accuracy: 0.8029\n",
      "Epoch 278/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9044 - val_loss: 0.4354 - val_accuracy: 0.8059\n",
      "Epoch 279/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2335 - accuracy: 0.9118 - val_loss: 0.4605 - val_accuracy: 0.8118\n",
      "Epoch 280/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2442 - accuracy: 0.9029 - val_loss: 0.4462 - val_accuracy: 0.8029\n",
      "Epoch 281/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2377 - accuracy: 0.9007 - val_loss: 0.4337 - val_accuracy: 0.8176\n",
      "Epoch 282/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9051 - val_loss: 0.4444 - val_accuracy: 0.8029\n",
      "Epoch 283/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2422 - accuracy: 0.9015 - val_loss: 0.4217 - val_accuracy: 0.8147\n",
      "Epoch 284/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9103 - val_loss: 0.4179 - val_accuracy: 0.8059\n",
      "Epoch 285/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.9118 - val_loss: 0.4205 - val_accuracy: 0.8176\n",
      "Epoch 286/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2319 - accuracy: 0.9037 - val_loss: 0.4234 - val_accuracy: 0.8088\n",
      "Epoch 287/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2378 - accuracy: 0.9029 - val_loss: 0.4372 - val_accuracy: 0.8118\n",
      "Epoch 288/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2230 - accuracy: 0.9029 - val_loss: 0.4289 - val_accuracy: 0.8118\n",
      "Epoch 289/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2287 - accuracy: 0.9066 - val_loss: 0.4286 - val_accuracy: 0.8118\n",
      "Epoch 290/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.9154 - val_loss: 0.4239 - val_accuracy: 0.8088\n",
      "Epoch 291/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2532 - accuracy: 0.9037 - val_loss: 0.4156 - val_accuracy: 0.8088\n",
      "Epoch 292/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2469 - accuracy: 0.9015 - val_loss: 0.4255 - val_accuracy: 0.7971\n",
      "Epoch 293/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2370 - accuracy: 0.9037 - val_loss: 0.4184 - val_accuracy: 0.8088\n",
      "Epoch 294/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9000 - val_loss: 0.4342 - val_accuracy: 0.8000\n",
      "Epoch 295/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9059 - val_loss: 0.4290 - val_accuracy: 0.8059\n",
      "Epoch 296/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9118 - val_loss: 0.4336 - val_accuracy: 0.7971\n",
      "Epoch 297/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2245 - accuracy: 0.9051 - val_loss: 0.4281 - val_accuracy: 0.8118\n",
      "Epoch 298/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9059 - val_loss: 0.4414 - val_accuracy: 0.8000\n",
      "Epoch 299/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2323 - accuracy: 0.9140 - val_loss: 0.4432 - val_accuracy: 0.7941\n",
      "Epoch 300/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2781 - accuracy: 0.9044 - val_loss: 0.4263 - val_accuracy: 0.8118\n",
      "Epoch 301/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2205 - accuracy: 0.9176 - val_loss: 0.4290 - val_accuracy: 0.8000\n",
      "Epoch 302/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9199 - val_loss: 0.4379 - val_accuracy: 0.7912\n",
      "Epoch 303/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9169 - val_loss: 0.4395 - val_accuracy: 0.8059\n",
      "Epoch 304/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9096 - val_loss: 0.4313 - val_accuracy: 0.8000\n",
      "Epoch 305/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2216 - accuracy: 0.9103 - val_loss: 0.4565 - val_accuracy: 0.7941\n",
      "Epoch 306/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2410 - accuracy: 0.9022 - val_loss: 0.4545 - val_accuracy: 0.8029\n",
      "Epoch 307/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2306 - accuracy: 0.9059 - val_loss: 0.4394 - val_accuracy: 0.7971\n",
      "Epoch 308/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9081 - val_loss: 0.4360 - val_accuracy: 0.8118\n",
      "Epoch 309/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2133 - accuracy: 0.9140 - val_loss: 0.4260 - val_accuracy: 0.8147\n",
      "Epoch 310/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9140 - val_loss: 0.4074 - val_accuracy: 0.8235\n",
      "Epoch 311/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2249 - accuracy: 0.9125 - val_loss: 0.4179 - val_accuracy: 0.8206\n",
      "Epoch 312/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9132 - val_loss: 0.4194 - val_accuracy: 0.8147\n",
      "Epoch 313/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2211 - accuracy: 0.9154 - val_loss: 0.4199 - val_accuracy: 0.8206\n",
      "Epoch 314/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2180 - accuracy: 0.9074 - val_loss: 0.4181 - val_accuracy: 0.8059\n",
      "Epoch 315/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2317 - accuracy: 0.9088 - val_loss: 0.4134 - val_accuracy: 0.8118\n",
      "Epoch 316/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9147 - val_loss: 0.4353 - val_accuracy: 0.8176\n",
      "Epoch 317/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2146 - accuracy: 0.9176 - val_loss: 0.4374 - val_accuracy: 0.8088\n",
      "Epoch 318/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2204 - accuracy: 0.9125 - val_loss: 0.4353 - val_accuracy: 0.8147\n",
      "Epoch 319/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2255 - accuracy: 0.9066 - val_loss: 0.4311 - val_accuracy: 0.8118\n",
      "Epoch 320/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9110 - val_loss: 0.4402 - val_accuracy: 0.8118\n",
      "Epoch 321/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2310 - accuracy: 0.9066 - val_loss: 0.4382 - val_accuracy: 0.8088\n",
      "Epoch 322/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2291 - accuracy: 0.9147 - val_loss: 0.4175 - val_accuracy: 0.8206\n",
      "Epoch 323/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9074 - val_loss: 0.4238 - val_accuracy: 0.8206\n",
      "Epoch 324/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9169 - val_loss: 0.4295 - val_accuracy: 0.8265\n",
      "Epoch 325/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.9176 - val_loss: 0.4164 - val_accuracy: 0.8235\n",
      "Epoch 326/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2190 - accuracy: 0.9125 - val_loss: 0.4179 - val_accuracy: 0.8235\n",
      "Epoch 327/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9110 - val_loss: 0.4179 - val_accuracy: 0.8206\n",
      "Epoch 328/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.9118 - val_loss: 0.4160 - val_accuracy: 0.8206\n",
      "Epoch 329/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9066 - val_loss: 0.4217 - val_accuracy: 0.8118\n",
      "Epoch 330/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2252 - accuracy: 0.9074 - val_loss: 0.4174 - val_accuracy: 0.8206\n",
      "Epoch 331/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2132 - accuracy: 0.9213 - val_loss: 0.4143 - val_accuracy: 0.8118\n",
      "Epoch 332/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.9169 - val_loss: 0.4236 - val_accuracy: 0.8265\n",
      "Epoch 333/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2224 - accuracy: 0.9140 - val_loss: 0.4385 - val_accuracy: 0.8088\n",
      "Epoch 334/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2277 - accuracy: 0.9118 - val_loss: 0.4756 - val_accuracy: 0.8118\n",
      "Epoch 335/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2246 - accuracy: 0.9125 - val_loss: 0.4616 - val_accuracy: 0.8235\n",
      "Epoch 336/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9206 - val_loss: 0.4513 - val_accuracy: 0.8206\n",
      "Epoch 337/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2272 - accuracy: 0.9154 - val_loss: 0.4435 - val_accuracy: 0.8235\n",
      "Epoch 338/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2035 - accuracy: 0.9088 - val_loss: 0.4517 - val_accuracy: 0.8176\n",
      "Epoch 339/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2101 - accuracy: 0.9191 - val_loss: 0.4538 - val_accuracy: 0.8294\n",
      "Epoch 340/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9206 - val_loss: 0.4517 - val_accuracy: 0.8235\n",
      "Epoch 341/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2243 - accuracy: 0.9154 - val_loss: 0.4406 - val_accuracy: 0.8147\n",
      "Epoch 342/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9125 - val_loss: 0.4386 - val_accuracy: 0.8118\n",
      "Epoch 343/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2172 - accuracy: 0.9162 - val_loss: 0.4293 - val_accuracy: 0.8118\n",
      "Epoch 344/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2124 - accuracy: 0.9184 - val_loss: 0.4290 - val_accuracy: 0.8265\n",
      "Epoch 345/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2329 - accuracy: 0.9118 - val_loss: 0.4153 - val_accuracy: 0.8353\n",
      "Epoch 346/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2111 - accuracy: 0.9169 - val_loss: 0.4243 - val_accuracy: 0.8265\n",
      "Epoch 347/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2174 - accuracy: 0.9213 - val_loss: 0.4309 - val_accuracy: 0.8265\n",
      "Epoch 348/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1969 - accuracy: 0.9191 - val_loss: 0.4178 - val_accuracy: 0.8294\n",
      "Epoch 349/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9228 - val_loss: 0.4121 - val_accuracy: 0.8235\n",
      "Epoch 350/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2046 - accuracy: 0.9199 - val_loss: 0.4086 - val_accuracy: 0.8265\n",
      "Epoch 351/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9066 - val_loss: 0.4068 - val_accuracy: 0.8265\n",
      "Epoch 352/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9265 - val_loss: 0.4043 - val_accuracy: 0.8324\n",
      "Epoch 353/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9206 - val_loss: 0.3995 - val_accuracy: 0.8265\n",
      "Epoch 354/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1982 - accuracy: 0.9265 - val_loss: 0.4108 - val_accuracy: 0.8265\n",
      "Epoch 355/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2177 - accuracy: 0.9184 - val_loss: 0.4296 - val_accuracy: 0.8206\n",
      "Epoch 356/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9154 - val_loss: 0.4097 - val_accuracy: 0.8294\n",
      "Epoch 357/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2042 - accuracy: 0.9213 - val_loss: 0.4212 - val_accuracy: 0.8235\n",
      "Epoch 358/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2084 - accuracy: 0.9191 - val_loss: 0.4206 - val_accuracy: 0.8206\n",
      "Epoch 359/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2104 - accuracy: 0.9147 - val_loss: 0.4364 - val_accuracy: 0.8235\n",
      "Epoch 360/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2052 - accuracy: 0.9243 - val_loss: 0.4223 - val_accuracy: 0.8265\n",
      "Epoch 361/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9228 - val_loss: 0.4277 - val_accuracy: 0.8147\n",
      "Epoch 362/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.9132 - val_loss: 0.4199 - val_accuracy: 0.8265\n",
      "Epoch 363/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2032 - accuracy: 0.9206 - val_loss: 0.4096 - val_accuracy: 0.8235\n",
      "Epoch 364/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9103 - val_loss: 0.4247 - val_accuracy: 0.8294\n",
      "Epoch 365/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2118 - accuracy: 0.9221 - val_loss: 0.4330 - val_accuracy: 0.8235\n",
      "Epoch 366/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2083 - accuracy: 0.9206 - val_loss: 0.4197 - val_accuracy: 0.8206\n",
      "Epoch 367/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9213 - val_loss: 0.4431 - val_accuracy: 0.8206\n",
      "Epoch 368/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2173 - accuracy: 0.9191 - val_loss: 0.4449 - val_accuracy: 0.8265\n",
      "Epoch 369/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2082 - accuracy: 0.9184 - val_loss: 0.4364 - val_accuracy: 0.8294\n",
      "Epoch 370/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2141 - accuracy: 0.9191 - val_loss: 0.4798 - val_accuracy: 0.8235\n",
      "Epoch 371/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2120 - accuracy: 0.9221 - val_loss: 0.4822 - val_accuracy: 0.8206\n",
      "Epoch 372/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2117 - accuracy: 0.9213 - val_loss: 0.4908 - val_accuracy: 0.8235\n",
      "Epoch 373/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2119 - accuracy: 0.9176 - val_loss: 0.4783 - val_accuracy: 0.8235\n",
      "Epoch 374/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9221 - val_loss: 0.4669 - val_accuracy: 0.8265\n",
      "Epoch 375/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1981 - accuracy: 0.9221 - val_loss: 0.4611 - val_accuracy: 0.8265\n",
      "Epoch 376/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2012 - accuracy: 0.9169 - val_loss: 0.4650 - val_accuracy: 0.8206\n",
      "Epoch 377/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1991 - accuracy: 0.9235 - val_loss: 0.4566 - val_accuracy: 0.8235\n",
      "Epoch 378/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2062 - accuracy: 0.9206 - val_loss: 0.4502 - val_accuracy: 0.8294\n",
      "Epoch 379/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9243 - val_loss: 0.4569 - val_accuracy: 0.8235\n",
      "Epoch 380/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9250 - val_loss: 0.4540 - val_accuracy: 0.8265\n",
      "Epoch 381/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1858 - accuracy: 0.9272 - val_loss: 0.4579 - val_accuracy: 0.8265\n",
      "Epoch 382/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9147 - val_loss: 0.4431 - val_accuracy: 0.8294\n",
      "Epoch 383/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.9265 - val_loss: 0.4407 - val_accuracy: 0.8294\n",
      "Epoch 384/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1892 - accuracy: 0.9250 - val_loss: 0.4371 - val_accuracy: 0.8412\n",
      "Epoch 385/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1932 - accuracy: 0.9257 - val_loss: 0.4204 - val_accuracy: 0.8382\n",
      "Epoch 386/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2125 - accuracy: 0.9199 - val_loss: 0.4300 - val_accuracy: 0.8294\n",
      "Epoch 387/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2043 - accuracy: 0.9206 - val_loss: 0.4473 - val_accuracy: 0.8265\n",
      "Epoch 388/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1912 - accuracy: 0.9324 - val_loss: 0.4403 - val_accuracy: 0.8412\n",
      "Epoch 389/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9287 - val_loss: 0.4340 - val_accuracy: 0.8265\n",
      "Epoch 390/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1876 - accuracy: 0.9309 - val_loss: 0.4214 - val_accuracy: 0.8294\n",
      "Epoch 391/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2077 - accuracy: 0.9191 - val_loss: 0.4372 - val_accuracy: 0.8412\n",
      "Epoch 392/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9206 - val_loss: 0.4404 - val_accuracy: 0.8353\n",
      "Epoch 393/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9294 - val_loss: 0.4561 - val_accuracy: 0.8265\n",
      "Epoch 394/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1934 - accuracy: 0.9191 - val_loss: 0.4689 - val_accuracy: 0.8265\n",
      "Epoch 395/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2017 - accuracy: 0.9309 - val_loss: 0.4348 - val_accuracy: 0.8324\n",
      "Epoch 396/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2094 - accuracy: 0.9243 - val_loss: 0.4438 - val_accuracy: 0.8324\n",
      "Epoch 397/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9294 - val_loss: 0.4572 - val_accuracy: 0.8265\n",
      "Epoch 398/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9272 - val_loss: 0.4687 - val_accuracy: 0.8235\n",
      "Epoch 399/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2143 - accuracy: 0.9265 - val_loss: 0.4597 - val_accuracy: 0.8265\n",
      "Epoch 400/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9265 - val_loss: 0.4361 - val_accuracy: 0.8441\n",
      "Epoch 401/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2134 - accuracy: 0.9162 - val_loss: 0.4296 - val_accuracy: 0.8353\n",
      "Epoch 402/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9279 - val_loss: 0.4243 - val_accuracy: 0.8235\n",
      "Epoch 403/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2123 - accuracy: 0.9103 - val_loss: 0.4467 - val_accuracy: 0.8294\n",
      "Epoch 404/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1937 - accuracy: 0.9301 - val_loss: 0.4339 - val_accuracy: 0.8412\n",
      "Epoch 405/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1956 - accuracy: 0.9169 - val_loss: 0.4368 - val_accuracy: 0.8412\n",
      "Epoch 406/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9360 - val_loss: 0.4318 - val_accuracy: 0.8412\n",
      "Epoch 407/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1930 - accuracy: 0.9199 - val_loss: 0.4475 - val_accuracy: 0.8412\n",
      "Epoch 408/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2010 - accuracy: 0.9176 - val_loss: 0.4349 - val_accuracy: 0.8206\n",
      "Epoch 409/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9162 - val_loss: 0.4288 - val_accuracy: 0.8294\n",
      "Epoch 410/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.9250 - val_loss: 0.4387 - val_accuracy: 0.8353\n",
      "Epoch 411/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9206 - val_loss: 0.4325 - val_accuracy: 0.8382\n",
      "Epoch 412/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1825 - accuracy: 0.9265 - val_loss: 0.4725 - val_accuracy: 0.8324\n",
      "Epoch 413/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9199 - val_loss: 0.4670 - val_accuracy: 0.8353\n",
      "Epoch 414/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9294 - val_loss: 0.4522 - val_accuracy: 0.8471\n",
      "Epoch 415/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1913 - accuracy: 0.9287 - val_loss: 0.4441 - val_accuracy: 0.8353\n",
      "Epoch 416/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9272 - val_loss: 0.4541 - val_accuracy: 0.8412\n",
      "Epoch 417/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1928 - accuracy: 0.9140 - val_loss: 0.4650 - val_accuracy: 0.8382\n",
      "Epoch 418/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9191 - val_loss: 0.4539 - val_accuracy: 0.8382\n",
      "Epoch 419/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1940 - accuracy: 0.9206 - val_loss: 0.4738 - val_accuracy: 0.8353\n",
      "Epoch 420/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2114 - accuracy: 0.9184 - val_loss: 0.4603 - val_accuracy: 0.8529\n",
      "Epoch 421/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1875 - accuracy: 0.9206 - val_loss: 0.4648 - val_accuracy: 0.8324\n",
      "Epoch 422/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9316 - val_loss: 0.4699 - val_accuracy: 0.8441\n",
      "Epoch 423/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1764 - accuracy: 0.9397 - val_loss: 0.4605 - val_accuracy: 0.8412\n",
      "Epoch 424/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9265 - val_loss: 0.4404 - val_accuracy: 0.8353\n",
      "Epoch 425/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1826 - accuracy: 0.9257 - val_loss: 0.4267 - val_accuracy: 0.8382\n",
      "Epoch 426/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.9235 - val_loss: 0.4291 - val_accuracy: 0.8382\n",
      "Epoch 427/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1813 - accuracy: 0.9397 - val_loss: 0.4229 - val_accuracy: 0.8324\n",
      "Epoch 428/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9235 - val_loss: 0.4253 - val_accuracy: 0.8324\n",
      "Epoch 429/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9309 - val_loss: 0.4348 - val_accuracy: 0.8471\n",
      "Epoch 430/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1963 - accuracy: 0.9235 - val_loss: 0.4423 - val_accuracy: 0.8294\n",
      "Epoch 431/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9265 - val_loss: 0.4421 - val_accuracy: 0.8382\n",
      "Epoch 432/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1791 - accuracy: 0.9353 - val_loss: 0.4418 - val_accuracy: 0.8412\n",
      "Epoch 433/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2024 - accuracy: 0.9279 - val_loss: 0.4452 - val_accuracy: 0.8382\n",
      "Epoch 434/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9272 - val_loss: 0.4577 - val_accuracy: 0.8324\n",
      "Epoch 435/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9287 - val_loss: 0.4654 - val_accuracy: 0.8324\n",
      "Epoch 436/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1665 - accuracy: 0.9316 - val_loss: 0.4542 - val_accuracy: 0.8294\n",
      "Epoch 437/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.9228 - val_loss: 0.4433 - val_accuracy: 0.8412\n",
      "Epoch 438/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1927 - accuracy: 0.9176 - val_loss: 0.4762 - val_accuracy: 0.8412\n",
      "Epoch 439/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1783 - accuracy: 0.9346 - val_loss: 0.4875 - val_accuracy: 0.8235\n",
      "Epoch 440/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9294 - val_loss: 0.4699 - val_accuracy: 0.8353\n",
      "Epoch 441/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9294 - val_loss: 0.4832 - val_accuracy: 0.8353\n",
      "Epoch 442/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1908 - accuracy: 0.9213 - val_loss: 0.4493 - val_accuracy: 0.8353\n",
      "Epoch 443/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9382 - val_loss: 0.4511 - val_accuracy: 0.8382\n",
      "Epoch 444/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1886 - accuracy: 0.9213 - val_loss: 0.4589 - val_accuracy: 0.8412\n",
      "Epoch 445/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1881 - accuracy: 0.9309 - val_loss: 0.4686 - val_accuracy: 0.8441\n",
      "Epoch 446/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1766 - accuracy: 0.9397 - val_loss: 0.4680 - val_accuracy: 0.8412\n",
      "Epoch 447/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1752 - accuracy: 0.9360 - val_loss: 0.4556 - val_accuracy: 0.8471\n",
      "Epoch 448/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1695 - accuracy: 0.9353 - val_loss: 0.4583 - val_accuracy: 0.8353\n",
      "Epoch 449/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1746 - accuracy: 0.9375 - val_loss: 0.4726 - val_accuracy: 0.8324\n",
      "Epoch 450/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1836 - accuracy: 0.9316 - val_loss: 0.4647 - val_accuracy: 0.8265\n",
      "Epoch 451/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1910 - accuracy: 0.9287 - val_loss: 0.4626 - val_accuracy: 0.8294\n",
      "Epoch 452/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9294 - val_loss: 0.4639 - val_accuracy: 0.8412\n",
      "Epoch 453/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1717 - accuracy: 0.9390 - val_loss: 0.4812 - val_accuracy: 0.8265\n",
      "Epoch 454/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1702 - accuracy: 0.9338 - val_loss: 0.4888 - val_accuracy: 0.8265\n",
      "Epoch 455/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9250 - val_loss: 0.4762 - val_accuracy: 0.8206\n",
      "Epoch 456/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1915 - accuracy: 0.9250 - val_loss: 0.4980 - val_accuracy: 0.8147\n",
      "Epoch 457/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1744 - accuracy: 0.9360 - val_loss: 0.4886 - val_accuracy: 0.8206\n",
      "Epoch 458/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1709 - accuracy: 0.9412 - val_loss: 0.4744 - val_accuracy: 0.8176\n",
      "Epoch 459/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1852 - accuracy: 0.9360 - val_loss: 0.4762 - val_accuracy: 0.8265\n",
      "Epoch 460/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1876 - accuracy: 0.9257 - val_loss: 0.4568 - val_accuracy: 0.8324\n",
      "Epoch 461/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9287 - val_loss: 0.4545 - val_accuracy: 0.8382\n",
      "Epoch 462/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9449 - val_loss: 0.4282 - val_accuracy: 0.8382\n",
      "Epoch 463/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1811 - accuracy: 0.9301 - val_loss: 0.4573 - val_accuracy: 0.8471\n",
      "Epoch 464/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9346 - val_loss: 0.4501 - val_accuracy: 0.8471\n",
      "Epoch 465/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1784 - accuracy: 0.9360 - val_loss: 0.4533 - val_accuracy: 0.8441\n",
      "Epoch 466/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1731 - accuracy: 0.9279 - val_loss: 0.4402 - val_accuracy: 0.8353\n",
      "Epoch 467/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1873 - accuracy: 0.9250 - val_loss: 0.4582 - val_accuracy: 0.8471\n",
      "Epoch 468/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1914 - accuracy: 0.9294 - val_loss: 0.4547 - val_accuracy: 0.8294\n",
      "Epoch 469/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9412 - val_loss: 0.4366 - val_accuracy: 0.8412\n",
      "Epoch 470/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1758 - accuracy: 0.9324 - val_loss: 0.4359 - val_accuracy: 0.8412\n",
      "Epoch 471/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9331 - val_loss: 0.4412 - val_accuracy: 0.8412\n",
      "Epoch 472/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9404 - val_loss: 0.4444 - val_accuracy: 0.8353\n",
      "Epoch 473/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9324 - val_loss: 0.4454 - val_accuracy: 0.8265\n",
      "Epoch 474/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1888 - accuracy: 0.9250 - val_loss: 0.4351 - val_accuracy: 0.8235\n",
      "Epoch 475/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1766 - accuracy: 0.9309 - val_loss: 0.4542 - val_accuracy: 0.8235\n",
      "Epoch 476/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9382 - val_loss: 0.4507 - val_accuracy: 0.8265\n",
      "Epoch 477/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1865 - accuracy: 0.9338 - val_loss: 0.4707 - val_accuracy: 0.8294\n",
      "Epoch 478/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1680 - accuracy: 0.9360 - val_loss: 0.4578 - val_accuracy: 0.8265\n",
      "Epoch 479/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1800 - accuracy: 0.9265 - val_loss: 0.5066 - val_accuracy: 0.8294\n",
      "Epoch 480/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1832 - accuracy: 0.9331 - val_loss: 0.4901 - val_accuracy: 0.8324\n",
      "Epoch 481/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2036 - accuracy: 0.9184 - val_loss: 0.4789 - val_accuracy: 0.8412\n",
      "Epoch 482/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1628 - accuracy: 0.9485 - val_loss: 0.4731 - val_accuracy: 0.8265\n",
      "Epoch 483/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1803 - accuracy: 0.9309 - val_loss: 0.4685 - val_accuracy: 0.8353\n",
      "Epoch 484/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1872 - accuracy: 0.9279 - val_loss: 0.4701 - val_accuracy: 0.8294\n",
      "Epoch 485/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1798 - accuracy: 0.9338 - val_loss: 0.4729 - val_accuracy: 0.8265\n",
      "Epoch 486/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1644 - accuracy: 0.9390 - val_loss: 0.4585 - val_accuracy: 0.8294\n",
      "Epoch 487/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9294 - val_loss: 0.4739 - val_accuracy: 0.8353\n",
      "Epoch 488/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9390 - val_loss: 0.4643 - val_accuracy: 0.8324\n",
      "Epoch 489/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1829 - accuracy: 0.9243 - val_loss: 0.4693 - val_accuracy: 0.8353\n",
      "Epoch 490/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1958 - accuracy: 0.9228 - val_loss: 0.4598 - val_accuracy: 0.8265\n",
      "Epoch 491/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9316 - val_loss: 0.4425 - val_accuracy: 0.8471\n",
      "Epoch 492/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9243 - val_loss: 0.4327 - val_accuracy: 0.8500\n",
      "Epoch 493/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1689 - accuracy: 0.9301 - val_loss: 0.4236 - val_accuracy: 0.8441\n",
      "Epoch 494/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1542 - accuracy: 0.9441 - val_loss: 0.4415 - val_accuracy: 0.8412\n",
      "Epoch 495/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9426 - val_loss: 0.4435 - val_accuracy: 0.8441\n",
      "Epoch 496/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9360 - val_loss: 0.4494 - val_accuracy: 0.8353\n",
      "Epoch 497/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9434 - val_loss: 0.4526 - val_accuracy: 0.8471\n",
      "Epoch 498/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9301 - val_loss: 0.4535 - val_accuracy: 0.8353\n",
      "Epoch 499/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9331 - val_loss: 0.4826 - val_accuracy: 0.8324\n",
      "Epoch 500/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9463 - val_loss: 0.4825 - val_accuracy: 0.8324\n",
      "Epoch 501/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1786 - accuracy: 0.9279 - val_loss: 0.4724 - val_accuracy: 0.8324\n",
      "Epoch 502/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1762 - accuracy: 0.9338 - val_loss: 0.4832 - val_accuracy: 0.8382\n",
      "Epoch 503/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9485 - val_loss: 0.4769 - val_accuracy: 0.8353\n",
      "Epoch 504/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9382 - val_loss: 0.4969 - val_accuracy: 0.8118\n",
      "Epoch 505/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1821 - accuracy: 0.9426 - val_loss: 0.4802 - val_accuracy: 0.8353\n",
      "Epoch 506/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1667 - accuracy: 0.9434 - val_loss: 0.4682 - val_accuracy: 0.8294\n",
      "Epoch 507/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1765 - accuracy: 0.9324 - val_loss: 0.4514 - val_accuracy: 0.8500\n",
      "Epoch 508/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1713 - accuracy: 0.9412 - val_loss: 0.4467 - val_accuracy: 0.8382\n",
      "Epoch 509/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1563 - accuracy: 0.9426 - val_loss: 0.4551 - val_accuracy: 0.8294\n",
      "Epoch 510/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9368 - val_loss: 0.4573 - val_accuracy: 0.8294\n",
      "Epoch 511/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1846 - accuracy: 0.9294 - val_loss: 0.4477 - val_accuracy: 0.8294\n",
      "Epoch 512/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1704 - accuracy: 0.9301 - val_loss: 0.4894 - val_accuracy: 0.8324\n",
      "Epoch 513/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1622 - accuracy: 0.9441 - val_loss: 0.5024 - val_accuracy: 0.8353\n",
      "Epoch 514/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9353 - val_loss: 0.4742 - val_accuracy: 0.8294\n",
      "Epoch 515/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9404 - val_loss: 0.4636 - val_accuracy: 0.8382\n",
      "Epoch 516/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1656 - accuracy: 0.9412 - val_loss: 0.4515 - val_accuracy: 0.8324\n",
      "Epoch 517/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9404 - val_loss: 0.4472 - val_accuracy: 0.8382\n",
      "Epoch 518/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1701 - accuracy: 0.9316 - val_loss: 0.4620 - val_accuracy: 0.8235\n",
      "Epoch 519/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9338 - val_loss: 0.4560 - val_accuracy: 0.8265\n",
      "Epoch 520/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9449 - val_loss: 0.4566 - val_accuracy: 0.8353\n",
      "Epoch 521/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1670 - accuracy: 0.9360 - val_loss: 0.4654 - val_accuracy: 0.8382\n",
      "Epoch 522/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9397 - val_loss: 0.4610 - val_accuracy: 0.8382\n",
      "Epoch 523/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9397 - val_loss: 0.4719 - val_accuracy: 0.8324\n",
      "Epoch 524/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1756 - accuracy: 0.9309 - val_loss: 0.4623 - val_accuracy: 0.8353\n",
      "Epoch 525/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9500 - val_loss: 0.4622 - val_accuracy: 0.8235\n",
      "Epoch 526/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9382 - val_loss: 0.4554 - val_accuracy: 0.8294\n",
      "Epoch 527/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1745 - accuracy: 0.9368 - val_loss: 0.4615 - val_accuracy: 0.8382\n",
      "Epoch 528/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9368 - val_loss: 0.4410 - val_accuracy: 0.8441\n",
      "Epoch 529/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1769 - accuracy: 0.9434 - val_loss: 0.4388 - val_accuracy: 0.8441\n",
      "Epoch 530/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1799 - accuracy: 0.9294 - val_loss: 0.4517 - val_accuracy: 0.8353\n",
      "Epoch 531/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1673 - accuracy: 0.9324 - val_loss: 0.4824 - val_accuracy: 0.8235\n",
      "Epoch 532/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9346 - val_loss: 0.4492 - val_accuracy: 0.8294\n",
      "Epoch 533/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1664 - accuracy: 0.9360 - val_loss: 0.4467 - val_accuracy: 0.8441\n",
      "Epoch 534/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1503 - accuracy: 0.9441 - val_loss: 0.4488 - val_accuracy: 0.8412\n",
      "Epoch 535/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1687 - accuracy: 0.9434 - val_loss: 0.4349 - val_accuracy: 0.8412\n",
      "Epoch 536/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1647 - accuracy: 0.9441 - val_loss: 0.4592 - val_accuracy: 0.8412\n",
      "Epoch 537/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1684 - accuracy: 0.9368 - val_loss: 0.4447 - val_accuracy: 0.8382\n",
      "Epoch 538/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9397 - val_loss: 0.4428 - val_accuracy: 0.8353\n",
      "Epoch 539/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1547 - accuracy: 0.9471 - val_loss: 0.4158 - val_accuracy: 0.8324\n",
      "Epoch 540/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1587 - accuracy: 0.9463 - val_loss: 0.4405 - val_accuracy: 0.8353\n",
      "Epoch 541/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1668 - accuracy: 0.9346 - val_loss: 0.4574 - val_accuracy: 0.8382\n",
      "Epoch 542/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1538 - accuracy: 0.9441 - val_loss: 0.4563 - val_accuracy: 0.8412\n",
      "Epoch 543/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1651 - accuracy: 0.9412 - val_loss: 0.4494 - val_accuracy: 0.8265\n",
      "Epoch 544/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1800 - accuracy: 0.9301 - val_loss: 0.4570 - val_accuracy: 0.8353\n",
      "Epoch 545/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1716 - accuracy: 0.9449 - val_loss: 0.4590 - val_accuracy: 0.8353\n",
      "Epoch 546/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9353 - val_loss: 0.4646 - val_accuracy: 0.8235\n",
      "Epoch 547/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1592 - accuracy: 0.9368 - val_loss: 0.4798 - val_accuracy: 0.8412\n",
      "Epoch 548/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1558 - accuracy: 0.9368 - val_loss: 0.4913 - val_accuracy: 0.8382\n",
      "Epoch 549/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1686 - accuracy: 0.9397 - val_loss: 0.4851 - val_accuracy: 0.8412\n",
      "Epoch 550/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1535 - accuracy: 0.9463 - val_loss: 0.4895 - val_accuracy: 0.8294\n",
      "Epoch 551/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1527 - accuracy: 0.9441 - val_loss: 0.4680 - val_accuracy: 0.8206\n",
      "Epoch 552/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9463 - val_loss: 0.4658 - val_accuracy: 0.8235\n",
      "Epoch 553/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1648 - accuracy: 0.9397 - val_loss: 0.4528 - val_accuracy: 0.8294\n",
      "Epoch 554/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9390 - val_loss: 0.4323 - val_accuracy: 0.8265\n",
      "Epoch 555/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9419 - val_loss: 0.4604 - val_accuracy: 0.8353\n",
      "Epoch 556/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9353 - val_loss: 0.4812 - val_accuracy: 0.8382\n",
      "Epoch 557/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1854 - accuracy: 0.9368 - val_loss: 0.4654 - val_accuracy: 0.8382\n",
      "Epoch 558/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1735 - accuracy: 0.9390 - val_loss: 0.5103 - val_accuracy: 0.8294\n",
      "Epoch 559/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9404 - val_loss: 0.5020 - val_accuracy: 0.8265\n",
      "Epoch 560/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1724 - accuracy: 0.9353 - val_loss: 0.4683 - val_accuracy: 0.8382\n",
      "Epoch 561/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1608 - accuracy: 0.9426 - val_loss: 0.4767 - val_accuracy: 0.8382\n",
      "Epoch 562/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9397 - val_loss: 0.4663 - val_accuracy: 0.8412\n",
      "Epoch 563/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9360 - val_loss: 0.4755 - val_accuracy: 0.8235\n",
      "Epoch 564/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9375 - val_loss: 0.5079 - val_accuracy: 0.8324\n",
      "Epoch 565/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9375 - val_loss: 0.4786 - val_accuracy: 0.8294\n",
      "Epoch 566/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1399 - accuracy: 0.9507 - val_loss: 0.4691 - val_accuracy: 0.8353\n",
      "Epoch 567/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9441 - val_loss: 0.4485 - val_accuracy: 0.8353\n",
      "Epoch 568/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1658 - accuracy: 0.9331 - val_loss: 0.4345 - val_accuracy: 0.8500\n",
      "Epoch 569/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9471 - val_loss: 0.4474 - val_accuracy: 0.8441\n",
      "Epoch 570/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1631 - accuracy: 0.9382 - val_loss: 0.4575 - val_accuracy: 0.8382\n",
      "Epoch 571/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9449 - val_loss: 0.4542 - val_accuracy: 0.8412\n",
      "Epoch 572/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1621 - accuracy: 0.9456 - val_loss: 0.4602 - val_accuracy: 0.8324\n",
      "Epoch 573/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9346 - val_loss: 0.4563 - val_accuracy: 0.8353\n",
      "Epoch 574/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1630 - accuracy: 0.9397 - val_loss: 0.4595 - val_accuracy: 0.8324\n",
      "Epoch 575/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9471 - val_loss: 0.4521 - val_accuracy: 0.8324\n",
      "Epoch 576/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9404 - val_loss: 0.4371 - val_accuracy: 0.8265\n",
      "Epoch 577/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1597 - accuracy: 0.9412 - val_loss: 0.4769 - val_accuracy: 0.8265\n",
      "Epoch 578/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9471 - val_loss: 0.4665 - val_accuracy: 0.8382\n",
      "Epoch 579/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1455 - accuracy: 0.9500 - val_loss: 0.4615 - val_accuracy: 0.8294\n",
      "Epoch 580/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1877 - accuracy: 0.9522 - val_loss: 0.4941 - val_accuracy: 0.8353\n",
      "Epoch 581/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1824 - accuracy: 0.9397 - val_loss: 0.4992 - val_accuracy: 0.8294\n",
      "Epoch 582/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9485 - val_loss: 0.4621 - val_accuracy: 0.8324\n",
      "Epoch 583/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9426 - val_loss: 0.4583 - val_accuracy: 0.8353\n",
      "Epoch 584/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9471 - val_loss: 0.4518 - val_accuracy: 0.8441\n",
      "Epoch 585/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9449 - val_loss: 0.4510 - val_accuracy: 0.8353\n",
      "Epoch 586/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9478 - val_loss: 0.4720 - val_accuracy: 0.8206\n",
      "Epoch 587/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1579 - accuracy: 0.9412 - val_loss: 0.4932 - val_accuracy: 0.8412\n",
      "Epoch 588/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1659 - accuracy: 0.9397 - val_loss: 0.4971 - val_accuracy: 0.8382\n",
      "Epoch 589/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9309 - val_loss: 0.5055 - val_accuracy: 0.8294\n",
      "Epoch 590/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1668 - accuracy: 0.9368 - val_loss: 0.4766 - val_accuracy: 0.8324\n",
      "Epoch 591/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9463 - val_loss: 0.4773 - val_accuracy: 0.8235\n",
      "Epoch 592/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9449 - val_loss: 0.4899 - val_accuracy: 0.8235\n",
      "Epoch 593/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9412 - val_loss: 0.4707 - val_accuracy: 0.8265\n",
      "Epoch 594/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.9419 - val_loss: 0.4650 - val_accuracy: 0.8265\n",
      "Epoch 595/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1513 - accuracy: 0.9434 - val_loss: 0.4677 - val_accuracy: 0.8324\n",
      "Epoch 596/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9500 - val_loss: 0.4661 - val_accuracy: 0.8265\n",
      "Epoch 597/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1566 - accuracy: 0.9426 - val_loss: 0.4645 - val_accuracy: 0.8235\n",
      "Epoch 598/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9537 - val_loss: 0.4767 - val_accuracy: 0.8147\n",
      "Epoch 599/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9485 - val_loss: 0.5063 - val_accuracy: 0.8147\n",
      "Epoch 600/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9368 - val_loss: 0.5029 - val_accuracy: 0.8118\n",
      "Epoch 601/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9551 - val_loss: 0.4871 - val_accuracy: 0.8265\n",
      "Epoch 602/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9559 - val_loss: 0.4962 - val_accuracy: 0.8382\n",
      "Epoch 603/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1596 - accuracy: 0.9471 - val_loss: 0.4995 - val_accuracy: 0.8265\n",
      "Epoch 604/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9397 - val_loss: 0.4948 - val_accuracy: 0.8235\n",
      "Epoch 605/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.9331 - val_loss: 0.5010 - val_accuracy: 0.8294\n",
      "Epoch 606/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9500 - val_loss: 0.4868 - val_accuracy: 0.8353\n",
      "Epoch 607/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9434 - val_loss: 0.5150 - val_accuracy: 0.8265\n",
      "Epoch 608/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1534 - accuracy: 0.9404 - val_loss: 0.5106 - val_accuracy: 0.8324\n",
      "Epoch 609/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9449 - val_loss: 0.4972 - val_accuracy: 0.8294\n",
      "Epoch 610/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1543 - accuracy: 0.9471 - val_loss: 0.4928 - val_accuracy: 0.8265\n",
      "Epoch 611/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9456 - val_loss: 0.5054 - val_accuracy: 0.8324\n",
      "Epoch 612/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1553 - accuracy: 0.9434 - val_loss: 0.5090 - val_accuracy: 0.8206\n",
      "Epoch 613/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1436 - accuracy: 0.9485 - val_loss: 0.5004 - val_accuracy: 0.8353\n",
      "Epoch 614/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1518 - accuracy: 0.9507 - val_loss: 0.4955 - val_accuracy: 0.8382\n",
      "Epoch 615/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1570 - accuracy: 0.9463 - val_loss: 0.4886 - val_accuracy: 0.8294\n",
      "Epoch 616/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1481 - accuracy: 0.9500 - val_loss: 0.4802 - val_accuracy: 0.8412\n",
      "Epoch 617/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9412 - val_loss: 0.4969 - val_accuracy: 0.8382\n",
      "Epoch 618/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1479 - accuracy: 0.9463 - val_loss: 0.5204 - val_accuracy: 0.8353\n",
      "Epoch 619/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1697 - accuracy: 0.9397 - val_loss: 0.4930 - val_accuracy: 0.8353\n",
      "Epoch 620/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9426 - val_loss: 0.4699 - val_accuracy: 0.8353\n",
      "Epoch 621/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9515 - val_loss: 0.4708 - val_accuracy: 0.8441\n",
      "Epoch 622/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9515 - val_loss: 0.4965 - val_accuracy: 0.8353\n",
      "Epoch 623/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9441 - val_loss: 0.4977 - val_accuracy: 0.8294\n",
      "Epoch 624/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9434 - val_loss: 0.4941 - val_accuracy: 0.8294\n",
      "Epoch 625/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1453 - accuracy: 0.9544 - val_loss: 0.4727 - val_accuracy: 0.8412\n",
      "Epoch 626/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9500 - val_loss: 0.4769 - val_accuracy: 0.8471\n",
      "Epoch 627/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9515 - val_loss: 0.4729 - val_accuracy: 0.8382\n",
      "Epoch 628/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1282 - accuracy: 0.9478 - val_loss: 0.4687 - val_accuracy: 0.8412\n",
      "Epoch 629/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1445 - accuracy: 0.9507 - val_loss: 0.4778 - val_accuracy: 0.8412\n",
      "Epoch 630/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9397 - val_loss: 0.4723 - val_accuracy: 0.8353\n",
      "Epoch 631/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1456 - accuracy: 0.9456 - val_loss: 0.4766 - val_accuracy: 0.8235\n",
      "Epoch 632/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1759 - accuracy: 0.9412 - val_loss: 0.4736 - val_accuracy: 0.8265\n",
      "Epoch 633/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1525 - accuracy: 0.9434 - val_loss: 0.5036 - val_accuracy: 0.8294\n",
      "Epoch 634/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2244 - accuracy: 0.9404 - val_loss: 0.4990 - val_accuracy: 0.8176\n",
      "Epoch 635/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1493 - accuracy: 0.9449 - val_loss: 0.5169 - val_accuracy: 0.8147\n",
      "Epoch 636/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9434 - val_loss: 0.5030 - val_accuracy: 0.8118\n",
      "Epoch 637/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9390 - val_loss: 0.4936 - val_accuracy: 0.8206\n",
      "Epoch 638/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1575 - accuracy: 0.9478 - val_loss: 0.4528 - val_accuracy: 0.8265\n",
      "Epoch 639/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1578 - accuracy: 0.9441 - val_loss: 0.4434 - val_accuracy: 0.8265\n",
      "Epoch 640/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9441 - val_loss: 0.4444 - val_accuracy: 0.8206\n",
      "Epoch 641/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9588 - val_loss: 0.4366 - val_accuracy: 0.8353\n",
      "Epoch 642/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1609 - accuracy: 0.9412 - val_loss: 0.4403 - val_accuracy: 0.8265\n",
      "Epoch 643/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9493 - val_loss: 0.4367 - val_accuracy: 0.8265\n",
      "Epoch 644/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9456 - val_loss: 0.4385 - val_accuracy: 0.8353\n",
      "Epoch 645/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9529 - val_loss: 0.4388 - val_accuracy: 0.8324\n",
      "Epoch 646/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1416 - accuracy: 0.9449 - val_loss: 0.4377 - val_accuracy: 0.8324\n",
      "Epoch 647/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1529 - accuracy: 0.9456 - val_loss: 0.4429 - val_accuracy: 0.8294\n",
      "Epoch 648/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1404 - accuracy: 0.9456 - val_loss: 0.4574 - val_accuracy: 0.8324\n",
      "Epoch 649/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9463 - val_loss: 0.4373 - val_accuracy: 0.8500\n",
      "Epoch 650/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9522 - val_loss: 0.4444 - val_accuracy: 0.8353\n",
      "Epoch 651/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1675 - accuracy: 0.9485 - val_loss: 0.4625 - val_accuracy: 0.8324\n",
      "Epoch 652/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9434 - val_loss: 0.4611 - val_accuracy: 0.8206\n",
      "Epoch 653/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1505 - accuracy: 0.9412 - val_loss: 0.4943 - val_accuracy: 0.8206\n",
      "Epoch 654/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1478 - accuracy: 0.9449 - val_loss: 0.4817 - val_accuracy: 0.8353\n",
      "Epoch 655/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9537 - val_loss: 0.5015 - val_accuracy: 0.8265\n",
      "Epoch 656/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1472 - accuracy: 0.9478 - val_loss: 0.4874 - val_accuracy: 0.8206\n",
      "Epoch 657/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1567 - accuracy: 0.9412 - val_loss: 0.5011 - val_accuracy: 0.8235\n",
      "Epoch 658/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1615 - accuracy: 0.9390 - val_loss: 0.4843 - val_accuracy: 0.8294\n",
      "Epoch 659/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9618 - val_loss: 0.4793 - val_accuracy: 0.8324\n",
      "Epoch 660/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9522 - val_loss: 0.4841 - val_accuracy: 0.8206\n",
      "Epoch 661/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1179 - accuracy: 0.9581 - val_loss: 0.4668 - val_accuracy: 0.8294\n",
      "Epoch 662/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1313 - accuracy: 0.9507 - val_loss: 0.4661 - val_accuracy: 0.8206\n",
      "Epoch 663/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1511 - accuracy: 0.9434 - val_loss: 0.4408 - val_accuracy: 0.8235\n",
      "Epoch 664/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9551 - val_loss: 0.4754 - val_accuracy: 0.8324\n",
      "Epoch 665/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1545 - accuracy: 0.9382 - val_loss: 0.4735 - val_accuracy: 0.8353\n",
      "Epoch 666/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9375 - val_loss: 0.4720 - val_accuracy: 0.8206\n",
      "Epoch 667/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1506 - accuracy: 0.9537 - val_loss: 0.4757 - val_accuracy: 0.8324\n",
      "Epoch 668/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9434 - val_loss: 0.4668 - val_accuracy: 0.8235\n",
      "Epoch 669/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1488 - accuracy: 0.9493 - val_loss: 0.4716 - val_accuracy: 0.8265\n",
      "Epoch 670/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9515 - val_loss: 0.4680 - val_accuracy: 0.8324\n",
      "Epoch 671/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1423 - accuracy: 0.9485 - val_loss: 0.4839 - val_accuracy: 0.8382\n",
      "Epoch 672/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1497 - accuracy: 0.9404 - val_loss: 0.4860 - val_accuracy: 0.8324\n",
      "Epoch 673/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9507 - val_loss: 0.4759 - val_accuracy: 0.8441\n",
      "Epoch 674/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9522 - val_loss: 0.4780 - val_accuracy: 0.8382\n",
      "Epoch 675/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9515 - val_loss: 0.4867 - val_accuracy: 0.8382\n",
      "Epoch 676/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9566 - val_loss: 0.4720 - val_accuracy: 0.8471\n",
      "Epoch 677/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1417 - accuracy: 0.9471 - val_loss: 0.4877 - val_accuracy: 0.8206\n",
      "Epoch 678/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9507 - val_loss: 0.4915 - val_accuracy: 0.8353\n",
      "Epoch 679/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9515 - val_loss: 0.5014 - val_accuracy: 0.8235\n",
      "Epoch 680/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9507 - val_loss: 0.5214 - val_accuracy: 0.8176\n",
      "Epoch 681/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9588 - val_loss: 0.4957 - val_accuracy: 0.8353\n",
      "Epoch 682/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1700 - accuracy: 0.9419 - val_loss: 0.5475 - val_accuracy: 0.8294\n",
      "Epoch 683/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9463 - val_loss: 0.5799 - val_accuracy: 0.8265\n",
      "Epoch 684/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1515 - accuracy: 0.9434 - val_loss: 0.5384 - val_accuracy: 0.8206\n",
      "Epoch 685/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9390 - val_loss: 0.5105 - val_accuracy: 0.8206\n",
      "Epoch 686/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1494 - accuracy: 0.9522 - val_loss: 0.4981 - val_accuracy: 0.8206\n",
      "Epoch 687/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9500 - val_loss: 0.4985 - val_accuracy: 0.8294\n",
      "Epoch 688/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1350 - accuracy: 0.9382 - val_loss: 0.4970 - val_accuracy: 0.8235\n",
      "Epoch 689/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1380 - accuracy: 0.9471 - val_loss: 0.4889 - val_accuracy: 0.8324\n",
      "Epoch 690/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9507 - val_loss: 0.4785 - val_accuracy: 0.8353\n",
      "Epoch 691/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9426 - val_loss: 0.5040 - val_accuracy: 0.8176\n",
      "Epoch 692/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9478 - val_loss: 0.4829 - val_accuracy: 0.8265\n",
      "Epoch 693/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9500 - val_loss: 0.4792 - val_accuracy: 0.8324\n",
      "Epoch 694/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9551 - val_loss: 0.4892 - val_accuracy: 0.8294\n",
      "Epoch 695/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9515 - val_loss: 0.4892 - val_accuracy: 0.8324\n",
      "Epoch 696/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9537 - val_loss: 0.4875 - val_accuracy: 0.8294\n",
      "Epoch 697/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1394 - accuracy: 0.9485 - val_loss: 0.4694 - val_accuracy: 0.8294\n",
      "Epoch 698/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9551 - val_loss: 0.5030 - val_accuracy: 0.8235\n",
      "Epoch 699/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1827 - accuracy: 0.9493 - val_loss: 0.4977 - val_accuracy: 0.8265\n",
      "Epoch 700/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9529 - val_loss: 0.5031 - val_accuracy: 0.8206\n",
      "Epoch 701/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1239 - accuracy: 0.9566 - val_loss: 0.5003 - val_accuracy: 0.8382\n",
      "Epoch 702/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9441 - val_loss: 0.5260 - val_accuracy: 0.8382\n",
      "Epoch 703/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1508 - accuracy: 0.9471 - val_loss: 0.5159 - val_accuracy: 0.8265\n",
      "Epoch 704/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9551 - val_loss: 0.5458 - val_accuracy: 0.8324\n",
      "Epoch 705/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1378 - accuracy: 0.9537 - val_loss: 0.5276 - val_accuracy: 0.8294\n",
      "Epoch 706/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9581 - val_loss: 0.5301 - val_accuracy: 0.8324\n",
      "Epoch 707/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9544 - val_loss: 0.5124 - val_accuracy: 0.8471\n",
      "Epoch 708/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1314 - accuracy: 0.9507 - val_loss: 0.5235 - val_accuracy: 0.8235\n",
      "Epoch 709/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9507 - val_loss: 0.5168 - val_accuracy: 0.8235\n",
      "Epoch 710/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9581 - val_loss: 0.5033 - val_accuracy: 0.8265\n",
      "Epoch 711/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9471 - val_loss: 0.5007 - val_accuracy: 0.8324\n",
      "Epoch 712/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1306 - accuracy: 0.9537 - val_loss: 0.5263 - val_accuracy: 0.8206\n",
      "Epoch 713/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9529 - val_loss: 0.5490 - val_accuracy: 0.8265\n",
      "Epoch 714/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1775 - accuracy: 0.9529 - val_loss: 0.5343 - val_accuracy: 0.8235\n",
      "Epoch 715/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9596 - val_loss: 0.5249 - val_accuracy: 0.8235\n",
      "Epoch 716/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9529 - val_loss: 0.5134 - val_accuracy: 0.8324\n",
      "Epoch 717/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9485 - val_loss: 0.5772 - val_accuracy: 0.8294\n",
      "Epoch 718/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9434 - val_loss: 0.5664 - val_accuracy: 0.8265\n",
      "Epoch 719/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9551 - val_loss: 0.5159 - val_accuracy: 0.8235\n",
      "Epoch 720/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9507 - val_loss: 0.4942 - val_accuracy: 0.8294\n",
      "Epoch 721/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1190 - accuracy: 0.9544 - val_loss: 0.4784 - val_accuracy: 0.8235\n",
      "Epoch 722/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9632 - val_loss: 0.4665 - val_accuracy: 0.8265\n",
      "Epoch 723/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1573 - accuracy: 0.9485 - val_loss: 0.4877 - val_accuracy: 0.8382\n",
      "Epoch 724/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1389 - accuracy: 0.9463 - val_loss: 0.5916 - val_accuracy: 0.8294\n",
      "Epoch 725/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9515 - val_loss: 0.5879 - val_accuracy: 0.8324\n",
      "Epoch 726/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1526 - accuracy: 0.9434 - val_loss: 0.5889 - val_accuracy: 0.8176\n",
      "Epoch 727/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9588 - val_loss: 0.5679 - val_accuracy: 0.8353\n",
      "Epoch 728/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9559 - val_loss: 0.5404 - val_accuracy: 0.8382\n",
      "Epoch 729/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1285 - accuracy: 0.9522 - val_loss: 0.5347 - val_accuracy: 0.8441\n",
      "Epoch 730/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9610 - val_loss: 0.5286 - val_accuracy: 0.8353\n",
      "Epoch 731/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9360 - val_loss: 0.5234 - val_accuracy: 0.8265\n",
      "Epoch 732/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9529 - val_loss: 0.5269 - val_accuracy: 0.8441\n",
      "Epoch 733/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9529 - val_loss: 0.5261 - val_accuracy: 0.8382\n",
      "Epoch 734/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9566 - val_loss: 0.5249 - val_accuracy: 0.8294\n",
      "Epoch 735/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1523 - accuracy: 0.9485 - val_loss: 0.5166 - val_accuracy: 0.8412\n",
      "Epoch 736/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1661 - accuracy: 0.9434 - val_loss: 0.5282 - val_accuracy: 0.8206\n",
      "Epoch 737/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9529 - val_loss: 0.5219 - val_accuracy: 0.8353\n",
      "Epoch 738/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1365 - accuracy: 0.9500 - val_loss: 0.5197 - val_accuracy: 0.8324\n",
      "Epoch 739/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9500 - val_loss: 0.5039 - val_accuracy: 0.8441\n",
      "Epoch 740/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1280 - accuracy: 0.9566 - val_loss: 0.5275 - val_accuracy: 0.8324\n",
      "Epoch 741/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9529 - val_loss: 0.5354 - val_accuracy: 0.8324\n",
      "Epoch 742/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9507 - val_loss: 0.5150 - val_accuracy: 0.8294\n",
      "Epoch 743/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1489 - accuracy: 0.9419 - val_loss: 0.5312 - val_accuracy: 0.8235\n",
      "Epoch 744/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9537 - val_loss: 0.5157 - val_accuracy: 0.8412\n",
      "Epoch 745/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9588 - val_loss: 0.5113 - val_accuracy: 0.8235\n",
      "Epoch 746/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1272 - accuracy: 0.9493 - val_loss: 0.5105 - val_accuracy: 0.8176\n",
      "Epoch 747/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1101 - accuracy: 0.9596 - val_loss: 0.5426 - val_accuracy: 0.8324\n",
      "Epoch 748/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9647 - val_loss: 0.5420 - val_accuracy: 0.8265\n",
      "Epoch 749/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9485 - val_loss: 0.5164 - val_accuracy: 0.8412\n",
      "Epoch 750/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1412 - accuracy: 0.9551 - val_loss: 0.5499 - val_accuracy: 0.8294\n",
      "Epoch 751/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9449 - val_loss: 0.5086 - val_accuracy: 0.8294\n",
      "Epoch 752/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9551 - val_loss: 0.5043 - val_accuracy: 0.8441\n",
      "Epoch 753/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9529 - val_loss: 0.5197 - val_accuracy: 0.8382\n",
      "Epoch 754/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9559 - val_loss: 0.5248 - val_accuracy: 0.8441\n",
      "Epoch 755/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9559 - val_loss: 0.5295 - val_accuracy: 0.8382\n",
      "Epoch 756/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9559 - val_loss: 0.5051 - val_accuracy: 0.8382\n",
      "Epoch 757/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9515 - val_loss: 0.5176 - val_accuracy: 0.8353\n",
      "Epoch 758/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9529 - val_loss: 0.5238 - val_accuracy: 0.8294\n",
      "Epoch 759/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1341 - accuracy: 0.9493 - val_loss: 0.5172 - val_accuracy: 0.8265\n",
      "Epoch 760/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 0.9566 - val_loss: 0.5180 - val_accuracy: 0.8176\n",
      "Epoch 761/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1386 - accuracy: 0.9537 - val_loss: 0.5232 - val_accuracy: 0.8265\n",
      "Epoch 762/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1346 - accuracy: 0.9551 - val_loss: 0.5121 - val_accuracy: 0.8206\n",
      "Epoch 763/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9551 - val_loss: 0.4785 - val_accuracy: 0.8294\n",
      "Epoch 764/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9485 - val_loss: 0.4924 - val_accuracy: 0.8324\n",
      "Epoch 765/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1742 - accuracy: 0.9544 - val_loss: 0.5039 - val_accuracy: 0.8294\n",
      "Epoch 766/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1364 - accuracy: 0.9544 - val_loss: 0.5121 - val_accuracy: 0.8294\n",
      "Epoch 767/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9529 - val_loss: 0.5573 - val_accuracy: 0.8206\n",
      "Epoch 768/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9596 - val_loss: 0.5843 - val_accuracy: 0.8265\n",
      "Epoch 769/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9515 - val_loss: 0.5662 - val_accuracy: 0.8235\n",
      "Epoch 770/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1434 - accuracy: 0.9522 - val_loss: 0.5659 - val_accuracy: 0.8235\n",
      "Epoch 771/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9588 - val_loss: 0.5332 - val_accuracy: 0.8412\n",
      "Epoch 772/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1377 - accuracy: 0.9537 - val_loss: 0.5204 - val_accuracy: 0.8471\n",
      "Epoch 773/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1450 - accuracy: 0.9515 - val_loss: 0.5251 - val_accuracy: 0.8412\n",
      "Epoch 774/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9596 - val_loss: 0.5272 - val_accuracy: 0.8324\n",
      "Epoch 775/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1428 - accuracy: 0.9478 - val_loss: 0.5326 - val_accuracy: 0.8235\n",
      "Epoch 776/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9596 - val_loss: 0.5517 - val_accuracy: 0.8206\n",
      "Epoch 777/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9471 - val_loss: 0.5551 - val_accuracy: 0.8265\n",
      "Epoch 778/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1351 - accuracy: 0.9529 - val_loss: 0.5588 - val_accuracy: 0.8206\n",
      "Epoch 779/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1192 - accuracy: 0.9544 - val_loss: 0.5857 - val_accuracy: 0.8147\n",
      "Epoch 780/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1443 - accuracy: 0.9529 - val_loss: 0.5836 - val_accuracy: 0.8294\n",
      "Epoch 781/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1422 - accuracy: 0.9559 - val_loss: 0.5723 - val_accuracy: 0.8353\n",
      "Epoch 782/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9507 - val_loss: 0.5723 - val_accuracy: 0.8294\n",
      "Epoch 783/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9493 - val_loss: 0.5693 - val_accuracy: 0.8265\n",
      "Epoch 784/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9566 - val_loss: 0.5714 - val_accuracy: 0.8235\n",
      "Epoch 785/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1442 - accuracy: 0.9507 - val_loss: 0.5654 - val_accuracy: 0.8206\n",
      "Epoch 786/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9574 - val_loss: 0.5640 - val_accuracy: 0.8265\n",
      "Epoch 787/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.2478 - accuracy: 0.9515 - val_loss: 0.5473 - val_accuracy: 0.8206\n",
      "Epoch 788/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9478 - val_loss: 0.5608 - val_accuracy: 0.8206\n",
      "Epoch 789/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9551 - val_loss: 0.5558 - val_accuracy: 0.8265\n",
      "Epoch 790/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9522 - val_loss: 0.5468 - val_accuracy: 0.8235\n",
      "Epoch 791/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9596 - val_loss: 0.5385 - val_accuracy: 0.8206\n",
      "Epoch 792/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1462 - accuracy: 0.9441 - val_loss: 0.5489 - val_accuracy: 0.8235\n",
      "Epoch 793/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9544 - val_loss: 0.5393 - val_accuracy: 0.8206\n",
      "Epoch 794/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9529 - val_loss: 0.5122 - val_accuracy: 0.8294\n",
      "Epoch 795/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1174 - accuracy: 0.9647 - val_loss: 0.5322 - val_accuracy: 0.8324\n",
      "Epoch 796/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9544 - val_loss: 0.5053 - val_accuracy: 0.8382\n",
      "Epoch 797/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9581 - val_loss: 0.5306 - val_accuracy: 0.8265\n",
      "Epoch 798/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1335 - accuracy: 0.9463 - val_loss: 0.5222 - val_accuracy: 0.8324\n",
      "Epoch 799/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1339 - accuracy: 0.9471 - val_loss: 0.5180 - val_accuracy: 0.8324\n",
      "Epoch 800/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1446 - accuracy: 0.9478 - val_loss: 0.4964 - val_accuracy: 0.8412\n",
      "Epoch 801/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9551 - val_loss: 0.6043 - val_accuracy: 0.8353\n",
      "Epoch 802/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1240 - accuracy: 0.9588 - val_loss: 0.5991 - val_accuracy: 0.8353\n",
      "Epoch 803/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1324 - accuracy: 0.9559 - val_loss: 0.5866 - val_accuracy: 0.8265\n",
      "Epoch 804/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1307 - accuracy: 0.9574 - val_loss: 0.5916 - val_accuracy: 0.8088\n",
      "Epoch 805/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9507 - val_loss: 0.5769 - val_accuracy: 0.8294\n",
      "Epoch 806/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9507 - val_loss: 0.5944 - val_accuracy: 0.8324\n",
      "Epoch 807/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9581 - val_loss: 0.5955 - val_accuracy: 0.8206\n",
      "Epoch 808/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9618 - val_loss: 0.5918 - val_accuracy: 0.8294\n",
      "Epoch 809/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1202 - accuracy: 0.9581 - val_loss: 0.5778 - val_accuracy: 0.8353\n",
      "Epoch 810/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9603 - val_loss: 0.5691 - val_accuracy: 0.8324\n",
      "Epoch 811/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1398 - accuracy: 0.9515 - val_loss: 0.5695 - val_accuracy: 0.8235\n",
      "Epoch 812/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1290 - accuracy: 0.9544 - val_loss: 0.5546 - val_accuracy: 0.8353\n",
      "Epoch 813/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1296 - accuracy: 0.9551 - val_loss: 0.5887 - val_accuracy: 0.8324\n",
      "Epoch 814/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1345 - accuracy: 0.9551 - val_loss: 0.5846 - val_accuracy: 0.8324\n",
      "Epoch 815/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1257 - accuracy: 0.9522 - val_loss: 0.5834 - val_accuracy: 0.8324\n",
      "Epoch 816/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9588 - val_loss: 0.5653 - val_accuracy: 0.8294\n",
      "Epoch 817/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9537 - val_loss: 0.5571 - val_accuracy: 0.8353\n",
      "Epoch 818/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1418 - accuracy: 0.9544 - val_loss: 0.5530 - val_accuracy: 0.8353\n",
      "Epoch 819/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9529 - val_loss: 0.5560 - val_accuracy: 0.8294\n",
      "Epoch 820/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1457 - accuracy: 0.9522 - val_loss: 0.5452 - val_accuracy: 0.8382\n",
      "Epoch 821/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9500 - val_loss: 0.5616 - val_accuracy: 0.8412\n",
      "Epoch 822/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9596 - val_loss: 0.5735 - val_accuracy: 0.8353\n",
      "Epoch 823/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9559 - val_loss: 0.5600 - val_accuracy: 0.8206\n",
      "Epoch 824/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9537 - val_loss: 0.5442 - val_accuracy: 0.8324\n",
      "Epoch 825/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9574 - val_loss: 0.5754 - val_accuracy: 0.8324\n",
      "Epoch 826/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9581 - val_loss: 0.5547 - val_accuracy: 0.8294\n",
      "Epoch 827/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9559 - val_loss: 0.5544 - val_accuracy: 0.8265\n",
      "Epoch 828/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9603 - val_loss: 0.5452 - val_accuracy: 0.8235\n",
      "Epoch 829/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9581 - val_loss: 0.5342 - val_accuracy: 0.8294\n",
      "Epoch 830/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9551 - val_loss: 0.5113 - val_accuracy: 0.8324\n",
      "Epoch 831/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9588 - val_loss: 0.5317 - val_accuracy: 0.8353\n",
      "Epoch 832/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9566 - val_loss: 0.5312 - val_accuracy: 0.8382\n",
      "Epoch 833/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9610 - val_loss: 0.5761 - val_accuracy: 0.8353\n",
      "Epoch 834/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9691 - val_loss: 0.5636 - val_accuracy: 0.8441\n",
      "Epoch 835/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9588 - val_loss: 0.5507 - val_accuracy: 0.8324\n",
      "Epoch 836/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 0.9559 - val_loss: 0.5537 - val_accuracy: 0.8382\n",
      "Epoch 837/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9566 - val_loss: 0.5257 - val_accuracy: 0.8235\n",
      "Epoch 838/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9596 - val_loss: 0.5251 - val_accuracy: 0.8265\n",
      "Epoch 839/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9566 - val_loss: 0.5406 - val_accuracy: 0.8353\n",
      "Epoch 840/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9603 - val_loss: 0.5470 - val_accuracy: 0.8206\n",
      "Epoch 841/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9647 - val_loss: 0.5413 - val_accuracy: 0.8294\n",
      "Epoch 842/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1721 - accuracy: 0.9537 - val_loss: 0.5419 - val_accuracy: 0.8412\n",
      "Epoch 843/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1238 - accuracy: 0.9551 - val_loss: 0.5636 - val_accuracy: 0.8324\n",
      "Epoch 844/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9603 - val_loss: 0.5647 - val_accuracy: 0.8382\n",
      "Epoch 845/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9522 - val_loss: 0.5603 - val_accuracy: 0.8265\n",
      "Epoch 846/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1166 - accuracy: 0.9596 - val_loss: 0.5396 - val_accuracy: 0.8471\n",
      "Epoch 847/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9537 - val_loss: 0.5167 - val_accuracy: 0.8441\n",
      "Epoch 848/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9632 - val_loss: 0.5286 - val_accuracy: 0.8441\n",
      "Epoch 849/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1348 - accuracy: 0.9500 - val_loss: 0.5343 - val_accuracy: 0.8353\n",
      "Epoch 850/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1267 - accuracy: 0.9574 - val_loss: 0.5391 - val_accuracy: 0.8235\n",
      "Epoch 851/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1366 - accuracy: 0.9529 - val_loss: 0.5342 - val_accuracy: 0.8265\n",
      "Epoch 852/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1281 - accuracy: 0.9588 - val_loss: 0.5339 - val_accuracy: 0.8235\n",
      "Epoch 853/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9537 - val_loss: 0.5263 - val_accuracy: 0.8265\n",
      "Epoch 854/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1187 - accuracy: 0.9485 - val_loss: 0.5265 - val_accuracy: 0.8294\n",
      "Epoch 855/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1144 - accuracy: 0.9588 - val_loss: 0.5516 - val_accuracy: 0.8294\n",
      "Epoch 856/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9603 - val_loss: 0.5575 - val_accuracy: 0.8176\n",
      "Epoch 857/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1327 - accuracy: 0.9544 - val_loss: 0.5798 - val_accuracy: 0.8206\n",
      "Epoch 858/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9596 - val_loss: 0.5555 - val_accuracy: 0.8324\n",
      "Epoch 859/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1347 - accuracy: 0.9544 - val_loss: 0.5821 - val_accuracy: 0.8294\n",
      "Epoch 860/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1224 - accuracy: 0.9618 - val_loss: 0.5537 - val_accuracy: 0.8147\n",
      "Epoch 861/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1160 - accuracy: 0.9581 - val_loss: 0.5340 - val_accuracy: 0.8147\n",
      "Epoch 862/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9574 - val_loss: 0.5367 - val_accuracy: 0.8176\n",
      "Epoch 863/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1384 - accuracy: 0.9566 - val_loss: 0.5611 - val_accuracy: 0.8235\n",
      "Epoch 864/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9676 - val_loss: 0.5738 - val_accuracy: 0.8206\n",
      "Epoch 865/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9551 - val_loss: 0.5853 - val_accuracy: 0.8353\n",
      "Epoch 866/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9529 - val_loss: 0.5602 - val_accuracy: 0.8235\n",
      "Epoch 867/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9581 - val_loss: 0.5539 - val_accuracy: 0.8235\n",
      "Epoch 868/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1333 - accuracy: 0.9551 - val_loss: 0.5883 - val_accuracy: 0.8235\n",
      "Epoch 869/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9537 - val_loss: 0.5910 - val_accuracy: 0.8206\n",
      "Epoch 870/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9566 - val_loss: 0.5918 - val_accuracy: 0.8235\n",
      "Epoch 871/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9507 - val_loss: 0.5866 - val_accuracy: 0.8176\n",
      "Epoch 872/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1178 - accuracy: 0.9588 - val_loss: 0.5587 - val_accuracy: 0.8206\n",
      "Epoch 873/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9566 - val_loss: 0.5775 - val_accuracy: 0.8265\n",
      "Epoch 874/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1231 - accuracy: 0.9566 - val_loss: 0.5585 - val_accuracy: 0.8265\n",
      "Epoch 875/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9654 - val_loss: 0.5425 - val_accuracy: 0.8206\n",
      "Epoch 876/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9603 - val_loss: 0.5410 - val_accuracy: 0.8324\n",
      "Epoch 877/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9566 - val_loss: 0.5584 - val_accuracy: 0.8265\n",
      "Epoch 878/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1039 - accuracy: 0.9588 - val_loss: 0.5710 - val_accuracy: 0.8324\n",
      "Epoch 879/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1214 - accuracy: 0.9574 - val_loss: 0.5840 - val_accuracy: 0.8206\n",
      "Epoch 880/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9654 - val_loss: 0.5807 - val_accuracy: 0.8294\n",
      "Epoch 881/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.9515 - val_loss: 0.5660 - val_accuracy: 0.8353\n",
      "Epoch 882/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1137 - accuracy: 0.9559 - val_loss: 0.5655 - val_accuracy: 0.8324\n",
      "Epoch 883/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9618 - val_loss: 0.5786 - val_accuracy: 0.8235\n",
      "Epoch 884/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9515 - val_loss: 0.5497 - val_accuracy: 0.8353\n",
      "Epoch 885/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9574 - val_loss: 0.5794 - val_accuracy: 0.8294\n",
      "Epoch 886/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1242 - accuracy: 0.9574 - val_loss: 0.5776 - val_accuracy: 0.8206\n",
      "Epoch 887/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9574 - val_loss: 0.5744 - val_accuracy: 0.8294\n",
      "Epoch 888/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9456 - val_loss: 0.5727 - val_accuracy: 0.8294\n",
      "Epoch 889/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9588 - val_loss: 0.5660 - val_accuracy: 0.8324\n",
      "Epoch 890/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1051 - accuracy: 0.9632 - val_loss: 0.5642 - val_accuracy: 0.8382\n",
      "Epoch 891/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9625 - val_loss: 0.5785 - val_accuracy: 0.8412\n",
      "Epoch 892/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9588 - val_loss: 0.5764 - val_accuracy: 0.8294\n",
      "Epoch 893/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9596 - val_loss: 0.5797 - val_accuracy: 0.8324\n",
      "Epoch 894/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1369 - accuracy: 0.9603 - val_loss: 0.5702 - val_accuracy: 0.8353\n",
      "Epoch 895/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1352 - accuracy: 0.9493 - val_loss: 0.5872 - val_accuracy: 0.8382\n",
      "Epoch 896/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9529 - val_loss: 0.6032 - val_accuracy: 0.8382\n",
      "Epoch 897/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9647 - val_loss: 0.5823 - val_accuracy: 0.8382\n",
      "Epoch 898/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1189 - accuracy: 0.9588 - val_loss: 0.5734 - val_accuracy: 0.8471\n",
      "Epoch 899/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1279 - accuracy: 0.9574 - val_loss: 0.5825 - val_accuracy: 0.8294\n",
      "Epoch 900/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9544 - val_loss: 0.5924 - val_accuracy: 0.8382\n",
      "Epoch 901/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9574 - val_loss: 0.5652 - val_accuracy: 0.8382\n",
      "Epoch 902/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1729 - accuracy: 0.9478 - val_loss: 0.5739 - val_accuracy: 0.8353\n",
      "Epoch 903/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9603 - val_loss: 0.5820 - val_accuracy: 0.8324\n",
      "Epoch 904/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9640 - val_loss: 0.5854 - val_accuracy: 0.8324\n",
      "Epoch 905/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.9654 - val_loss: 0.5946 - val_accuracy: 0.8412\n",
      "Epoch 906/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9640 - val_loss: 0.6449 - val_accuracy: 0.8353\n",
      "Epoch 907/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9632 - val_loss: 0.5642 - val_accuracy: 0.8265\n",
      "Epoch 908/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9596 - val_loss: 0.5670 - val_accuracy: 0.8324\n",
      "Epoch 909/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9544 - val_loss: 0.5700 - val_accuracy: 0.8353\n",
      "Epoch 910/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1353 - accuracy: 0.9522 - val_loss: 0.5983 - val_accuracy: 0.8294\n",
      "Epoch 911/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1181 - accuracy: 0.9610 - val_loss: 0.5968 - val_accuracy: 0.8206\n",
      "Epoch 912/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1170 - accuracy: 0.9544 - val_loss: 0.5799 - val_accuracy: 0.8324\n",
      "Epoch 913/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1473 - accuracy: 0.9551 - val_loss: 0.5821 - val_accuracy: 0.8265\n",
      "Epoch 914/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1233 - accuracy: 0.9544 - val_loss: 0.5746 - val_accuracy: 0.8265\n",
      "Epoch 915/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9596 - val_loss: 0.5737 - val_accuracy: 0.8294\n",
      "Epoch 916/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9669 - val_loss: 0.5636 - val_accuracy: 0.8324\n",
      "Epoch 917/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9463 - val_loss: 0.5669 - val_accuracy: 0.8324\n",
      "Epoch 918/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9463 - val_loss: 0.5786 - val_accuracy: 0.8353\n",
      "Epoch 919/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9551 - val_loss: 0.5481 - val_accuracy: 0.8324\n",
      "Epoch 920/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9662 - val_loss: 0.5486 - val_accuracy: 0.8294\n",
      "Epoch 921/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1308 - accuracy: 0.9544 - val_loss: 0.5684 - val_accuracy: 0.8412\n",
      "Epoch 922/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9654 - val_loss: 0.5849 - val_accuracy: 0.8353\n",
      "Epoch 923/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1294 - accuracy: 0.9529 - val_loss: 0.5902 - val_accuracy: 0.8324\n",
      "Epoch 924/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1387 - accuracy: 0.9515 - val_loss: 0.5808 - val_accuracy: 0.8235\n",
      "Epoch 925/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1420 - accuracy: 0.9640 - val_loss: 0.5687 - val_accuracy: 0.8324\n",
      "Epoch 926/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1221 - accuracy: 0.9507 - val_loss: 0.5441 - val_accuracy: 0.8294\n",
      "Epoch 927/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9618 - val_loss: 0.5423 - val_accuracy: 0.8265\n",
      "Epoch 928/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1276 - accuracy: 0.9574 - val_loss: 0.5415 - val_accuracy: 0.8294\n",
      "Epoch 929/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1363 - accuracy: 0.9493 - val_loss: 0.5242 - val_accuracy: 0.8235\n",
      "Epoch 930/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9544 - val_loss: 0.5139 - val_accuracy: 0.8382\n",
      "Epoch 931/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9632 - val_loss: 0.5463 - val_accuracy: 0.8382\n",
      "Epoch 932/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9676 - val_loss: 0.5511 - val_accuracy: 0.8294\n",
      "Epoch 933/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1117 - accuracy: 0.9669 - val_loss: 0.5645 - val_accuracy: 0.8382\n",
      "Epoch 934/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.9529 - val_loss: 0.5534 - val_accuracy: 0.8324\n",
      "Epoch 935/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1802 - accuracy: 0.9544 - val_loss: 0.5586 - val_accuracy: 0.8294\n",
      "Epoch 936/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9566 - val_loss: 0.5685 - val_accuracy: 0.8324\n",
      "Epoch 937/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9537 - val_loss: 0.5646 - val_accuracy: 0.8265\n",
      "Epoch 938/1000\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.1264 - accuracy: 0.9603 - val_loss: 0.6191 - val_accuracy: 0.8235\n",
      "Epoch 939/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1106 - accuracy: 0.9559 - val_loss: 0.6155 - val_accuracy: 0.8412\n",
      "Epoch 940/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1176 - accuracy: 0.9588 - val_loss: 0.6067 - val_accuracy: 0.8353\n",
      "Epoch 941/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1383 - accuracy: 0.9551 - val_loss: 0.6047 - val_accuracy: 0.8265\n",
      "Epoch 942/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.9640 - val_loss: 0.5992 - val_accuracy: 0.8265\n",
      "Epoch 943/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1009 - accuracy: 0.9632 - val_loss: 0.6346 - val_accuracy: 0.8265\n",
      "Epoch 944/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1485 - accuracy: 0.9581 - val_loss: 0.6176 - val_accuracy: 0.8412\n",
      "Epoch 945/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1390 - accuracy: 0.9566 - val_loss: 0.6015 - val_accuracy: 0.8412\n",
      "Epoch 946/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1340 - accuracy: 0.9485 - val_loss: 0.5790 - val_accuracy: 0.8353\n",
      "Epoch 947/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9662 - val_loss: 0.5928 - val_accuracy: 0.8382\n",
      "Epoch 948/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9537 - val_loss: 0.5913 - val_accuracy: 0.8353\n",
      "Epoch 949/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1134 - accuracy: 0.9588 - val_loss: 0.5845 - val_accuracy: 0.8353\n",
      "Epoch 950/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9588 - val_loss: 0.5695 - val_accuracy: 0.8412\n",
      "Epoch 951/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1355 - accuracy: 0.9603 - val_loss: 0.5857 - val_accuracy: 0.8412\n",
      "Epoch 952/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.9610 - val_loss: 0.5851 - val_accuracy: 0.8353\n",
      "Epoch 953/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9632 - val_loss: 0.5713 - val_accuracy: 0.8412\n",
      "Epoch 954/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9529 - val_loss: 0.5667 - val_accuracy: 0.8353\n",
      "Epoch 955/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9574 - val_loss: 0.5936 - val_accuracy: 0.8235\n",
      "Epoch 956/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9610 - val_loss: 0.5641 - val_accuracy: 0.8412\n",
      "Epoch 957/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9632 - val_loss: 0.5734 - val_accuracy: 0.8412\n",
      "Epoch 958/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.9596 - val_loss: 0.5808 - val_accuracy: 0.8471\n",
      "Epoch 959/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9596 - val_loss: 0.5838 - val_accuracy: 0.8441\n",
      "Epoch 960/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9566 - val_loss: 0.5992 - val_accuracy: 0.8412\n",
      "Epoch 961/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9654 - val_loss: 0.5917 - val_accuracy: 0.8412\n",
      "Epoch 962/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9588 - val_loss: 0.6011 - val_accuracy: 0.8441\n",
      "Epoch 963/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9610 - val_loss: 0.5940 - val_accuracy: 0.8441\n",
      "Epoch 964/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1168 - accuracy: 0.9610 - val_loss: 0.5645 - val_accuracy: 0.8412\n",
      "Epoch 965/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9610 - val_loss: 0.5630 - val_accuracy: 0.8412\n",
      "Epoch 966/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9669 - val_loss: 0.5181 - val_accuracy: 0.8500\n",
      "Epoch 967/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9574 - val_loss: 0.5268 - val_accuracy: 0.8235\n",
      "Epoch 968/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.9625 - val_loss: 0.6488 - val_accuracy: 0.8206\n",
      "Epoch 969/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9603 - val_loss: 0.6462 - val_accuracy: 0.8294\n",
      "Epoch 970/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1252 - accuracy: 0.9515 - val_loss: 0.6326 - val_accuracy: 0.8235\n",
      "Epoch 971/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1406 - accuracy: 0.9507 - val_loss: 0.5973 - val_accuracy: 0.8382\n",
      "Epoch 972/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9574 - val_loss: 0.6176 - val_accuracy: 0.8176\n",
      "Epoch 973/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1041 - accuracy: 0.9676 - val_loss: 0.6276 - val_accuracy: 0.8294\n",
      "Epoch 974/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9618 - val_loss: 0.6130 - val_accuracy: 0.8235\n",
      "Epoch 975/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1135 - accuracy: 0.9640 - val_loss: 0.6087 - val_accuracy: 0.8324\n",
      "Epoch 976/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9647 - val_loss: 0.5998 - val_accuracy: 0.8294\n",
      "Epoch 977/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.9713 - val_loss: 0.6062 - val_accuracy: 0.8294\n",
      "Epoch 978/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9566 - val_loss: 0.6074 - val_accuracy: 0.8265\n",
      "Epoch 979/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1108 - accuracy: 0.9610 - val_loss: 0.5664 - val_accuracy: 0.8324\n",
      "Epoch 980/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9618 - val_loss: 0.5500 - val_accuracy: 0.8294\n",
      "Epoch 981/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.9603 - val_loss: 0.5568 - val_accuracy: 0.8294\n",
      "Epoch 982/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0990 - accuracy: 0.9699 - val_loss: 0.5429 - val_accuracy: 0.8206\n",
      "Epoch 983/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9551 - val_loss: 0.5275 - val_accuracy: 0.8324\n",
      "Epoch 984/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9647 - val_loss: 0.5527 - val_accuracy: 0.8265\n",
      "Epoch 985/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1133 - accuracy: 0.9610 - val_loss: 0.5753 - val_accuracy: 0.8353\n",
      "Epoch 986/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1145 - accuracy: 0.9603 - val_loss: 0.5686 - val_accuracy: 0.8324\n",
      "Epoch 987/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9618 - val_loss: 0.5523 - val_accuracy: 0.8324\n",
      "Epoch 988/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1051 - accuracy: 0.9654 - val_loss: 0.5628 - val_accuracy: 0.8265\n",
      "Epoch 989/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9647 - val_loss: 0.5814 - val_accuracy: 0.8265\n",
      "Epoch 990/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9596 - val_loss: 0.5701 - val_accuracy: 0.8353\n",
      "Epoch 991/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1146 - accuracy: 0.9625 - val_loss: 0.5482 - val_accuracy: 0.8412\n",
      "Epoch 992/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1017 - accuracy: 0.9654 - val_loss: 0.5622 - val_accuracy: 0.8324\n",
      "Epoch 993/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1380 - accuracy: 0.9537 - val_loss: 0.5696 - val_accuracy: 0.8382\n",
      "Epoch 994/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1183 - accuracy: 0.9522 - val_loss: 0.5789 - val_accuracy: 0.8324\n",
      "Epoch 995/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1206 - accuracy: 0.9515 - val_loss: 0.5344 - val_accuracy: 0.8294\n",
      "Epoch 996/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.9625 - val_loss: 0.5306 - val_accuracy: 0.8412\n",
      "Epoch 997/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9603 - val_loss: 0.5749 - val_accuracy: 0.8353\n",
      "Epoch 998/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1230 - accuracy: 0.9507 - val_loss: 0.5737 - val_accuracy: 0.8353\n",
      "Epoch 999/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.0980 - accuracy: 0.9632 - val_loss: 0.5831 - val_accuracy: 0.8294\n",
      "Epoch 1000/1000\n",
      "43/43 [==============================] - 0s 3ms/step - loss: 0.1268 - accuracy: 0.9544 - val_loss: 0.5178 - val_accuracy: 0.8353\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.8353\n",
      "Accuracy for investment grade classification: 83.53%\n",
      "11/11 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train_grade, epochs=1000, batch_size=32, validation_data=(X_test, y_test_grade))\n",
    "# evaluate the model for investment grade classification\n",
    "_, accuracy = model.evaluate(X_test, y_test_grade)\n",
    "print('Accuracy for investment grade classification: {:.2f}%'.format(accuracy*100))\n",
    "\n",
    "# predict the investment grade for the test set\n",
    "y_pred_grade = model.predict(X_test)\n",
    "y_pred_grade = (y_pred_grade > 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
